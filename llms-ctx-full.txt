<project title="Claude Flow" summary="To provide a comprehensive AI development environment that utilizes hive-mind coordination, neural computing, and distributed memory systems for efficient task execution, coordination, and integration with platforms like GitHub and Claude Code. The project aims to test and refine these capabilities in an alpha release.">**Remember:**
- Hive-mind coordination with a queen agent and specialized worker agents
- Neural computing for pattern recognition and AI optimization
- Distributed memory system with SQLite persistence and cross-session recall
- Integration with GitHub for repository automation and security analysis
- Claude Code integration for AI development workflows
- 87 MCP tools for comprehensive AI task orchestration<docs><doc title="README" desc="overview and usage.">---
name: Agents Directory
type: documentation
category: agents
description: Sub-agent definitions organized by type and purpose with specific capabilities and tool restrictions
---

# Claude Code Agents Directory Structure

This directory contains sub-agent definitions organized by type and purpose. Each agent has specific capabilities, tool restrictions, and naming conventions that trigger automatic delegation.

## Directory Structure

```
.claude/agents/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ _templates/                  # Agent templates
â”‚   â”œâ”€â”€ base-agent.yaml
â”‚   â””â”€â”€ agent-types.md
â”œâ”€â”€ development/                 # Development agents
â”‚   â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ fullstack/
â”‚   â””â”€â”€ api/
â”œâ”€â”€ testing/                     # Testing agents
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ performance/
â”œâ”€â”€ architecture/                # Architecture agents
â”‚   â”œâ”€â”€ system-design/
â”‚   â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ cloud/
â”‚   â””â”€â”€ security/
â”œâ”€â”€ devops/                      # DevOps agents
â”‚   â”œâ”€â”€ ci-cd/
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ deployment/
â”œâ”€â”€ documentation/               # Documentation agents
â”‚   â”œâ”€â”€ api-docs/
â”‚   â”œâ”€â”€ user-guides/
â”‚   â”œâ”€â”€ technical/
â”‚   â””â”€â”€ readme/
â”œâ”€â”€ analysis/                    # Analysis agents
â”‚   â”œâ”€â”€ code-review/
â”‚   â”œâ”€â”€ performance/
â”‚   â”œâ”€â”€ security/
â”‚   â””â”€â”€ refactoring/
â”œâ”€â”€ data/                        # Data agents
â”‚   â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ ml/
â”‚   â””â”€â”€ visualization/
â””â”€â”€ specialized/                 # Specialized agents
    â”œâ”€â”€ mobile/
    â”œâ”€â”€ embedded/
    â”œâ”€â”€ blockchain/
    â””â”€â”€ ai-ml/
```

## Naming Conventions

Agent files follow this naming pattern:
`[type]-[specialization]-[capability].agent.yaml`

Examples:
- `dev-backend-api.agent.yaml`
- `test-unit-jest.agent.yaml`
- `arch-cloud-aws.agent.yaml`
- `docs-api-openapi.agent.yaml`

## Automatic Delegation Triggers

Claude Code automatically delegates to agents based on:
1. **Keywords in user request**: "test", "deploy", "document", "review"
2. **File patterns**: `*.test.js` â†’ testing agent, `*.tf` â†’ infrastructure agent
3. **Task complexity**: Multi-step tasks spawn coordinator agents
4. **Domain detection**: Database queries â†’ data agent, API endpoints â†’ backend agent

## Tool Restrictions

Each agent type has specific tool access:
- **Development agents**: Full file system access, code execution
- **Testing agents**: Test runners, coverage tools, limited write access
- **Architecture agents**: Read-only access, diagram generation
- **Documentation agents**: Markdown tools, read access, limited write to docs/
- **DevOps agents**: Infrastructure tools, deployment scripts, environment access
- **Analysis agents**: Read-only access, static analysis tools</doc><doc title="Docs Api Openapi" desc="docs page.">---
name: "api-docs"
color: "indigo"
type: "documentation"
version: "1.0.0"
created: "2025-07-25"
author: "Claude Code"
metadata:
  description: "Expert agent for creating and maintaining OpenAPI/Swagger documentation"
  specialization: "OpenAPI 3.0 specification, API documentation, interactive docs"
  complexity: "moderate"
  autonomous: true
triggers:
  keywords:
    - "api documentation"
    - "openapi"
    - "swagger"
    - "api docs"
    - "endpoint documentation"
  file_patterns:
    - "**/openapi.yaml"
    - "**/swagger.yaml"
    - "**/api-docs/**"
    - "**/api.yaml"
  task_patterns:
    - "document * api"
    - "create openapi spec"
    - "update api documentation"
  domains:
    - "documentation"
    - "api"
capabilities:
  allowed_tools:
    - Read
    - Write
    - Edit
    - MultiEdit
    - Grep
    - Glob
  restricted_tools:
    - Bash  # No need for execution
    - Task  # Focused on documentation
    - WebSearch
  max_file_operations: 50
  max_execution_time: 300
  memory_access: "read"
constraints:
  allowed_paths:
    - "docs/**"
    - "api/**"
    - "openapi/**"
    - "swagger/**"
    - "*.yaml"
    - "*.yml"
    - "*.json"
  forbidden_paths:
    - "node_modules/**"
    - ".git/**"
    - "secrets/**"
  max_file_size: 2097152  # 2MB
  allowed_file_types:
    - ".yaml"
    - ".yml"
    - ".json"
    - ".md"
behavior:
  error_handling: "lenient"
  confirmation_required:
    - "deleting API documentation"
    - "changing API versions"
  auto_rollback: false
  logging_level: "info"
communication:
  style: "technical"
  update_frequency: "summary"
  include_code_snippets: true
  emoji_usage: "minimal"
integration:
  can_spawn: []
  can_delegate_to:
    - "analyze-api"
  requires_approval_from: []
  shares_context_with:
    - "dev-backend-api"
    - "test-integration"
optimization:
  parallel_operations: true
  batch_size: 10
  cache_results: false
  memory_limit: "256MB"
hooks:
  pre_execution: |
    echo "ğŸ“ OpenAPI Documentation Specialist starting..."
    echo "ğŸ” Analyzing API endpoints..."
    # Look for existing API routes
    find . -name "*.route.js" -o -name "*.controller.js" -o -name "routes.js" | grep -v node_modules | head -10
    # Check for existing OpenAPI docs
    find . -name "openapi.yaml" -o -name "swagger.yaml" -o -name "api.yaml" | grep -v node_modules
  post_execution: |
    echo "âœ… API documentation completed"
    echo "ğŸ“Š Validating OpenAPI specification..."
    # Check if the spec exists and show basic info
    if [ -f "openapi.yaml" ]; then
      echo "OpenAPI spec found at openapi.yaml"
      grep -E "^(openapi:|info:|paths:)" openapi.yaml | head -5
    fi
  on_error: |
    echo "âš ï¸ Documentation error: {{error_message}}"
    echo "ğŸ”§ Check OpenAPI specification syntax"
examples:
  - trigger: "create OpenAPI documentation for user API"
    response: "I'll create comprehensive OpenAPI 3.0 documentation for your user API, including all endpoints, schemas, and examples..."
  - trigger: "document REST API endpoints"
    response: "I'll analyze your REST API endpoints and create detailed OpenAPI documentation with request/response examples..."
---

# OpenAPI Documentation Specialist

You are an OpenAPI Documentation Specialist focused on creating comprehensive API documentation.

## Key responsibilities:
1. Create OpenAPI 3.0 compliant specifications
2. Document all endpoints with descriptions and examples
3. Define request/response schemas accurately
4. Include authentication and security schemes
5. Provide clear examples for all operations

## Best practices:
- Use descriptive summaries and descriptions
- Include example requests and responses
- Document all possible error responses
- Use $ref for reusable components
- Follow OpenAPI 3.0 specification strictly
- Group endpoints logically with tags

## OpenAPI structure:
```yaml
openapi: 3.0.0
info:
  title: API Title
  version: 1.0.0
  description: API Description
servers:
  - url: https://api.example.com
paths:
  /endpoint:
    get:
      summary: Brief description
      description: Detailed description
      parameters: []
      responses:
        '200':
          description: Success response
          content:
            application/json:
              schema:
                type: object
              example:
                key: value
components:
  schemas:
    Model:
      type: object
      properties:
        id:
          type: string
```

## Documentation elements:
- Clear operation IDs
- Request/response examples
- Error response documentation
- Security requirements
- Rate limiting information</doc><doc title="README" desc="docs page."># SPARC Memory Bank System

## Overview

The SPARC Memory Bank is a sophisticated, distributed memory management system designed for multi-agent collaborative development environments. It provides persistent, searchable, and conflict-resistant storage with advanced features including CRDT-based synchronization, vector search, namespace isolation, and multiple storage backends.

## Key Features

- **Dual Storage Backends**: SQLite for performance, Markdown for human-readability and git integration
- **Advanced Caching**: Multiple eviction strategies with TTL support and performance metrics
- **Vector Search**: Semantic similarity search with embeddings and indexing
- **CRDT Conflict Resolution**: Automatic conflict resolution for concurrent updates
- **Namespace Isolation**: Multi-tenant support with permissions and access control
- **Replication**: Distributed synchronization across multiple instances
- **Import/Export**: Multiple formats with compression and encryption
- **Full-Text Search**: Integrated FTS5 search for SQLite backend

## Quick Start

```typescript
import { MemoryManager } from '@sparc/memory-bank';

// Initialize with SQLite backend
const memory = new MemoryManager({
  backend: 'sqlite',
  storage: { path: './memory.db' },
  cache: { enabled: true, maxSize: 100 * 1024 * 1024 }, // 100MB
  indexing: { vectorSearch: true }
});

// Store a memory item
const item = await memory.store({
  id: 'task-001',
  category: 'implementation',
  content: 'Implemented user authentication system',
  tags: ['auth', 'security', 'backend'],
  metadata: {
    assignee: 'alice',
    priority: 'high',
    completion: 0.8
  }
});

// Query memories
const results = await memory.query({
  category: 'implementation',
  tags: ['auth'],
  fullText: 'authentication',
  limit: 10
});
```

## Documentation Structure

- [Architecture Overview](./architecture.md) - System design and component interactions
- [API Reference](./api.md) - Complete API documentation
- [Usage Guide](./usage.md) - Practical examples and best practices
- [Backends](./backends.md) - Storage backend configuration and capabilities
- [Configuration](./configuration.md) - Complete configuration reference
- [Performance](./performance.md) - Optimization and monitoring
- [Security](./security.md) - Security features and best practices
- [Deployment](./deployment.md) - Production deployment guide
- [Troubleshooting](./troubleshooting.md) - Common issues and solutions

## Installation

```bash
# Using npm
npm install @sparc/memory-bank

# Using deno
import { MemoryManager } from 'https://deno.land/x/sparc_memory@latest/mod.ts';
```

## Core Concepts

### Memory Items

Memory items are the fundamental unit of storage in the SPARC Memory Bank:

```typescript
interface MemoryItem {
  id: string;                           // Unique identifier
  category: string;                     // Logical grouping
  content: string;                      // Main content
  tags: string[];                       // Searchable tags
  namespace?: string;                   // Isolation boundary
  metadata?: Record<string, unknown>;   // Additional data
  embedding?: number[];                 // Vector representation
  version: number;                      // CRDT version
  vectorClock: Record<string, number>;  // Conflict resolution
  created: Date;                        // Creation timestamp
  updated: Date;                        // Last modification
  checksum: string;                     // Integrity verification
}
```

### Backends

**SQLite Backend**: Optimized for performance with FTS5 search, WAL mode, and proper indexing.

**Markdown Backend**: Human-readable storage with git integration for version control and collaboration.

### Caching

Intelligent caching layer with multiple eviction strategies:
- **LRU**: Least Recently Used (default)
- **LFU**: Least Frequently Used
- **FIFO**: First In, First Out
- **TTL**: Time To Live based expiration

### Vector Search

Semantic similarity search using vector embeddings:
- Automatic embedding generation
- Cosine similarity matching
- Configurable similarity thresholds
- Integration with external embedding services

## System Requirements

- **Runtime**: Node.js 18+ or Deno 1.30+
- **Storage**: SQLite 3.38+ (for SQLite backend)
- **Memory**: Minimum 512MB RAM (varies with cache size)
- **Disk**: Variable (depends on data volume and caching)

## License

MIT License - see [LICENSE](../LICENSE) for details.

## Contributing

See [CONTRIBUTING.md](../CONTRIBUTING.md) for development setup and guidelines.

## Support

- **Documentation**: [GitHub Wiki](https://github.com/sparc/memory-bank/wiki)
- **Issues**: [GitHub Issues](https://github.com/sparc/memory-bank/issues)
- **Discussions**: [GitHub Discussions](https://github.com/sparc/memory-bank/discussions)</doc><doc title="Api" desc="docs page."># API Reference

## Core Classes

### MemoryManager

The main interface for all memory operations.

```typescript
class MemoryManager {
  constructor(config: MemoryConfig)
  
  // Core operations
  async store(item: Partial<MemoryItem>): Promise<MemoryItem>
  async retrieve(id: string): Promise<MemoryItem | null>
  async query(query: MemoryQuery): Promise<MemoryItem[]>
  async update(id: string, updates: Partial<MemoryItem>): Promise<MemoryItem>
  async delete(id: string): Promise<boolean>
  
  // Batch operations
  async storeBatch(items: Partial<MemoryItem>[]): Promise<MemoryItem[]>
  async retrieveBatch(ids: string[]): Promise<(MemoryItem | null)[]>
  async deleteBatch(ids: string[]): Promise<boolean[]>
  
  // Advanced operations
  async vectorSearch(query: VectorQuery): Promise<VectorSearchResult[]>
  async fullTextSearch(query: string, options?: SearchOptions): Promise<MemoryItem[]>
  async getStatistics(): Promise<MemoryStatistics>
  
  // Lifecycle
  async initialize(): Promise<void>
  async close(): Promise<void>
  async backup(options: BackupOptions): Promise<string>
  async restore(backupPath: string): Promise<void>
}
```

#### store(item: Partial<MemoryItem>): Promise<MemoryItem>

Stores a new memory item or updates an existing one.

**Parameters:**
- `item`: Partial memory item with at least `category` and `content`

**Returns:**
- Complete `MemoryItem` with generated ID, timestamps, and metadata

**Example:**
```typescript
const item = await memory.store({
  category: 'task',
  content: 'Implement user authentication',
  tags: ['auth', 'security'],
  metadata: {
    priority: 'high',
    assignee: 'alice'
  }
});

console.log(`Created item: ${item.id}`);
```

#### retrieve(id: string): Promise<MemoryItem | null>

Retrieves a memory item by its unique ID.

**Parameters:**
- `id`: Unique identifier of the memory item

**Returns:**
- `MemoryItem` if found, `null` otherwise

**Example:**
```typescript
const item = await memory.retrieve('item-123');
if (item) {
  console.log(`Found: ${item.content}`);
} else {
  console.log('Item not found');
}
```

#### query(query: MemoryQuery): Promise<MemoryItem[]>

Searches for memory items based on various criteria.

**Parameters:**
- `query`: Search criteria and options

**Returns:**
- Array of matching `MemoryItem`s, sorted by relevance

**Example:**
```typescript
const results = await memory.query({
  category: 'task',
  tags: ['auth'],
  fullText: 'authentication',
  dateRange: {
    start: new Date('2024-01-01'),
    end: new Date('2024-12-31')
  },
  limit: 10,
  sortBy: 'updated',
  sortOrder: 'desc'
});

console.log(`Found ${results.length} items`);
```

#### update(id: string, updates: Partial<MemoryItem>): Promise<MemoryItem>

Updates an existing memory item with conflict resolution.

**Parameters:**
- `id`: Unique identifier of the item to update
- `updates`: Partial updates to apply

**Returns:**
- Updated `MemoryItem` with new version and timestamp

**Example:**
```typescript
const updated = await memory.update('item-123', {
  content: 'Updated implementation notes',
  tags: ['auth', 'security', 'completed'],
  metadata: {
    ...item.metadata,
    status: 'completed',
    completedAt: new Date()
  }
});

console.log(`Updated to version ${updated.version}`);
```

#### delete(id: string): Promise<boolean>

Deletes a memory item permanently.

**Parameters:**
- `id`: Unique identifier of the item to delete

**Returns:**
- `true` if item was deleted, `false` if not found

**Example:**
```typescript
const deleted = await memory.delete('item-123');
if (deleted) {
  console.log('Item deleted successfully');
} else {
  console.log('Item not found');
}
```

#### vectorSearch(query: VectorQuery): Promise<VectorSearchResult[]>

Performs semantic similarity search using vector embeddings.

**Parameters:**
- `query`: Vector search criteria

**Returns:**
- Array of results with similarity scores

**Example:**
```typescript
const results = await memory.vectorSearch({
  text: 'user authentication and security',
  threshold: 0.7,
  limit: 5,
  categories: ['task', 'research']
});

for (const result of results) {
  console.log(`${result.item.content} (${result.similarity})`);
}
```

## Data Types

### MemoryItem

The core data structure representing a stored memory.

```typescript
interface MemoryItem {
  id: string;                           // Unique identifier (UUID)
  category: string;                     // Logical grouping (e.g., 'task', 'research')
  content: string;                      // Main content/description
  tags: string[];                       // Searchable tags
  namespace?: string;                   // Isolation boundary
  metadata?: Record<string, unknown>;   // Additional structured data
  embedding?: number[];                 // Vector representation (1536 dimensions)
  version: number;                      // CRDT version counter
  vectorClock: Record<string, number>;  // Conflict resolution timestamps
  created: Date;                        // Creation timestamp
  updated: Date;                        // Last modification timestamp
  checksum: string;                     // SHA-256 integrity hash
}
```

### MemoryQuery

Search criteria for querying memory items.

```typescript
interface MemoryQuery {
  // Content filters
  category?: string;                    // Exact category match
  categories?: string[];                // Multiple category options
  tags?: string[];                      // Must include all tags (AND)
  tagsAny?: string[];                   // Must include any tag (OR)
  fullText?: string;                    // Full-text search query
  content?: string;                     // Content substring match
  
  // Metadata filters
  namespace?: string;                   // Namespace isolation
  metadata?: Record<string, unknown>;   // Metadata key-value matches
  
  // Time filters
  dateRange?: {
    start?: Date;                       // Items created/updated after
    end?: Date;                         // Items created/updated before
    field?: 'created' | 'updated';     // Which timestamp to use
  };
  
  // Vector search
  similarity?: {
    text?: string;                      // Text to compare against
    embedding?: number[];               // Direct embedding comparison
    threshold?: number;                 // Minimum similarity (0-1)
  };
  
  // Result options
  limit?: number;                       // Maximum results (default: 100)
  offset?: number;                      // Skip first N results
  sortBy?: 'created' | 'updated' | 'category' | 'relevance';
  sortOrder?: 'asc' | 'desc';          // Sort direction
  
  // Performance options
  useCache?: boolean;                   // Use cache for results
  includeEmbeddings?: boolean;          // Include vector data in results
}
```

### VectorQuery

Specialized query for semantic vector search.

```typescript
interface VectorQuery {
  text?: string;                        // Text to find similar items for
  embedding?: number[];                 // Pre-computed embedding vector
  threshold?: number;                   // Minimum similarity score (0-1)
  limit?: number;                       // Maximum results
  categories?: string[];                // Limit to specific categories
  namespaces?: string[];                // Limit to specific namespaces
  excludeIds?: string[];                // Exclude specific item IDs
}
```

### VectorSearchResult

Result from vector similarity search.

```typescript
interface VectorSearchResult {
  item: MemoryItem;                     // The matching memory item
  similarity: number;                   // Cosine similarity score (0-1)
  distance: number;                     // Euclidean distance
  rank: number;                         // Result ranking (1-based)
}
```

### MemoryConfig

Configuration options for the memory system.

```typescript
interface MemoryConfig {
  // Backend configuration
  backend: 'sqlite' | 'markdown';      // Storage backend type
  storage: {
    path: string;                       // Storage path/connection string
    options?: Record<string, unknown>;  // Backend-specific options
  };
  
  // Cache configuration
  cache?: {
    enabled: boolean;                   // Enable caching
    maxSize: number;                    // Maximum cache size in bytes
    strategy: 'lru' | 'lfu' | 'fifo' | 'ttl';  // Eviction strategy
    ttl?: number;                       // Time-to-live in milliseconds
  };
  
  // Indexing configuration
  indexing?: {
    enabled: boolean;                   // Enable advanced indexing
    vectorSearch: boolean;              // Enable vector search
    fullTextSearch: boolean;            // Enable full-text search
    embeddingService?: EmbeddingService; // Custom embedding service
  };
  
  // Namespace configuration
  namespaces?: {
    enabled: boolean;                   // Enable namespace isolation
    defaultNamespace: string;           // Default namespace name
    permissions?: NamespacePermissions; // Access control
  };
  
  // Replication configuration
  replication?: {
    enabled: boolean;                   // Enable replication
    peers: string[];                    // Peer connection strings
    strategy: 'immediate' | 'batched' | 'scheduled';
    conflictResolution: 'lastWrite' | 'merge' | 'manual';
  };
  
  // Security configuration
  security?: {
    encryption: {
      enabled: boolean;                 // Enable encryption at rest
      algorithm: 'aes-256-gcm';         // Encryption algorithm
      keyDerivation: 'pbkdf2';          // Key derivation function
    };
    checksums: boolean;                 // Enable integrity checking
    auditLog: boolean;                  // Enable audit logging
  };
}
```

## Error Types

### MemoryError

Base error class for all memory-related errors.

```typescript
class MemoryError extends Error {
  constructor(
    message: string,
    public code: string,
    public details?: unknown
  )
}
```

### Common Error Codes

- `ITEM_NOT_FOUND`: Requested item does not exist
- `INVALID_QUERY`: Query parameters are invalid
- `STORAGE_ERROR`: Backend storage operation failed
- `CACHE_ERROR`: Cache operation failed
- `INDEX_ERROR`: Indexing operation failed
- `NAMESPACE_ERROR`: Namespace operation failed
- `PERMISSION_DENIED`: Insufficient permissions
- `CONFLICT_ERROR`: CRDT merge conflict
- `VALIDATION_ERROR`: Data validation failed
- `INITIALIZATION_ERROR`: System initialization failed

## Advanced Features

### Batch Operations

Efficient bulk operations for high-throughput scenarios.

```typescript
// Store multiple items efficiently
const items = await memory.storeBatch([
  { category: 'task', content: 'Task 1' },
  { category: 'task', content: 'Task 2' },
  { category: 'research', content: 'Finding 1' }
]);

// Retrieve multiple items by ID
const retrieved = await memory.retrieveBatch(['id1', 'id2', 'id3']);

// Delete multiple items
const deleted = await memory.deleteBatch(['id1', 'id2']);
```

### Statistics and Monitoring

```typescript
interface MemoryStatistics {
  totalItems: number;
  itemsByCategory: Record<string, number>;
  itemsByNamespace: Record<string, number>;
  storageSize: number;
  cacheStats: {
    hitRate: number;
    missRate: number;
    evictions: number;
    size: number;
  };
  indexStats: {
    vectorIndexSize: number;
    fullTextIndexSize: number;
    rebuildCount: number;
  };
  performance: {
    averageQueryTime: number;
    averageStoreTime: number;
    averageRetrieveTime: number;
  };
}

const stats = await memory.getStatistics();
console.log(`Total items: ${stats.totalItems}`);
console.log(`Cache hit rate: ${(stats.cacheStats.hitRate * 100).toFixed(2)}%`);
```

### Backup and Restore

```typescript
// Create backup
const backupPath = await memory.backup({
  format: 'json',
  compression: 'gzip',
  encryption: true,
  includeIndexes: false
});

// Restore from backup
await memory.restore(backupPath);
```

### Event Handling

```typescript
// Listen for memory events
memory.on('itemStored', (item: MemoryItem) => {
  console.log(`Stored: ${item.id}`);
});

memory.on('itemUpdated', (item: MemoryItem, previousVersion: number) => {
  console.log(`Updated: ${item.id} (v${previousVersion} -> v${item.version})`);
});

memory.on('itemDeleted', (id: string) => {
  console.log(`Deleted: ${id}`);
});

memory.on('conflictResolved', (item: MemoryItem, conflicts: MemoryItem[]) => {
  console.log(`Resolved conflict for: ${item.id}`);
});
```</doc><doc title="Architecture" desc="docs page."># Architecture Overview

## System Architecture

The SPARC Memory Bank follows a layered architecture designed for scalability, maintainability, and performance:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Application Layer                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Memory Manager  â”‚  Namespace Manager  â”‚  Replication Mgr  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Cache Layer     â”‚      Indexer      â”‚   Import/Export   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        SQLite Backend        â”‚      Markdown Backend        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Storage Layer (File System/Database)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### Memory Manager

The central orchestrator that coordinates all memory operations:

```typescript
class MemoryManager {
  private backend: MemoryBackend;
  private cache: MemoryCache;
  private indexer: MemoryIndexer;
  private namespaceManager: NamespaceManager;
  private replicationManager: ReplicationManager;
  private config: MemoryConfig;

  // Core operations
  async store(item: Partial<MemoryItem>): Promise<MemoryItem>
  async retrieve(id: string): Promise<MemoryItem | null>
  async query(query: MemoryQuery): Promise<MemoryItem[]>
  async update(id: string, updates: Partial<MemoryItem>): Promise<MemoryItem>
  async delete(id: string): Promise<boolean>
}
```

**Key Responsibilities:**
- Coordinate operations across all subsystems
- Manage transactions and consistency
- Handle caching strategies
- Orchestrate replication and conflict resolution
- Provide unified API interface

### Storage Backends

#### SQLite Backend

**Optimizations:**
- WAL (Write-Ahead Logging) mode for concurrent access
- FTS5 full-text search with custom tokenizers
- Prepared statements for performance
- Connection pooling for concurrent operations
- Automatic vacuum and optimization

**Schema Design:**
```sql
CREATE TABLE memory_items (
  id TEXT PRIMARY KEY,
  category TEXT NOT NULL,
  content TEXT NOT NULL,
  tags TEXT, -- JSON array
  namespace TEXT,
  metadata TEXT, -- JSON object
  embedding BLOB, -- Vector data
  version INTEGER NOT NULL,
  vector_clock TEXT, -- JSON object
  created INTEGER NOT NULL,
  updated INTEGER NOT NULL,
  checksum TEXT NOT NULL
);

-- Indexes for optimal query performance
CREATE INDEX idx_category ON memory_items(category);
CREATE INDEX idx_namespace ON memory_items(namespace);
CREATE INDEX idx_created ON memory_items(created);
CREATE INDEX idx_updated ON memory_items(updated);

-- Full-text search virtual table
CREATE VIRTUAL TABLE memory_fts USING fts5(
  content,
  tags,
  content='memory_items',
  content_rowid='rowid'
);
```

#### Markdown Backend

**Directory Structure:**
```
memory/
â”œâ”€â”€ namespaces/
â”‚   â”œâ”€â”€ default/
â”‚   â”‚   â”œâ”€â”€ implementation/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2024/01/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ task-001.md
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ task-002.md
â”‚   â”‚   â”‚   â””â”€â”€ index.json
â”‚   â”‚   â””â”€â”€ research/
â”‚   â””â”€â”€ project-x/
â”œâ”€â”€ .meta/
â”‚   â”œâ”€â”€ vector_clock.json
â”‚   â”œâ”€â”€ checksums.json
â”‚   â””â”€â”€ indexes/
â””â”€â”€ .gitignore
```

**File Format:**
```markdown
---
id: task-001
category: implementation
tags: [auth, security, backend]
namespace: default
version: 3
vectorClock:
  agent-1: 2
  agent-2: 1
created: 2024-01-15T10:30:00Z
updated: 2024-01-15T14:20:00Z
checksum: sha256:abc123...
metadata:
  assignee: alice
  priority: high
  completion: 0.8
---

# User Authentication Implementation

Implemented JWT-based authentication system with the following features:

- Token generation and validation
- Role-based access control
- Session management
- Password hashing with bcrypt

## Progress

- [x] JWT token service
- [x] Authentication middleware
- [x] User registration endpoint
- [ ] Password reset functionality
```

### Caching System

**Multi-Strategy Cache:**
```typescript
interface CacheEntry<T> {
  value: T;
  accessCount: number;
  lastAccessed: number;
  created: number;
  ttl?: number;
  size: number;
}

class MemoryCache {
  private strategies: {
    lru: LRUStrategy;
    lfu: LFUStrategy;
    fifo: FIFOStrategy;
    ttl: TTLStrategy;
  };

  private stats: {
    hits: number;
    misses: number;
    evictions: number;
    totalSize: number;
  };
}
```

**Cache Strategies:**
- **LRU (Least Recently Used)**: Evicts items not accessed recently
- **LFU (Least Frequently Used)**: Evicts items with lowest access count
- **FIFO (First In, First Out)**: Evicts oldest items first
- **TTL (Time To Live)**: Automatic expiration based on time

### Indexing System

**Multi-Dimensional Indexing:**
```typescript
class MemoryIndexer {
  private indexes: {
    category: Map<string, Set<string>>;
    tags: Map<string, Set<string>>;
    namespace: Map<string, Set<string>>;
    timestamp: TreeMap<number, Set<string>>;
    vector: VectorIndex;
  };

  private vectorIndex: {
    embeddings: Map<string, number[]>;
    index: HNSWIndex; // Hierarchical Navigable Small World
  };
}
```

**Vector Search Implementation:**
- HNSW (Hierarchical Navigable Small World) for efficient similarity search
- Cosine similarity for semantic matching
- Configurable embedding dimensions (default: 1536 for OpenAI)
- Batch processing for embedding generation

### Conflict Resolution (CRDT)

**Vector Clock Implementation:**
```typescript
interface VectorClock {
  [agentId: string]: number;
}

class ConflictResolver {
  // Determine if clock A happened before clock B
  happensBefore(clockA: VectorClock, clockB: VectorClock): boolean {
    let allLessOrEqual = true;
    let atLeastOneLess = false;

    for (const agent in clockB) {
      const a = clockA[agent] || 0;
      const b = clockB[agent] || 0;
      
      if (a > b) return false;
      if (a < b) atLeastOneLess = true;
    }

    return allLessOrEqual && atLeastOneLess;
  }

  // Merge concurrent updates
  merge(itemA: MemoryItem, itemB: MemoryItem): MemoryItem {
    // Custom merge strategies based on field types
    return {
      ...itemA,
      content: this.mergeContent(itemA.content, itemB.content),
      tags: this.mergeTags(itemA.tags, itemB.tags),
      metadata: this.mergeMetadata(itemA.metadata, itemB.metadata),
      version: Math.max(itemA.version, itemB.version) + 1,
      vectorClock: this.mergeVectorClocks(itemA.vectorClock, itemB.vectorClock),
      updated: new Date()
    };
  }
}
```

### Replication Manager

**Distributed Synchronization:**
```typescript
class ReplicationManager {
  private peers: Map<string, PeerConnection>;
  private conflictResolver: ConflictResolver;
  private syncStrategy: SyncStrategy;

  // Synchronization strategies
  private strategies: {
    immediate: ImmediateSyncStrategy;
    batched: BatchedSyncStrategy;
    scheduled: ScheduledSyncStrategy;
  };

  async syncWithPeer(peerId: string): Promise<SyncResult> {
    const peer = this.peers.get(peerId);
    const localState = await this.getLocalState();
    const remoteState = await peer.getState();
    
    return this.reconcile(localState, remoteState);
  }
}
```

### Namespace Management

**Multi-Tenant Isolation:**
```typescript
interface NamespaceConfig {
  id: string;
  name: string;
  description?: string;
  permissions: NamespacePermissions;
  quotas: NamespaceQuotas;
  encryption: EncryptionConfig;
  replication: ReplicationConfig;
}

interface NamespacePermissions {
  read: string[]; // Agent IDs
  write: string[];
  admin: string[];
  public: boolean;
}

class NamespaceManager {
  async createNamespace(config: NamespaceConfig): Promise<void>
  async deleteNamespace(id: string): Promise<void>
  async checkPermission(namespace: string, agent: string, action: string): Promise<boolean>
  async enforceQuotas(namespace: string): Promise<QuotaStatus>
}
```

## Data Flow

### Write Operation Flow

```mermaid
sequenceDiagram
    participant App as Application
    participant MM as MemoryManager
    participant Cache as Cache
    participant Idx as Indexer
    participant BE as Backend
    participant Repl as ReplicationManager

    App->>MM: store(item)
    MM->>MM: generateId()
    MM->>MM: calculateChecksum()
    MM->>Cache: store(item)
    MM->>Idx: index(item)
    MM->>BE: store(item)
    MM->>Repl: propagate(item)
    MM->>App: return item
```

### Query Operation Flow

```mermaid
sequenceDiagram
    participant App as Application
    participant MM as MemoryManager
    participant Cache as Cache
    participant Idx as Indexer
    participant BE as Backend

    App->>MM: query(criteria)
    MM->>Cache: checkCache(criteria)
    alt Cache Hit
        Cache->>MM: return cached results
    else Cache Miss
        MM->>Idx: findCandidates(criteria)
        MM->>BE: retrieve(candidates)
        MM->>Cache: store(results)
    end
    MM->>App: return results
```

## Performance Characteristics

### Time Complexity

| Operation | SQLite Backend | Markdown Backend | Notes |
|-----------|---------------|------------------|-------|
| Store | O(log n) | O(1) | SQLite index updates |
| Retrieve by ID | O(1) | O(1) | Hash table lookup |
| Query by category | O(log n) | O(n) | Index vs scan |
| Full-text search | O(k log n) | O(n) | FTS5 vs grep |
| Vector search | O(k log n) | O(n) | HNSW vs linear |

### Space Complexity

- **SQLite**: ~1.5x original data size (indexes, metadata)
- **Markdown**: ~1.2x original data size (YAML frontmatter)
- **Cache**: Configurable, typically 10-20% of total data
- **Indexes**: ~30-50% of original data size

## Scalability Considerations

### Horizontal Scaling

- **Read Replicas**: Multiple read-only instances
- **Sharding**: Namespace-based partitioning
- **Load Balancing**: Round-robin or weighted routing

### Vertical Scaling

- **Memory**: Larger cache sizes improve performance
- **Storage**: SSD recommended for SQLite backend
- **CPU**: Multi-core benefits indexing and search operations

### Limits

- **SQLite**: ~281TB theoretical, ~140TB practical
- **Markdown**: Limited by filesystem (ext4: 16TB, NTFS: 256TB)
- **Vector Search**: ~10M vectors with reasonable performance
- **Concurrent Users**: ~1000 with proper connection pooling

## Security Architecture

### Encryption

- **At Rest**: AES-256 for sensitive data
- **In Transit**: TLS 1.3 for replication
- **Key Management**: PBKDF2 with salt for key derivation

### Access Control

- **Namespace-level**: Read/write/admin permissions
- **Item-level**: Optional fine-grained access control
- **Audit Logging**: All operations logged with agent ID

### Integrity

- **Checksums**: SHA-256 for data integrity
- **Digital Signatures**: Optional signing for critical data
- **Version Verification**: CRDT vector clocks prevent tampering</doc><doc title="Backends" desc="docs page."># Storage Backends

SPARC Memory Bank supports multiple storage backends, each optimized for different use cases and requirements.

## SQLite Backend

The SQLite backend provides high-performance, ACID-compliant storage with advanced indexing and full-text search capabilities.

### Features

- **ACID Transactions**: Full transaction support with rollback capabilities
- **WAL Mode**: Write-Ahead Logging for better concurrent access
- **FTS5 Search**: Full-text search with ranking and highlighting
- **Vector Storage**: Efficient storage and retrieval of embeddings
- **Connection Pooling**: Multiple concurrent connections
- **Automatic Optimization**: VACUUM and ANALYZE operations

### Configuration

```typescript
const sqliteConfig = {
  backend: 'sqlite',
  storage: {
    path: './memory.db',
    options: {
      // SQLite-specific options
      journalMode: 'WAL',           // WAL, DELETE, TRUNCATE, PERSIST, MEMORY, OFF
      synchronous: 'NORMAL',        // OFF, NORMAL, FULL, EXTRA
      cacheSize: 2000,              // Number of pages in cache
      tempStore: 'MEMORY',          // MEMORY, FILE, DEFAULT
      mmapSize: 268435456,          // Memory-mapped I/O size (256MB)
      pageSize: 4096,               // Database page size
      autoVacuum: 'INCREMENTAL',    // NONE, FULL, INCREMENTAL
      foreignKeys: true,            // Enable foreign key constraints
      
      // Connection pool settings
      maxConnections: 10,           // Maximum concurrent connections
      idleTimeout: 60000,           // Idle connection timeout (ms)
      busyTimeout: 30000,           // Busy timeout (ms)
      
      // Full-text search settings
      ftsTokenizer: 'unicode61',    // Tokenizer for FTS5
      ftsRankFunction: 'bm25',      // Ranking function
      
      // Performance tuning
      enableWalCheckpoint: true,    // Automatic WAL checkpointing
      walCheckpointInterval: 300000, // Checkpoint interval (5 minutes)
      pragmaOptimize: true,         // Run PRAGMA optimize periodically
    }
  }
};
```

### Schema Design

The SQLite backend uses an optimized schema for memory storage:

```sql
-- Main table for memory items
CREATE TABLE memory_items (
    id TEXT PRIMARY KEY NOT NULL,
    category TEXT NOT NULL,
    content TEXT NOT NULL,
    tags TEXT NOT NULL, -- JSON array
    namespace TEXT,
    metadata TEXT, -- JSON object
    embedding BLOB, -- Vector data as binary
    version INTEGER NOT NULL DEFAULT 1,
    vector_clock TEXT NOT NULL, -- JSON object
    created INTEGER NOT NULL, -- Unix timestamp
    updated INTEGER NOT NULL, -- Unix timestamp
    checksum TEXT NOT NULL,
    
    -- Constraints
    CHECK (version > 0),
    CHECK (created > 0),
    CHECK (updated >= created),
    CHECK (length(checksum) = 64) -- SHA-256 hex
);

-- Indexes for optimal query performance
CREATE INDEX idx_memory_category ON memory_items(category);
CREATE INDEX idx_memory_namespace ON memory_items(namespace);
CREATE INDEX idx_memory_created ON memory_items(created DESC);
CREATE INDEX idx_memory_updated ON memory_items(updated DESC);
CREATE INDEX idx_memory_version ON memory_items(version);
CREATE INDEX idx_memory_category_namespace ON memory_items(category, namespace);

-- JSON indexes for metadata queries (SQLite 3.45+)
CREATE INDEX idx_memory_metadata_status ON memory_items(json_extract(metadata, '$.status'));
CREATE INDEX idx_memory_metadata_priority ON memory_items(json_extract(metadata, '$.priority'));

-- Full-text search virtual table
CREATE VIRTUAL TABLE memory_fts USING fts5(
    content,
    tags,
    category,
    
    -- Configuration
    content='memory_items',
    content_rowid='rowid',
    tokenize='unicode61 remove_diacritics 2'
);

-- Triggers to maintain FTS index
CREATE TRIGGER memory_fts_insert AFTER INSERT ON memory_items
BEGIN
    INSERT INTO memory_fts(rowid, content, tags, category)
    VALUES (NEW.rowid, NEW.content, NEW.tags, NEW.category);
END;

CREATE TRIGGER memory_fts_update AFTER UPDATE ON memory_items
BEGIN
    UPDATE memory_fts
    SET content = NEW.content, tags = NEW.tags, category = NEW.category
    WHERE rowid = NEW.rowid;
END;

CREATE TRIGGER memory_fts_delete AFTER DELETE ON memory_items
BEGIN
    DELETE FROM memory_fts WHERE rowid = OLD.rowid;
END;

-- Vector similarity functions (requires sqlite-vss extension)
CREATE VIRTUAL TABLE IF NOT EXISTS memory_vectors USING vss0(
    embedding(1536), -- OpenAI embedding dimensions
    metadata TEXT
);
```

### Performance Characteristics

| Operation | Time Complexity | Notes |
|-----------|----------------|-------|
| Store | O(log n) | Index updates |
| Retrieve by ID | O(1) | Primary key lookup |
| Query by category | O(log n) | Index scan |
| Full-text search | O(k log n) | FTS5 with ranking |
| Vector search | O(k log n) | With vss extension |
| Batch operations | O(n log n) | Transaction batching |

### Optimization Tips

```typescript
// Enable performance monitoring
const memory = new MemoryManager({
  backend: 'sqlite',
  storage: {
    path: './optimized.db',
    options: {
      // Optimize for read-heavy workloads
      journalMode: 'WAL',
      synchronous: 'NORMAL',
      cacheSize: 10000, // Larger cache
      mmapSize: 1073741824, // 1GB memory mapping
      
      // Connection pooling for concurrent access
      maxConnections: 20,
      
      // Regular maintenance
      pragmaOptimize: true,
      enableWalCheckpoint: true,
      walCheckpointInterval: 60000 // More frequent checkpoints
    }
  }
});

// Monitor query performance
const stats = await memory.getStatistics();
if (stats.performance.averageQueryTime > 50) {
  console.warn('Consider adding indexes or optimizing queries');
}
```

## Markdown Backend

The Markdown backend provides human-readable storage with git integration for version control and collaboration.

### Features

- **Human-Readable**: Files can be edited directly in any text editor
- **Git Integration**: Full version control with git repositories
- **Hierarchical Organization**: Directory structure mirrors data organization
- **YAML Frontmatter**: Structured metadata in standard format
- **Cross-Platform**: Works on any filesystem
- **Backup-Friendly**: Easy to backup and restore

### Configuration

```typescript
const markdownConfig = {
  backend: 'markdown',
  storage: {
    path: './memory',
    options: {
      // Directory structure
      useNamespaceDirectories: true,    // Create dirs for namespaces
      useCategoryDirectories: true,     // Create dirs for categories
      useTimeBasedDirectories: true,    // Create YYYY/MM dirs
      
      // File naming
      fileNaming: 'timestamp',          // 'id', 'timestamp', 'slug'
      slugify: true,                    // Create URL-friendly filenames
      maxFilenameLength: 100,           // Truncate long filenames
      
      // Content formatting
      frontmatterFormat: 'yaml',        // 'yaml', 'toml', 'json'
      contentFormat: 'markdown',        // 'markdown', 'text', 'html'
      includeTableOfContents: false,    // Generate TOC
      
      // Git integration
      gitEnabled: true,                 // Enable git operations
      gitAutoCommit: true,              // Auto-commit changes
      gitCommitMessage: 'Update memory: {id}', // Commit message template
      gitBranch: 'main',                // Target branch
      
      // Performance
      cacheDirectory: './.cache',       // Cache parsed files
      watchForChanges: true,            // Watch for external changes
      rebuildIndexInterval: 300000,     // Rebuild index every 5 minutes
      
      // Cleanup
      enableGarbageCollection: true,    // Remove orphaned files
      garbageCollectionInterval: 86400000, // Daily cleanup
    }
  }
};
```

### Directory Structure

The Markdown backend organizes files in a hierarchical structure:

```
memory/
â”œâ”€â”€ namespaces/
â”‚   â”œâ”€â”€ default/
â”‚   â”‚   â”œâ”€â”€ task/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2024/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ implement-auth-system-20240115-143022.md
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ design-database-schema-20240116-091455.md
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ 02/
â”‚   â”‚   â”‚   â””â”€â”€ index.json
â”‚   â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2024/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ auth-patterns-analysis-20240115-102033.md
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.json
â”‚   â”‚   â”‚   â””â”€â”€ index.json
â”‚   â”‚   â””â”€â”€ implementation/
â”‚   â”œâ”€â”€ project-alpha/
â”‚   â”‚   â”œâ”€â”€ task/
â”‚   â”‚   â””â”€â”€ progress/
â”‚   â””â”€â”€ project-beta/
â”œâ”€â”€ .meta/
â”‚   â”œâ”€â”€ vector_clock.json
â”‚   â”œâ”€â”€ checksums.json
â”‚   â”œâ”€â”€ indexes/
â”‚   â”‚   â”œâ”€â”€ category.json
â”‚   â”‚   â”œâ”€â”€ tags.json
â”‚   â”‚   â”œâ”€â”€ namespace.json
â”‚   â”‚   â””â”€â”€ embeddings.bin
â”‚   â””â”€â”€ config.json
â”œâ”€â”€ .cache/
â”‚   â”œâ”€â”€ parsed/
â”‚   â””â”€â”€ indexes/
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### File Format

Each memory item is stored as a Markdown file with YAML frontmatter:

```markdown
---
id: "item_1705329022456_7x8k9n2m"
category: "implementation"
tags:
  - "auth"
  - "jwt"
  - "security"
  - "middleware"
namespace: "project-alpha"
version: 3
vectorClock:
  agent-alice: 2
  agent-bob: 1
created: "2024-01-15T14:30:22.456Z"
updated: "2024-01-15T16:45:33.789Z"
checksum: "sha256:a1b2c3d4e5f6789012345678901234567890abcdef1234567890abcdef123456"
metadata:
  assignee: "alice@company.com"
  priority: "high"
  estimatedHours: 8
  status: "completed"
  codeReviewUrl: "https://github.com/company/project/pull/123"
  testCoverage: 0.85
embedding:
  dimensions: 1536
  model: "text-embedding-ada-002"
  checksum: "md5:1a2b3c4d5e6f7890"
---

# JWT Authentication Middleware Implementation

Implemented a robust JWT authentication middleware for the Express.js application with the following features:

## Features Implemented

- **Token Validation**: Validates JWT tokens using RS256 algorithm
- **Expiration Checking**: Automatically rejects expired tokens
- **Role-Based Access**: Supports role-based authorization
- **Refresh Token Support**: Implements secure token refresh mechanism

## Code Structure

```typescript
interface JWTPayload {
  userId: string;
  email: string;
  roles: string[];
  iat: number;
  exp: number;
}

class AuthMiddleware {
  async validateToken(token: string): Promise<JWTPayload> {
    // Implementation details...
  }
}
```

## Testing

- âœ… Unit tests for token validation
- âœ… Integration tests with Express routes
- âœ… Security penetration testing
- âœ… Performance benchmarking

## Performance Metrics

- Token validation: ~2ms average
- Memory usage: <1MB per 1000 concurrent requests
- CPU usage: <0.1% under normal load

## Next Steps

- [ ] Add support for multiple JWT issuers
- [ ] Implement token blacklisting
- [ ] Add metrics and monitoring
```

### Git Integration

The Markdown backend can automatically manage git operations:

```typescript
// Enable git integration
const gitMemory = new MemoryManager({
  backend: 'markdown',
  storage: {
    path: './memory-repo',
    options: {
      gitEnabled: true,
      gitAutoCommit: true,
      gitCommitMessage: 'Memory update: {category} - {id}',
      gitBranch: 'main'
    }
  }
});

// Operations automatically create git commits
const item = await gitMemory.store({
  category: 'task',
  content: 'New task created'
});
// Creates git commit: "Memory update: task - item_1705329022456_7x8k9n2m"

// Manual git operations
const backend = gitMemory.getBackend();
await backend.gitCommit('Custom commit message');
await backend.gitPush('origin', 'main');
await backend.gitPull('origin', 'main');

// Branch management
await backend.gitCreateBranch('feature/new-memory-structure');
await backend.gitCheckout('feature/new-memory-structure');
await backend.gitMerge('main');
```

### Performance Characteristics

| Operation | Time Complexity | Notes |
|-----------|----------------|-------|
| Store | O(1) | File write + index update |
| Retrieve by ID | O(1) | Direct file read |
| Query by category | O(n) | Directory scan + filtering |
| Full-text search | O(n) | Grep-like text search |
| Vector search | O(n) | Linear search through embeddings |
| Git operations | O(m) | Where m = number of changed files |

### Optimization Tips

```typescript
// Optimize for large datasets
const optimizedMarkdown = new MemoryManager({
  backend: 'markdown',
  storage: {
    path: './large-memory',
    options: {
      // Use time-based directories to avoid large flat structures
      useTimeBasedDirectories: true,
      useCategoryDirectories: true,
      
      // Enable caching for better read performance
      cacheDirectory: './.cache',
      watchForChanges: false, // Disable if no external edits
      
      // Optimize git operations
      gitAutoCommit: false, // Manual commits for batching
      enableGarbageCollection: true,
      
      // Index optimization
      rebuildIndexInterval: 600000, // 10 minutes
    }
  },
  cache: {
    enabled: true,
    maxSize: 100 * 1024 * 1024, // 100MB cache
    strategy: 'lru'
  }
});

// Manual batching for better git performance
const items = [
  { category: 'task', content: 'Task 1' },
  { category: 'task', content: 'Task 2' },
  { category: 'task', content: 'Task 3' }
];

await optimizedMarkdown.storeBatch(items);
await optimizedMarkdown.getBackend().gitCommit('Batch update: 3 new tasks');
```

## Backend Comparison

| Feature | SQLite | Markdown |
|---------|--------|----------|
| **Performance** |
| Read speed | Excellent | Good |
| Write speed | Excellent | Good |
| Query speed | Excellent | Fair |
| Full-text search | Excellent (FTS5) | Good (grep) |
| Vector search | Excellent (with ext) | Fair (linear) |
| **Scalability** |
| Max items | 281 TB | Filesystem limit |
| Concurrent users | Excellent | Good |
| **Features** |
| ACID transactions | Yes | No |
| Human readable | No | Yes |
| Git integration | No | Yes |
| Direct editing | No | Yes |
| **Operational** |
| Backup complexity | Medium | Simple |
| Migration | Medium | Simple |
| Debugging | Medium | Easy |
| Monitoring | Good | Basic |

## Choosing a Backend

### Use SQLite When:

- **Performance is critical**: High-throughput applications
- **Complex queries**: Advanced search and filtering requirements
- **Large datasets**: Millions of memory items
- **Concurrent access**: Multiple agents accessing simultaneously
- **Transactional integrity**: ACID compliance required

### Use Markdown When:

- **Human collaboration**: Teams need to read/edit memories directly
- **Version control**: Git-based workflows and history
- **Transparency**: Auditable, human-readable storage
- **Simple deployment**: No database setup required
- **Documentation**: Memories serve as living documentation

## Hybrid Approach

For some use cases, you might want to use both backends:

```typescript
// Primary storage with SQLite for performance
const primaryMemory = new MemoryManager({
  backend: 'sqlite',
  storage: { path: './primary.db' }
});

// Secondary storage with Markdown for collaboration
const secondaryMemory = new MemoryManager({
  backend: 'markdown',
  storage: { path: './docs' }
});

// Sync important items to both
const importantItem = await primaryMemory.store({
  category: 'architecture-decision',
  content: 'Decision to use microservices architecture',
  tags: ['architecture', 'decision', 'microservices']
});

// Also store in markdown for documentation
await secondaryMemory.store(importantItem);
```

## Custom Backends

You can implement custom backends by implementing the `MemoryBackend` interface:

```typescript
interface MemoryBackend {
  initialize(): Promise<void>;
  close(): Promise<void>;
  store(item: MemoryItem): Promise<void>;
  retrieve(id: string): Promise<MemoryItem | null>;
  query(query: MemoryQuery): Promise<MemoryItem[]>;
  update(id: string, item: MemoryItem): Promise<void>;
  delete(id: string): Promise<boolean>;
  getStatistics(): Promise<BackendStatistics>;
}

// Example: Redis backend for distributed caching
class RedisBackend implements MemoryBackend {
  // Implementation...
}

// Use custom backend
const redisMemory = new MemoryManager({
  backend: new RedisBackend({
    host: 'localhost',
    port: 6379,
    password: 'secret'
  })
});
```</doc><doc title="Configuration" desc="docs page."># Configuration Reference

This document provides a complete reference for configuring the SPARC Memory Bank system.

## Main Configuration

### MemoryConfig Interface

```typescript
interface MemoryConfig {
  // Required: Backend configuration
  backend: 'sqlite' | 'markdown' | MemoryBackend;
  storage: StorageConfig;
  
  // Optional: Feature configurations
  cache?: CacheConfig;
  indexing?: IndexingConfig;
  namespaces?: NamespaceConfig;
  replication?: ReplicationConfig;
  security?: SecurityConfig;
  monitoring?: MonitoringConfig;
  
  // Optional: System settings
  system?: SystemConfig;
}
```

## Backend Configuration

### SQLite Backend

```typescript
interface SQLiteStorageConfig {
  path: string;                         // Database file path
  options?: {
    // SQLite PRAGMA settings
    journalMode?: 'DELETE' | 'TRUNCATE' | 'PERSIST' | 'MEMORY' | 'WAL' | 'OFF';
    synchronous?: 'OFF' | 'NORMAL' | 'FULL' | 'EXTRA';
    cacheSize?: number;                 // Number of pages (default: 2000)
    tempStore?: 'DEFAULT' | 'FILE' | 'MEMORY';
    mmapSize?: number;                  // Memory-mapped I/O size in bytes
    pageSize?: number;                  // Database page size (512-65536)
    autoVacuum?: 'NONE' | 'FULL' | 'INCREMENTAL';
    foreignKeys?: boolean;              // Enable foreign key constraints
    secureDelete?: boolean;             // Secure deletion of data
    
    // Connection management
    maxConnections?: number;            // Max concurrent connections (default: 10)
    idleTimeout?: number;               // Idle connection timeout in ms
    busyTimeout?: number;               // Busy timeout in ms (default: 30000)
    retryAttempts?: number;             // Connection retry attempts
    
    // Performance tuning
    enableWalCheckpoint?: boolean;      // Automatic WAL checkpointing
    walCheckpointInterval?: number;     // Checkpoint interval in ms
    walCheckpointPages?: number;        // Pages before checkpoint
    pragmaOptimize?: boolean;           // Run PRAGMA optimize
    optimizeInterval?: number;          // Optimize interval in ms
    
    // Full-text search
    ftsTokenizer?: 'simple' | 'porter' | 'unicode61' | 'ascii';
    ftsRankFunction?: 'bm25' | 'okapi';
    ftsRemoveDiacritics?: boolean;
    
    // Extensions
    loadExtensions?: string[];          // SQLite extension paths
    enableVectorSearch?: boolean;       // Load vector search extension
    
    // Backup and recovery
    backupInterval?: number;            // Automatic backup interval
    backupRetention?: number;           // Number of backups to keep
    pointInTimeRecovery?: boolean;      // Enable WAL-based recovery
    
    // Debugging
    logQueries?: boolean;               // Log SQL queries
    queryTimeout?: number;              // Query timeout in ms
    explainQueryPlan?: boolean;         // Log query plans
  };
}

// Example SQLite configuration
const sqliteConfig: MemoryConfig = {
  backend: 'sqlite',
  storage: {
    path: './data/memory.db',
    options: {
      journalMode: 'WAL',
      synchronous: 'NORMAL',
      cacheSize: 10000,
      mmapSize: 268435456, // 256MB
      maxConnections: 20,
      enableWalCheckpoint: true,
      walCheckpointInterval: 300000, // 5 minutes
      pragmaOptimize: true,
      ftsTokenizer: 'unicode61',
      loadExtensions: ['./extensions/vector.so'],
      enableVectorSearch: true
    }
  }
};
```

### Markdown Backend

```typescript
interface MarkdownStorageConfig {
  path: string;                         // Root directory path
  options?: {
    // Directory structure
    useNamespaceDirectories?: boolean;  // Create namespace subdirectories
    useCategoryDirectories?: boolean;   // Create category subdirectories
    useTimeBasedDirectories?: boolean;  // Create YYYY/MM subdirectories
    maxDirectoryDepth?: number;         // Maximum directory nesting
    
    // File naming
    fileNaming?: 'id' | 'timestamp' | 'slug' | 'custom';
    customNamingFunction?: (item: MemoryItem) => string;
    slugify?: boolean;                  // Create URL-friendly filenames
    maxFilenameLength?: number;         // Maximum filename length
    fileExtension?: string;             // File extension (default: '.md')
    
    // Content formatting
    frontmatterFormat?: 'yaml' | 'toml' | 'json';
    contentFormat?: 'markdown' | 'text' | 'html';
    includeTableOfContents?: boolean;   // Generate TOC
    includeMetadata?: boolean;          // Include metadata in content
    wordWrap?: number;                  // Word wrap column
    
    // Markdown options
    markdownOptions?: {
      gfm?: boolean;                    // GitHub Flavored Markdown
      breaks?: boolean;                 // Convert line breaks to <br>
      linkify?: boolean;                // Auto-link URLs
      typographer?: boolean;            // Smart quotes and dashes
      highlight?: (code: string, lang: string) => string; // Code highlighting
    };
    
    // Git integration
    gitEnabled?: boolean;               // Enable git operations
    gitAutoCommit?: boolean;            // Auto-commit changes
    gitCommitMessage?: string;          // Commit message template
    gitBranch?: string;                 // Target branch
    gitRemote?: string;                 // Remote repository
    gitAuthor?: {
      name: string;
      email: string;
    };
    gitIgnorePatterns?: string[];       // Additional .gitignore patterns
    
    // Performance
    cacheDirectory?: string;            // Cache directory for parsed files
    cacheParsedFiles?: boolean;         // Cache parsed frontmatter
    watchForChanges?: boolean;          // Watch for external file changes
    rebuildIndexInterval?: number;      // Index rebuild interval
    
    // Maintenance
    enableGarbageCollection?: boolean;  // Remove orphaned files
    garbageCollectionInterval?: number; // GC interval in ms
    validateChecksums?: boolean;        // Validate file integrity
    
    // Import/Export
    exportFormats?: string[];           // Supported export formats
    importFormats?: string[];           // Supported import formats
    
    // Templates
    itemTemplate?: string;              // Template for new items
    categoryTemplates?: Record<string, string>; // Category-specific templates
  };
}

// Example Markdown configuration
const markdownConfig: MemoryConfig = {
  backend: 'markdown',
  storage: {
    path: './memory-docs',
    options: {
      useNamespaceDirectories: true,
      useCategoryDirectories: true,
      useTimeBasedDirectories: true,
      fileNaming: 'slug',
      slugify: true,
      maxFilenameLength: 100,
      frontmatterFormat: 'yaml',
      contentFormat: 'markdown',
      gitEnabled: true,
      gitAutoCommit: true,
      gitCommitMessage: 'Memory update: {category}/{id}',
      gitBranch: 'main',
      cacheDirectory: './.cache',
      watchForChanges: true,
      enableGarbageCollection: true
    }
  }
};
```

## Cache Configuration

```typescript
interface CacheConfig {
  enabled: boolean;                     // Enable caching
  maxSize: number;                      // Maximum cache size in bytes
  strategy: 'lru' | 'lfu' | 'fifo' | 'ttl' | 'adaptive';
  
  // TTL settings
  ttl?: number;                         // Default TTL in milliseconds
  maxTtl?: number;                      // Maximum TTL
  checkInterval?: number;               // TTL check interval
  
  // Strategy-specific settings
  lru?: {
    maxAge?: number;                    // Maximum age for LRU items
  };
  lfu?: {
    windowSize?: number;                // Frequency calculation window
    decayFactor?: number;               // Frequency decay factor
  };
  adaptive?: {
    learningRate?: number;              // Adaptation learning rate
    performanceThreshold?: number;      // Performance threshold for strategy switching
  };
  
  // Performance settings
  preallocation?: number;               // Pre-allocate cache slots
  compressionEnabled?: boolean;         // Compress cached items
  compressionThreshold?: number;        // Compression size threshold
  
  // Monitoring
  enableMetrics?: boolean;              // Enable cache metrics
  metricsInterval?: number;             // Metrics collection interval
  logEvictions?: boolean;               // Log cache evictions
}

// Example cache configurations
const performanceCache: CacheConfig = {
  enabled: true,
  maxSize: 500 * 1024 * 1024, // 500MB
  strategy: 'adaptive',
  ttl: 3600000, // 1 hour
  adaptive: {
    learningRate: 0.1,
    performanceThreshold: 100 // ms
  },
  compressionEnabled: true,
  compressionThreshold: 1024, // 1KB
  enableMetrics: true
};

const memoryConstrainedCache: CacheConfig = {
  enabled: true,
  maxSize: 50 * 1024 * 1024, // 50MB
  strategy: 'lfu',
  lfu: {
    windowSize: 1000,
    decayFactor: 0.95
  },
  compressionEnabled: true,
  enableMetrics: false
};
```

## Indexing Configuration

```typescript
interface IndexingConfig {
  enabled: boolean;                     // Enable advanced indexing
  
  // Search capabilities
  vectorSearch?: VectorSearchConfig;
  fullTextSearch?: FullTextSearchConfig;
  
  // Index management
  rebuildInterval?: number;             // Automatic rebuild interval
  incrementalUpdates?: boolean;         // Use incremental index updates
  backgroundRebuild?: boolean;          // Rebuild indexes in background
  
  // Performance
  indexDirectory?: string;              // Directory for index files
  memoryLimit?: number;                 // Memory limit for indexing
  compressionEnabled?: boolean;         // Compress index files
  
  // Custom indexes
  customIndexes?: CustomIndexConfig[];
}

interface VectorSearchConfig {
  enabled: boolean;
  dimensions: number;                   // Embedding dimensions
  algorithm: 'hnsw' | 'ivf' | 'brute-force';
  
  // HNSW parameters
  hnsw?: {
    m: number;                          // Number of connections
    efConstruction: number;             // Construction parameter
    efSearch: number;                   // Search parameter
    maxM: number;                       // Maximum connections
    maxM0: number;                      // Maximum connections for layer 0
  };
  
  // IVF parameters
  ivf?: {
    nlist: number;                      // Number of clusters
    nprobe: number;                     // Number of clusters to search
  };
  
  // Embedding service
  embeddingService?: EmbeddingServiceConfig;
  
  // Similarity settings
  defaultThreshold: number;             // Default similarity threshold
  similarityMetric: 'cosine' | 'euclidean' | 'dot-product';
  
  // Performance
  batchSize: number;                    // Embedding batch size
  concurrency: number;                  // Concurrent embedding requests
  cacheEmbeddings: boolean;             // Cache generated embeddings
}

interface FullTextSearchConfig {
  enabled: boolean;
  language: string;                     // Language for stemming
  
  // Tokenization
  tokenizer: 'standard' | 'keyword' | 'pattern' | 'custom';
  stopWords: string[];                  // Stop words to ignore
  stemming: boolean;                    // Enable stemming
  
  // Indexing
  fields: string[];                     // Fields to index
  boost: Record<string, number>;        // Field boost factors
  
  // Search options
  fuzzySearch: boolean;                 // Enable fuzzy matching
  fuzzyDistance: number;                // Maximum edit distance
  phraseSlop: number;                   // Phrase search sloppiness
  
  // Performance
  maxClauseCount: number;               // Maximum query clauses
  analyzeWildcard: boolean;             // Analyze wildcard queries
}

interface EmbeddingServiceConfig {
  provider: 'openai' | 'huggingface' | 'local' | 'custom';
  
  // OpenAI configuration
  openai?: {
    apiKey: string;
    model: string;                      // e.g., 'text-embedding-ada-002'
    maxTokens: number;
    requestsPerMinute: number;
  };
  
  // Hugging Face configuration
  huggingface?: {
    apiKey?: string;
    model: string;
    endpoint?: string;
  };
  
  // Local service configuration
  local?: {
    endpoint: string;
    timeout: number;
    retries: number;
  };
  
  // Custom service
  custom?: {
    generateEmbedding: (text: string) => Promise<number[]>;
  };
}

// Example indexing configuration
const advancedIndexing: IndexingConfig = {
  enabled: true,
  vectorSearch: {
    enabled: true,
    dimensions: 1536,
    algorithm: 'hnsw',
    hnsw: {
      m: 16,
      efConstruction: 200,
      efSearch: 100,
      maxM: 16,
      maxM0: 32
    },
    embeddingService: {
      provider: 'openai',
      openai: {
        apiKey: process.env.OPENAI_API_KEY!,
        model: 'text-embedding-ada-002',
        maxTokens: 8000,
        requestsPerMinute: 1000
      }
    },
    defaultThreshold: 0.7,
    similarityMetric: 'cosine',
    batchSize: 100,
    concurrency: 5,
    cacheEmbeddings: true
  },
  fullTextSearch: {
    enabled: true,
    language: 'english',
    tokenizer: 'standard',
    stopWords: ['the', 'a', 'an', 'and', 'or', 'but'],
    stemming: true,
    fields: ['content', 'tags'],
    boost: {
      content: 1.0,
      tags: 2.0
    },
    fuzzySearch: true,
    fuzzyDistance: 2
  },
  rebuildInterval: 3600000, // 1 hour
  incrementalUpdates: true,
  backgroundRebuild: true
};
```

## Namespace Configuration

```typescript
interface NamespaceConfig {
  enabled: boolean;                     // Enable namespace isolation
  defaultNamespace: string;             // Default namespace name
  
  // Access control
  permissions?: NamespacePermissions;
  enforcePermissions?: boolean;         // Enforce permission checks
  
  // Quotas and limits
  quotas?: NamespaceQuotas;
  enforceQuotas?: boolean;              // Enforce quota limits
  
  // Isolation settings
  strictIsolation?: boolean;            // Prevent cross-namespace access
  allowGlobalSearch?: boolean;          // Allow search across namespaces
  inheritPermissions?: boolean;         // Inherit parent namespace permissions
}

interface NamespacePermissions {
  [namespace: string]: {
    read: string[];                     // Agent IDs with read access
    write: string[];                    // Agent IDs with write access
    admin: string[];                    // Agent IDs with admin access
    public?: boolean;                   // Allow public read access
    inherit?: string;                   // Inherit from parent namespace
  };
}

interface NamespaceQuotas {
  [namespace: string]: {
    maxItems?: number;                  // Maximum number of items
    maxStorage?: number;                // Maximum storage in bytes
    maxEmbeddings?: number;             // Maximum vector embeddings
    dailyWrites?: number;               // Daily write limit
    dailyReads?: number;                // Daily read limit
  };
}

// Example namespace configuration
const namespaceConfig: NamespaceConfig = {
  enabled: true,
  defaultNamespace: 'default',
  permissions: {
    'public': {
      read: ['*'],
      write: ['admin'],
      admin: ['admin'],
      public: true
    },
    'project-alpha': {
      read: ['alice', 'bob', 'charlie'],
      write: ['alice', 'bob'],
      admin: ['alice']
    },
    'sensitive': {
      read: ['admin', 'security-team'],
      write: ['admin'],
      admin: ['admin']
    }
  },
  quotas: {
    'project-alpha': {
      maxItems: 10000,
      maxStorage: 100 * 1024 * 1024, // 100MB
      dailyWrites: 1000
    },
    'development': {
      maxItems: 1000,
      maxStorage: 10 * 1024 * 1024,  // 10MB
      dailyWrites: 100
    }
  },
  enforcePermissions: true,
  enforceQuotas: true,
  strictIsolation: false,
  allowGlobalSearch: true
};
```

## Security Configuration

```typescript
interface SecurityConfig {
  // Encryption at rest
  encryption?: {
    enabled: boolean;
    algorithm: 'aes-256-gcm' | 'aes-256-cbc' | 'chacha20-poly1305';
    keyDerivation: 'pbkdf2' | 'scrypt' | 'argon2';
    keyDerivationOptions?: {
      iterations?: number;              // PBKDF2 iterations
      memory?: number;                  // Scrypt/Argon2 memory cost
      parallelism?: number;             // Argon2 parallelism
      saltLength?: number;              // Salt length in bytes
    };
    rotateKeys?: boolean;               // Enable key rotation
    keyRotationInterval?: number;       // Key rotation interval
  };
  
  // Data integrity
  checksums?: {
    enabled: boolean;
    algorithm: 'sha256' | 'sha512' | 'blake3';
    verifyOnRead: boolean;              // Verify checksums on read
    repairCorruption: boolean;          // Attempt to repair corruption
  };
  
  // Access control
  authentication?: {
    enabled: boolean;
    method: 'token' | 'certificate' | 'custom';
    tokenConfig?: {
      algorithm: 'HS256' | 'RS256' | 'ES256';
      secretOrKey: string | Buffer;
      expiresIn: string;
    };
    certificateConfig?: {
      ca: string;                       // CA certificate path
      cert: string;                     // Client certificate path
      key: string;                      // Client key path
    };
  };
  
  // Audit logging
  auditLog?: {
    enabled: boolean;
    level: 'minimal' | 'standard' | 'verbose';
    destination: 'file' | 'database' | 'syslog' | 'custom';
    logFile?: string;
    rotateSize?: number;                // Log rotation size
    retentionDays?: number;             // Log retention period
    includeData?: boolean;              // Include operation data
  };
  
  // Rate limiting
  rateLimiting?: {
    enabled: boolean;
    globalLimit?: number;               // Global operations per second
    perAgentLimit?: number;             // Per-agent operations per second
    burstAllowance?: number;            // Burst allowance
    windowSize?: number;                // Rate limiting window
  };
}

// Example security configuration
const highSecurityConfig: SecurityConfig = {
  encryption: {
    enabled: true,
    algorithm: 'aes-256-gcm',
    keyDerivation: 'argon2',
    keyDerivationOptions: {
      memory: 65536,      // 64MB
      iterations: 3,
      parallelism: 1,
      saltLength: 32
    },
    rotateKeys: true,
    keyRotationInterval: 30 * 24 * 60 * 60 * 1000 // 30 days
  },
  checksums: {
    enabled: true,
    algorithm: 'blake3',
    verifyOnRead: true,
    repairCorruption: false
  },
  authentication: {
    enabled: true,
    method: 'certificate',
    certificateConfig: {
      ca: './certs/ca.pem',
      cert: './certs/client.pem',
      key: './certs/client.key'
    }
  },
  auditLog: {
    enabled: true,
    level: 'verbose',
    destination: 'file',
    logFile: './logs/audit.log',
    rotateSize: 100 * 1024 * 1024, // 100MB
    retentionDays: 90,
    includeData: false
  },
  rateLimiting: {
    enabled: true,
    globalLimit: 1000,
    perAgentLimit: 100,
    burstAllowance: 50,
    windowSize: 60000 // 1 minute
  }
};
```

## Environment Variables

Many configuration options can be set via environment variables:

```bash
# Backend configuration
MEMORY_BACKEND=sqlite
MEMORY_STORAGE_PATH=./data/memory.db

# Cache configuration
MEMORY_CACHE_ENABLED=true
MEMORY_CACHE_SIZE=100MB
MEMORY_CACHE_STRATEGY=lru

# Security configuration
MEMORY_ENCRYPTION_ENABLED=true
MEMORY_ENCRYPTION_KEY=your-encryption-key

# OpenAI configuration
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=text-embedding-ada-002

# Git configuration
GIT_AUTHOR_NAME="SPARC Memory Agent"
GIT_AUTHOR_EMAIL="memory@sparc.ai"

# Performance tuning
MEMORY_MAX_CONNECTIONS=20
MEMORY_QUERY_TIMEOUT=30000
MEMORY_CACHE_TTL=3600000
```

## Configuration Validation

The system includes comprehensive configuration validation:

```typescript
import { validateConfig } from '@sparc/memory-bank';

try {
  const config = {
    backend: 'sqlite',
    storage: {
      path: './memory.db',
      options: {
        maxConnections: -1  // Invalid value
      }
    }
  };
  
  const validatedConfig = validateConfig(config);
} catch (error) {
  console.error('Configuration validation failed:', error.message);
  // Error: maxConnections must be a positive integer
}
```

## Configuration Profiles

Pre-defined configuration profiles for common use cases:

```typescript
import { 
  createDevelopmentConfig,
  createProductionConfig,
  createHighPerformanceConfig,
  createHighSecurityConfig 
} from '@sparc/memory-bank/profiles';

// Development profile
const devConfig = createDevelopmentConfig({
  storagePath: './dev-memory.db'
});

// Production profile
const prodConfig = createProductionConfig({
  storagePath: '/var/lib/memory/prod.db',
  encryptionKey: process.env.ENCRYPTION_KEY
});

// High-performance profile
const perfConfig = createHighPerformanceConfig({
  storagePath: './perf-memory.db',
  cacheSize: '1GB',
  maxConnections: 50
});

// High-security profile
const secureConfig = createHighSecurityConfig({
  storagePath: './secure-memory.db',
  encryptionKey: process.env.ENCRYPTION_KEY,
  auditLogPath: './audit.log'
});
```</doc><doc title="Changelog" desc="reference page."># Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [2.0.0-alpha.91] - 2025-08-21

> **ğŸš€ Claude Code Task Tool Integration Update**: Enhanced integration with Claude Code's Task tool for concurrent agent execution. Clear separation between MCP coordination tools and Claude Code's execution capabilities, with comprehensive documentation and examples for parallel agent spawning.

### âœ¨ New Features

#### ğŸ¯ Claude Code Task Tool Integration
- **Enhanced CLAUDE.md Templates**: Updated initialization templates with clear guidance
  - Explicit instructions that Claude Code's Task tool spawns agents for actual work
  - MCP tools clearly marked as coordination-only, not for execution
  - Step-by-step workflow: Optional MCP setup â†’ Required Task tool execution
  - Comprehensive examples of concurrent agent spawning patterns

- **Improved Swarm Prompts**: Updated swarm command prompts for better clarity
  - Prominent header emphasizing Task tool usage for agent execution
  - Clear visual separation between coordination and execution tools
  - Concrete examples showing ALL agents spawned in ONE message
  - Warning boxes highlighting critical concurrent execution patterns

- **Enhanced Hive Mind Prompts**: Restructured hive-mind spawn prompts
  - Three-step process clearly documented in prompts
  - Step 1: Optional MCP coordination setup
  - Step 2: REQUIRED Claude Code Task tool for agent spawning
  - Step 3: Batch ALL todos in single TodoWrite call (8-10 todos)

#### ğŸ“‹ Batch Operation Emphasis
- **TodoWrite Batching**: Strong emphasis on batching 5-10+ todos in ONE call
  - Clear examples showing proper todo batching patterns
  - Visual warnings against sequential todo updates
  - Concrete todo examples with priorities and statuses

- **Task Tool Concurrency**: Comprehensive examples of parallel agent execution
  - Full-stack development swarm examples (6-8 agents)
  - Research coordination patterns
  - Distributed system agent spawning
  - All with proper coordination hooks

#### ğŸ“š Documentation Improvements
- **Clear Separation of Concerns**:
  - âœ… Claude Code handles: Task tool, file operations, code generation, execution
  - âŒ MCP tools handle: Coordination setup, memory, performance tracking only
  - Visual formatting with emojis and boxes for clarity

- **Concrete Code Examples**:
  ```javascript
  // CORRECT Pattern - Single Message
  Task("Researcher", "Analyze patterns...", "researcher")
  Task("Coder", "Implement features...", "coder")
  Task("Tester", "Create tests...", "tester")
  TodoWrite { todos: [8-10 todos ALL in ONE call] }
  ```

### ğŸ”§ Technical Improvements

#### Prompt Generation Updates
- **generateHiveMindPrompt()**: Restructured to emphasize Task tool usage
  - Added getWorkerTypeInstructions() integration for agent-specific guidance
  - Clear step-by-step execution protocol
  - Visual examples of concurrent patterns

- **Swarm Prompt Updates**: Enhanced swarm initialization guidance
  - Separated MCP coordination from Task execution
  - Added critical execution reminders
  - Updated batch operation examples

### ğŸ“ˆ Version Updates
- Updated version to `2.0.0-alpha.91` across all files
- Updated `package.json`, `version.js`, `version.ts`
- New release notes in `--version` command output

### ğŸ“ Files Modified

#### Core Files Updated
- `src/cli/simple-commands/init/templates/claude-md.js` - CLAUDE.md template generation
- `src/cli/simple-commands/hive-mind.js` - generateHiveMindPrompt() function
- `src/cli/simple-commands/swarm.js` - swarm prompt generation
- `package.json` - Version bump to 2.0.0-alpha.91
- `src/core/version.js` - Fallback version update
- `src/core/version.ts` - TypeScript version update
- `bin/claude-flow.js` - Version display and release notes

### ğŸ› ï¸ Command Documentation Improvements

#### Complete Command File Generation
- **Fixed Init Command**: Now creates ALL 91 command documentation files
  - 10 swarm command files in `.claude/commands/swarm/`
  - 12 hive-mind command files in `.claude/commands/hive-mind/`
  - 5 agents documentation files in `.claude/commands/agents/`
  - All standard command documentation properly organized

- **Enhanced Template Structure**: Updated `enhanced-templates.js`
  - Added complete COMMAND_STRUCTURE with swarm, hive-mind, and agents categories
  - Comprehensive fallback documentation for all missing command files
  - Proper emphasis on Task tool usage in all agent-related docs

### ğŸ“ File Organization Rules
- **Never save to root folder**: All files properly organized in subdirectories
- Clear directory structure guidance in CLAUDE.md
- Proper organization for `/src`, `/tests`, `/docs`, `/config` directories

### ğŸ¯ Key Takeaways for Users

1. **Always use Claude Code's Task tool** to spawn agents that do actual work
2. **MCP tools are ONLY** for coordination setup, not execution
3. **Batch everything**: Spawn ALL agents in ONE message
4. **TodoWrite must batch**: Always include 5-10+ todos in ONE call
5. **Use coordination hooks**: Every agent must use claude-flow hooks
6. **Proper file organization**: Never save files to root directory

This release ensures users understand the critical distinction between:
- **MCP tools**: Coordinate and plan (the "brain")
- **Claude Code Task tool**: Execute and implement (the "hands")

## [2.0.0-alpha.90] - 2025-08-16

> **ğŸš€ Major MCP Implementation & Quality Update**: Delivered >95% functionality with 15+ real MCP tools, critical bug fixes, WASM neural networks, and reduced mock rate from 40% to <5%. This release represents our commitment to community feedback and real, working tools.

### âœ¨ New Features

#### ğŸ¯ Real MCP Tool Implementations
- **DAA Tools (6 tools)**: Complete Decentralized Autonomous Agent suite
  - `daa_agent_create` - Dynamic agent creation with unique ID tracking
  - `daa_capability_match` - Real capability scoring algorithm implementation
  - `daa_resource_alloc` - CPU/memory resource distribution system
  - `daa_lifecycle_manage` - Full state machine (created â†’ active â†’ idle â†’ terminated)
  - `daa_communication` - Inter-agent messaging with delivery confirmation
  - `daa_consensus` - Voting mechanism with configurable thresholds

- **Workflow Automation (6 tools)**: Complete workflow engine
  - `workflow_create` - Workflow storage with step dependencies
  - `workflow_execute` - Real execution tracking with status updates
  - `parallel_execute` - Concurrent task management using Promise.all
  - `batch_process` - Batch operation processing with configurable sizes
  - `workflow_export` - JSON/YAML export format support
  - `workflow_template` - Template management and retrieval system

- **Performance Monitoring (3 tools)**: Real system metrics
  - `performance_report` - Actual CPU, memory, uptime metrics from OS
  - `bottleneck_analyze` - Real bottleneck detection algorithms
  - `memory_analytics` - Process memory usage from process.memoryUsage()

#### ğŸ§  WASM Neural Networks
- **Real WebAssembly Integration**: Discovered and integrated actual WASM modules
  - `ruv-fann.wasm` - Fast Artificial Neural Network engine
  - `ruv_swarm_simd.wasm` - SIMD-optimized operations
  - `neuro-divergent.wasm` - Cognitive pattern processing
  - Not simulations - actual neural network processing capabilities

#### ğŸ“Š Agent Tracking System
- **Centralized Agent Registry**: New `agent-tracker.js` implementation
  - Real agent storage and retrieval
  - Persistent tracking across operations
  - Fixed `agent_list` to return actual tracked agents
  - Fixed `agent_metrics` to show real performance data

### ğŸ› Bug Fixes

#### Critical Runtime Errors Fixed
- **agent_metrics**: Fixed `neuralNetworks.map is not a function` error
  - Added type safety wrapper ensuring neuralNetworks is always an array
  - Proper initialization of neural network data structures

- **swarm_monitor**: Fixed `recentEvents.map is not a function` error
  - Initialized recentEvents as empty array with type checking
  - Added proper event queue management

- **neural_train**: Fixed parameter validation errors
  - Corrected parameter naming (pattern_type â†’ patternType)
  - Added comprehensive input validation

#### MCP Routing Fixes
- **Fixed 9 tools falling through**: Workflow and performance tools now route correctly
- **Proper error handling**: When managers not initialized
- **Response consistency**: All tools return consistent format

### ğŸ”§ Technical Improvements

#### Architecture Enhancements
- **Modular Structure**: New organized implementation directory
  ```
  src/mcp/
  â”œâ”€â”€ implementations/
  â”‚   â”œâ”€â”€ agent-tracker.js
  â”‚   â”œâ”€â”€ daa-tools.js
  â”‚   â””â”€â”€ workflow-tools.js
  â”œâ”€â”€ fixes/
  â”‚   â””â”€â”€ mcp-error-fixes.js
  â””â”€â”€ mcp-server.js
  ```

- **Type Safety**: Added validation for all tool inputs
- **Error Boundaries**: Proper error handling for all operations
- **Response Format**: Consistent JSON responses across all tools

### ğŸ“ˆ Performance Improvements
- **Response Time**: Reduced from 50-100ms to <20ms average
- **Memory Usage**: Stable at ~9.8% (6.5GB of 67GB total)
- **CPU Load**: Low utilization (0.02-0.14 average)
- **Success Rate**: Increased from ~60% to >95%

### ğŸ“Š Quality Metrics

| Category | Working | Mock/Stub | Success Rate |
|----------|---------|-----------|--------------|
| Memory | 10 | 0 | **100%** |
| DAA | 6 | 0 | **100%** |
| Workflow | 6 | 0 | **100%** |
| Performance | 3 | 0 | **100%** |
| Agent/Swarm | 10 | 0 | **100%** |
| Neural | 8 | 0 | **100%** |
| **TOTAL** | **43** | **2** | **>95%** |

### ğŸ™ Acknowledgments
- Community feedback from issues #653, #645, #640
- Contributors: @alexx-ftw, @lanemc
- All alpha testers who provided valuable feedback
- Discord community for continuous support

### ğŸ“¦ Installation
```bash
npm install -g claude-flow@alpha
```

### ğŸ”— Links
- [npm Package](https://www.npmjs.com/package/claude-flow/v/2.0.0-alpha.90)
- [Pull Request #661](https://github.com/ruvnet/claude-flow/pull/661)
- [Issue #660](https://github.com/ruvnet/claude-flow/issues/660)

---

## [2.0.0-alpha.89] - 2025-08-13

> **Highlights**: Working auto-fix implementation for pair programming with real command execution, complete command documentation system, real Claude Code stream chaining with background execution, enhanced help system with emojis, comprehensive pair programming features with guidance modes, and complete removal of simulation mode in training.

### âœ¨ New Features

#### ğŸ”— Stream Chain Command - Real Claude Code Execution
- **Complete Implementation**: Fixed missing `stream-chain` command (Issue #642)
  - Added full command handler in `/src/cli/simple-commands/stream-chain.js`
  - Registered in command registry with all subcommands
  - Implemented `run`, `demo`, `pipeline`, and `test` subcommands
  - Four pipeline types: `analysis`, `refactor`, `test`, `optimize`
  - Full integration with Claude Code's stream-json output format

- **Real Claude Code Integration**: Stream-chain now uses actual Claude Code execution
  - Fixed stream-json format compatibility with Claude Code
  - Proper context preservation between chained steps
  - Extracts assistant responses from stream-json output
  - Transforms output into context for next step
  - Handles system message filtering automatically
  - ~10-30s per step with full context preservation

- **Enhanced Help System**: Comprehensive documentation with emoji formatting
  - Brief help via `--help` with expanded details section
  - Full documentation via `stream-chain help` subcommand
  - Emoji section headers for better readability (ğŸ“š SUBCOMMANDS, âš™ï¸ OPTIONS, etc.)
  - Added pipeline subcommand with 4 predefined workflows:
    - `analysis` - Code analysis and improvement pipeline
    - `refactor` - Automated refactoring workflow
    - `test` - Comprehensive test generation
    - `optimize` - Performance optimization pipeline

- **Working Implementation Details**:
  - Uses `claude -p --output-format stream-json --verbose` for proper execution
  - Context injection via prompts (workaround for `--input-format` limitations)
  - Timeout handling with configurable `--timeout` flag (default 30s)
  - Verbose mode shows command execution and content preview
  - Test suite validates context preservation between steps

#### ğŸ§  Real Training Pipeline
- **Removed Simulation Mode**: Training now exclusively uses real code execution
  - Creates actual JavaScript files with real code
  - Runs real `npm install` and `npm test` commands  
  - Executes actual Jest tests for validation
  - Learns from genuine test results with 0.4 learning rate
  - Shows real improvements in agent performance (~50% success rate achieved)
  - Proper regex escaping in code templates
  - Code restoration after each strategy test

#### âœ… Truth Verification System
- **Production-Ready Implementation**: Based on GitHub Issue #640
  - Truth scoring with 95% accuracy threshold
  - Real-time verification during task execution
  - Git-based rollback mechanism for failed verifications
  - Integration with training pipeline for continuous improvement
  - Verification hooks for agent task validation
  - Dashboard export functionality for metrics
  - Pair programming mode with real-time verification

#### ğŸ‘¥ Pair Programming Features
- **Interactive Pair Programming**: New `pair` command with full documentation
  - Real-time code review and verification
  - Automated truth enforcement
  - Integration testing capabilities
  - Quality gates and thresholds
  - Collaborative development workflow
  - Three collaboration modes: driver, navigator, and switch
  - Session persistence and recovery
  - Background session support
  - Comprehensive metrics tracking

- **Full Interactive Implementation** (Fixed compilation issues):
  - Created standalone `pair.js` replacing verification.js integration
  - Interactive readline interface with 10+ session commands
  - Real verification system running `npm run typecheck`, `lint`, and `build`
  - Actual test execution with `npm test` and result parsing
  - Session commands: `/verify`, `/test`, `/status`, `/metrics`, `/commit`, `/switch`
  - Automatic role switching every 10 minutes in switch mode
  - Verification scoring with configurable thresholds (default 0.95)
  - Test result tracking and coverage monitoring
  - Pre-commit verification gates
  - Session data persistence in `.claude-flow/sessions/pair/`

- **Working Auto-Fix Implementation** (2025-08-13):
  - **Real Fix Application**: Actually applies fixes instead of simulating
    - ESLint auto-fix with `npm run lint -- --fix`
    - Prettier formatting as fallback for style issues
    - Missing TypeScript type definitions installation
    - Security vulnerability fixes with `npm audit fix`
    - Dependency updates with `npm update`
    - Build cache clearing and rebuild on errors
  - **Graduated Scoring**: Based on actual error/warning counts
    - Errors reduce score by 0.1 per error (min 0.2)
    - Warnings reduce score by 0.05 per warning (min 0.7)
    - Accurate reflection of code quality state
  - **Fix History Tracking**: Complete audit trail
    - Records all applied fixes per iteration
    - Shows score improvement over time
    - Tracks which fix types were most effective

- **Enhanced Guidance Modes** (2025-08-13):
  - **Five Expertise Levels**: 
    - `beginner`: Detailed explanations, frequent tips, educational focus
    - `intermediate`: Balanced guidance with key explanations
    - `expert`: Minimal guidance, maximum efficiency
    - `mentor`: Teaching mode with learning opportunities
    - `strict`: Enforces highest quality standards (0.99 threshold)
  - **Interactive Q&A System**: Ask questions with `?` prefix
  - **Contextual Suggestions**: Based on current code state
  - **Best Practices Library**: Per-language recommendations
  - **Pattern Suggestions**: Design pattern recommendations

#### ğŸ“š Command Documentation System
- **Complete Documentation Structure**: Created comprehensive docs in `.claude/commands/`
  - **Stream Chain Documentation** (`/stream-chain/`):
    - `README.md` - Overview with background execution integration
    - `pipeline.md` - Predefined pipeline documentation
    - `run.md` - Custom chain execution guide
    - Background commands approach from wiki integrated
  - **Pair Programming Documentation** (`/pair/`):
    - `README.md` - Complete overview and quick start
    - `start.md` - Starting sessions with all options
    - `modes.md` - Driver, navigator, switch, and specialized modes
    - `session.md` - Session lifecycle and management
    - `config.md` - Full configuration reference
    - `commands.md` - Complete command reference (100+ commands)
    - `examples.md` - 10 real-world scenarios with workflows
  - **Verification Documentation** (`/verify/`):
    - Complete verification system documentation
  - **Truth Metrics Documentation** (`/truth/`):
    - Truth scoring and reliability metrics

### ğŸ› ï¸ Technical Improvements

#### Command System
- **Stream Chain Infrastructure**:
  - Subcommands: `run`, `demo`, `pipeline`, `test`
  - Pipeline types: `analysis`, `refactor`, `test`, `optimize`
  - Stream-JSON format support for context preservation
  - 100% context preservation between agents
  - Sequential execution with configurable timeouts
  - O(1) memory usage via streaming

#### Pair Programming System
- **Performance Optimizations** (2025-08-13):
  - **Resource Usage**: Reduced from 10-17% CPU to <1% idle
    - Removed 30-second verification interval loop
    - Added 60-second cooldown for auto-verify
    - Manual verification control with `/verify` command
  - **Intelligent Fix Chains**: Targeted fix application
    - Only runs fixes for failing checks
    - Parallel fix application where possible
    - Caches verification results between iterations
  - **Guidance Mode Performance**:
    - Expert mode: Minimal overhead, fastest execution
    - Beginner mode: Educational value with reasonable performance
    - Strict mode: Highest quality with 0.99 threshold

#### Training System
- **Real Execution Metrics**:
  - Conservative strategy: 49.9% success, 1909ms avg time
  - Balanced strategy: 50.0% success, 1887ms avg time
  - Aggressive strategy: 50.0% success, 1670ms avg time (fastest)
  - All strategies using 14+ real executions
  - Exponential Moving Average (EMA) learning with 0.4 rate

#### Verification System
- **Comprehensive Verification**:
  - `verify` command with subcommands: `check`, `rollback`, `report`, `dashboard`
  - Truth threshold configuration (default 0.95)
  - Integration with swarm commands via `--verify` flag
  - Automatic rollback on verification failure
  - Performance tracking and reporting

### ğŸ› Bug Fixes

#### Stream Chain Command
- **Issue #642 Resolved**: Stream-chain command was documented but missing
  - Command now fully implemented and registered
  - All subcommands working with proper error handling
  - Background execution properly tracked
  - Monitor and kill commands functional

- **Claude Code Integration Fixed**: Resolved multiple issues with real execution
  - Fixed "Expected message type 'user' got 'system'" error
  - Implemented proper stream-json message filtering
  - Fixed timeout issues with Claude Code execution
  - Resolved `--input-format` and `--output-format` compatibility
  - Working context preservation between chained steps

#### Pair Programming Command
- **Fixed Compilation Errors**: Resolved verification system issues
  - Separated pair command from verification.js to standalone pair.js
  - Fixed infinite compile score 0.50 loop from typecheck failures
  - Removed simulated verification with Math.random()
  - Implemented real npm command execution for verification
  - Added proper error handling for test and build failures

- **Fixed Auto-Fix Issues** (2025-08-13):
  - **Shell Command Execution**: Fixed npm commands with proper escaping
    - Resolved issue where "2" was appended to all commands
    - Fixed stderr redirection with parentheses wrapping
    - Commands now execute correctly: `(npm run lint) 2>&1 || true`
  - **Actual Fix Application**: Auto-fix now performs real fixes
    - Previously just ran verification repeatedly without fixing
    - Now executes `npm run lint -- --fix` for real ESLint fixes
    - Applies Prettier formatting when ESLint can't auto-fix
    - Installs missing @types packages automatically
    - Runs `npm audit fix` for security vulnerabilities
  - **Verification Accuracy**: Scores based on actual output
    - Counts real errors and warnings from command output
    - Graduated scoring: errors -0.1, warnings -0.05
    - Reflects true code quality state

#### Training Pipeline
- **Fixed Simulation Issues**:
  - Removed `Math.random()` simulation that showed 0% improvement
  - Fixed regex escaping issues in generated code
  - Fixed conservative strategy breaking JavaScript syntax
  - Proper error handling for npm test failures
  - Real test results now driving learning

#### Non-Interactive Mode
- **Fixed Argument Injection**: 
  - Corrected command-line argument ordering for non-interactive mode
  - Flags must precede prompt arguments
  - Hive-mind spawn commands now work in CI/CD environments

### ğŸ“š Documentation

#### New Documentation
- **Command Documentation System**: Complete docs in `.claude/commands/`
  - Stream chain with background execution integration
  - Pair programming with 7 comprehensive guides
  - Verification system documentation
  - Truth metrics documentation
  - All commands now have structured documentation

- **Stream Chain Command Wiki**: Created `/claude-flow-wiki/Stream-Chain-Command.md`
  - Complete command reference with all subcommands
  - Background execution guide
  - Performance characteristics
  - Integration with other Claude Flow features
  - Troubleshooting section

- **Training Pipeline Documentation**: `/docs/training-pipeline-real-only.md`
  - Explains shift from simulation to real execution
  - Performance metrics and improvements
  - Task complexity levels
  - Learning mechanisms

- **Performance Validation**: `/workspaces/claude-code-flow/performance-validation.md`
  - Validation of training improvements
  - Agent profile analysis
  - Stream chaining integration

### ğŸ¯ Performance Improvements

#### Stream Chaining
- Latency: <100ms per handoff between agents
- Context preservation: 100% maintained
- Memory usage: O(1) constant via streaming
- Speed: 40-60% faster than file-based approaches

#### Training Pipeline
- Real execution provides genuine performance data
- Strategies converging to ~50% success rate
- Aggressive strategy 12.5% faster than conservative
- Learning effectiveness validated through real tests

### ğŸ”§ Command Updates

#### New Commands
- `stream-chain run` - Execute custom stream chains
- `stream-chain demo` - Run demonstration chain
- `stream-chain pipeline <type>` - Execute predefined pipelines
- `stream-chain test` - Test stream connection
- `stream-chain monitor` - Monitor background chains
- `stream-chain kill <id>` - Terminate background chains
- `verify check` - Run verification checks
- `verify rollback` - Rollback on failure
- `verify report` - Generate verification report
- `pair` - Start pair programming mode

#### Updated Commands
- Training pipeline now real-only (no `--real` flag needed)
- Swarm commands support `--verify` flag
- Non-interactive mode properly handles argument ordering

### ğŸ“¦ Files Changed

#### New Files
- `/src/cli/simple-commands/stream-chain.js` - Stream chain command implementation
- `/src/cli/simple-commands/train-and-stream.js` - Integrated training/streaming
- `/src/cli/simple-commands/pair.js` - Interactive pair programming implementation
- `/claude-flow-wiki/Stream-Chain-Command.md` - Wiki documentation
- `/docs/training-pipeline-real-only.md` - Real training documentation
- `/performance-validation.md` - Performance validation report
- `.claude/commands/stream-chain/README.md` - Stream chain main documentation
- `.claude/commands/stream-chain/pipeline.md` - Pipeline documentation
- `.claude/commands/stream-chain/run.md` - Run command documentation
- `.claude/commands/pair/README.md` - Pair programming overview
- `.claude/commands/pair/start.md` - Starting sessions guide
- `.claude/commands/pair/modes.md` - Collaboration modes guide
- `.claude/commands/pair/session.md` - Session management guide
- `.claude/commands/pair/config.md` - Configuration reference
- `.claude/commands/pair/commands.md` - Command reference
- `.claude/commands/pair/examples.md` - Real-world examples
- `.claude/commands/verify/README.md` - Verification documentation
- `.claude/commands/truth/README.md` - Truth metrics documentation

#### Modified Files
- `/src/cli/command-registry.js` - Updated pair command to use new pair.js
- `/src/cli/simple-commands/training-pipeline.js` - Removed simulation mode
- `/src/cli/simple-commands/verification.js` - Enhanced verification features
- `/.claude-flow/agents/profiles.json` - Updated with real execution metrics
- `/CLAUDE.md` - Updated with stream chain examples
- `/CHANGELOG.md` - Updated with alpha-89 release notes

### ğŸš€ Migration Notes

#### For Existing Users
1. Stream-chain command now available - run `stream-chain help`
2. Training pipeline uses real execution - expect initial slower performance
3. Verification system active - configure thresholds as needed
4. Background chains persist across sessions

#### Breaking Changes
- Training pipeline no longer supports simulation mode
- `--real` flag removed from training commands (always real now)
- Verification may block deployments if threshold not met

### ğŸ“Š Metrics

#### Issue Resolution
- Resolved: #642 (Missing stream-chain command)
- Resolved: #640 (Truth Verification System implementation)
- Fixed: Non-interactive mode argument injection
- Fixed: Training pipeline simulation issues

#### Test Coverage
- Stream chain: All subcommands tested and working
- Training pipeline: 14+ real executions per strategy
- Verification: 95% accuracy threshold validated

## [2.0.0-alpha.88] - 2025-08-11

### âœ¨ New Features
- **Session Persistence Enhancements**: Improved cross-session memory and state management
- **Background Command Improvements**: Enhanced background task management system
- **Wiki Documentation Updates**: Comprehensive documentation for all new features

## [2.0.0-alpha.87] - 2025-08-05

### âœ¨ New Features
- **Centralized Version Management**: Version now reads dynamically from package.json
  - Single source of truth for version numbers
  - Automatic version updates across all CLI commands
  - No more manual version string updates needed
  - Fallback support if package.json can't be read

### ğŸ› Bug Fixes
- **Async/Await Fixes**: Fixed missing await keywords in hive-mind commands
  - Fixed `getActiveSessionsWithProcessInfo()` missing await in stop.ts (lines 24, 90)
  - Fixed `getSession()` missing await in stop.ts (line 57) 
  - Fixed `getSession()` missing await in pause.ts (line 23)
  - Resolves "sessions.forEach is not a function" errors

### ğŸ”§ Improvements
- **Code Organization**: Created centralized version module
  - Added `src/core/version.ts` and `src/core/version.js`
  - Updated all CLI entry points to use centralized version
  - Improved maintainability and consistency

### ğŸ”„ Synced with Main
- Merged all latest changes from main branch
- Includes PR #584 (session resume fix)
- Includes all recent bug fixes and improvements

## [2.0.0-alpha.86] - 2025-08-05

### ğŸ› Bug Fixes
- **Import Alias Fix**: Removed unnecessary `execSyncOriginal` alias in init/index.js (PR #558)
  - Fixed unused import alias that was causing confusion
  - Simplified import statement for better code clarity

### ğŸ”„ Version Updates
- Updated version strings across the codebase to alpha-86
- Updated package.json version
- Updated CLI help text version references
- Updated --version command output

### ğŸ“š Documentation
- Updated CHANGELOG.md with latest release notes

## [2.0.0-alpha.85] - 2025-08-05

### âœ¨ New Features

#### ğŸ” Stream-JSON Chaining
- **Multi-Agent Pipeline Support**: Connect multiple Claude instances using real-time JSON streams
  - Use `--output-format stream-json` and `--input-format stream-json` flags
  - Build modular, recursive, multi-agent pipelines
  - Automatic dependency detection and stream chaining
  - Enables complex workflows: planner â†’ executor â†’ reviewer
  - Support for recursive pipelines and iterative refinement
  - Live feedback systems and task decomposition
  - New `stream-chain` command for easy pipeline creation

#### ğŸ¤– Advanced Automation Capabilities
- **Enhanced Workflow Automation**: Improved automation features for complex tasks
  - Automatic task dependency resolution
  - Intelligent agent spawning based on task requirements
  - Smart parallel execution with resource optimization
  - Enhanced error recovery and retry mechanisms
  - Automated progress tracking and reporting
  - Better integration with CI/CD pipelines

#### ğŸ¯ Improved Swarm Intelligence
- **Smarter Agent Coordination**: Enhanced multi-agent collaboration
  - Automatic topology optimization based on task type
  - Dynamic agent scaling based on workload
  - Improved knowledge sharing between agents
  - Better conflict resolution in parallel tasks
  - Enhanced performance monitoring and bottleneck detection

### ğŸ› ï¸ Technical Improvements
- **Stream Processing**: New stream-json module for efficient data piping
- **Automation Engine**: Enhanced task orchestration with dependency graphs
- **Performance**: Optimized agent communication reducing overhead by 15%
- **Reliability**: Improved error handling in multi-agent scenarios

### ğŸ“š Documentation
- Added comprehensive stream-chaining guide in `/docs/stream-chaining.md`
- Updated automation examples in `/examples/automation-examples.md`
- Enhanced workflow documentation with pipeline patterns

## [2.0.0-alpha.84] - 2025-02-03

### ğŸ”§ Bug Fixes
- **Fixed Hive Mind Wizard Memory Retrieval**: 
  - Fixed memory listing to read from correct database (`hive.db` instead of `memory.db`)
  - Updated collective memory search to query the `collective_memory` table
  - Memory wizard now correctly displays all 264 stored memories
  - Search functionality now properly queries collective memory store

### ğŸ“¦ Package Optimization
- **Reduced NPM Package Size by 31%**:
  - Excluded unnecessary `bin/claude-flow-node-pkg` binary (45MB) from npm package
  - Package size reduced from 58MB to 40MB
  - Binary is only needed for standalone distribution, not for npm/npx users
  - Updated package.json files field to exclude the precompiled binary

### ğŸ› ï¸ Technical Improvements
- **Database Consistency**: Aligned memory retrieval across hive mind commands
- **Memory Search**: Direct SQLite queries for better performance and accuracy

## [2.0.0-alpha.83] - 2025-02-01

### ğŸ”§ Bug Fixes
- **Fixed CLAUDE.md Template Generation**: 
  - Updated init command template to use correct agent names
  - Replaced legacy agent names (analyst, coordinator, etc.) with proper mappings
  - Ensures all generated CLAUDE.md files use valid agent types
  - Fixes issue #557: "Agent type 'analyst' not found" error

### ğŸ› ï¸ Technical Improvements
- **Agent Name Mapping**: Enhanced backward compatibility with legacy agent names
- **Template Updates**: Updated 18 instances of agent names in CLAUDE.md template
- **Agent Loader**: Maintains support for legacy names while using correct internal types

### ğŸ“¦ Package Notes
- Package successfully published to npm with alpha tag
- All agent definitions included (64 specialized agents)
- TypeScript build warnings present but don't affect functionality

## [2.0.0-alpha.80] - 2025-01-30

### âœ¨ New Features
- **Real Token Usage Tracking**: Track actual Claude API token consumption instead of simulated data
  - Integrates with Claude Code's OpenTelemetry metrics
  - Accurate cost calculations based on Anthropic pricing
  - Agent-level token breakdown showing usage by agent type
  - CSV export for detailed billing and analysis reports
  - Smart optimization recommendations to reduce costs

- **Real Performance Analytics**: ALL analysis commands now use real data
  - `claude-flow analysis performance-report` - Real task execution metrics
  - `claude-flow analysis bottleneck-detect` - Actual system bottleneck detection
  - Automatic performance tracking for all commands
  - System resource monitoring (CPU, memory)
  - Agent performance metrics by type
  - Trend analysis comparing periods

- **Enhanced Analytics Command**: 
  - `claude-flow analysis token-usage --breakdown --cost-analysis`
  - Real-time token consumption metrics
  - Cost projections with current Anthropic pricing
  - Filter by agent type with `--agent <type>`

- **Optional Monitoring During Init**:
  - `claude-flow init --monitoring` sets up token tracking
  - Creates `.claude-flow/` directory with tracking configuration
  - Generates environment setup script for telemetry
  - Adds token tracking hooks to Claude settings

### ğŸ”§ Technical Improvements
- **Performance Metrics System**: Complete real-time metrics collection in `performance-metrics.js`
- **Performance Hooks**: Automatic tracking integration for all commands
- **Token Tracking Implementation**: Real metrics integration in `analysis.js`
- **Init Command Enhancement**: Added `setupMonitoring()` function
- **Help Text Updates**: Added monitoring options to init and analysis commands
- **Documentation**: 
  - Token tracking guide in `/docs/REAL_TOKEN_TRACKING.md`
  - Performance tracking guide in `/docs/REAL_PERFORMANCE_TRACKING.md`

### ğŸ“Š Monitoring Features
- **Token Usage Tracking**:
  - OpenTelemetry metrics (when `CLAUDE_CODE_ENABLE_TELEMETRY=1`)
  - Local Claude Code metrics (`~/.claude/metrics/usage.json`)
  - Project-specific tracking (`.claude-flow/token-usage.json`)
- **Performance Tracking**:
  - Task execution metrics (duration, success rate)
  - Agent performance by type
  - System resource monitoring
  - Bottleneck detection and recommendations
  - HTML/JSON/CSV export formats
- Automatic fallback between data sources
- Monthly rotation for tracking data

## [2.0.0-alpha.79] - 2025-01-30

### ğŸš€ Major Improvements
- **Removed Deno Dependency**: Complete migration to pure Node.js implementation (#521)
  - Eliminated all Deno runtime references
  - Simplified installation and deployment
  - Fixed TypeScript compilation issues
  - Improved cross-platform compatibility

- **TBench Integration**: Added comprehensive Terminal Bench support
  - Created `ClaudeFlowInstalledAgent` implementation
  - Added installation script for TBench containers
  - Integrated with TBench evaluation framework
  - Support for both swarm and hive execution modes

- **Headless Mode Support**: Fixed non-interactive execution (#510)
  - Claude CLI now works in headless/production environments
  - Improved CI/CD pipeline compatibility
  - Better error handling in non-TTY environments

### ğŸ› Bug Fixes
- **Commander Dependency**: Fixed missing commander module error
- **GitHub CLI Timeout**: Resolved timeout issues with special characters (#514, #522)
- **Memory System**: Addressed memory persistence issues (#530)
- **Windows Compatibility**: Continued improvements from alpha 75
- **Hook Execution**: Stable hook system from previous alphas

### ğŸ“š Documentation
- **TBench Guide**: Added comprehensive integration documentation
- **Alpha Test Report**: Created detailed testing documentation
- **README Updates**: Fixed inaccuracies identified in #478
- **Maestro Workflow Guide**: Added comprehensive guide (#512)

### ğŸ”§ Technical Improvements
- **Build System**: Cleaned up TypeScript compilation warnings
- **Package Size**: Optimized to ~46.3MB including binary
- **Test Suite**: Identified configuration issues (non-blocking)
- **MCP Tools**: Verified all 87 tools functioning correctly

### ğŸ¯ Known Issues
- Test suite configuration needs adjustment (development only)
- Some TypeScript warnings remain (don't affect runtime)
- MCP process proliferation in some scenarios (#527)

### ğŸ“¦ Dependencies
- Updated all dependencies to latest stable versions
- Added explicit commander dependency
- Maintained compatibility with Node.js 20+

## [2.0.0-alpha.78] - 2025-01-28

### ğŸš€ Features
- **Agent System Fix**: Dynamic loading from .claude/agents/ (#485)
- **SPARC Experience**: Cleaned up legacy warnings
- **GitHub Safe Utilities**: Added timeout protection (#514)

### ğŸ› Bug Fixes
- **Hooks Pre-task**: Enhanced exit with timeout protection
- **Legacy Warnings**: Removed Deno-related warnings

## [2.0.0-alpha.77] - 2025-01-26

### ğŸ”§ Improvements
- Native Hive Mind Maestro Implementation
- Complete Maestro cleanup and consolidation
- Enhanced agent type system

## [2.0.0-alpha.75] - 2025-01-24

### ğŸš€ Windows Compatibility
- Major Windows compatibility overhaul
- Fixed path handling issues
- Improved cross-platform support

## [2.0.0-alpha.70] - 2025-01-22

### ğŸ”§ Critical Quote Handling Fix
- **Hook Commands**: Fixed "Unterminated quoted string" errors in all hook commands
  - Replaced complex `printf` and nested quotes with simpler `cat | jq | tr | xargs` pipeline
  - Used `jq -r '.field // empty'` instead of problematic `'.field // ""'` syntax
  - All hook commands now use consistent: `cat | jq -r '.tool_input.command // empty' | tr '\\n' '\\0' | xargs -0 -I {}`
  - Fixed both init template and current settings.json files

### ğŸ› ï¸ Command Improvements  
- **Simplified Pipeline**: More reliable command parsing without quote conflicts
- **Better Error Handling**: Clean failures instead of shell syntax errors
- **Consistent Syntax**: All hook commands use identical, tested patterns

## [2.0.0-alpha.69] - 2025-01-22

### ğŸ”§ Critical Fix
- **Init Template**: Fixed `claude-flow init` creating broken settings.json with xargs quote errors
  - Updated template to use `printf '%s\0'` instead of problematic `cat | jq | xargs -I` pipeline
  - Changed to `xargs -0` with single quotes around `{}` placeholders  
  - Removed non-existent `--train-neural` flag from post-edit hooks
  - All new projects initialized with `claude-flow init` now have working hooks

### ğŸ› ï¸ Template Improvements
- **Safer Command Execution**: Printf-based approach prevents quote parsing issues
- **Better Error Handling**: Commands fail gracefully instead of breaking xargs
- **Cleaner Syntax**: Simplified hook commands for better reliability

## [2.0.0-alpha.68] - 2025-01-22

### ğŸ”§ Critical Bug Fixes
- **Hook Execution**: Fixed xargs unmatched quote error in PreToolUse:Bash and PostToolUse:Bash hooks
  - Updated to use `xargs -0` with null-delimited input to properly handle commands with quotes
  - Changed from double quotes to single quotes around command placeholders
  - Added `tr '\n' '\0'` to convert newlines to null characters for safe processing
- **Neural Command**: Identified missing neural command implementation (created issue #444)
  - Affects error prevention, performance optimization, and session training
  - Temporary workaround: hooks fail gracefully with non-blocking errors

### ğŸ› ï¸ Improvements
- **Hook Reliability**: Enhanced quote and special character handling in all hook commands
- **Error Handling**: Improved error reporting for missing commands
- **Settings Format**: Updated .claude/settings.json with fixed hook configurations

### ğŸ“ Known Issues
- Neural commands (`neural predict`, `neural train`, etc.) are not yet implemented in alpha version
- Memory store command requires proper key-value syntax

## [2.0.0-alpha.67] - 2025-01-21

### ğŸ Hive Mind Enhancement
- **Hive Mind Integration**: Fixed settings.json validation errors for Claude Code compatibility
- **Configuration Fix**: Removed unrecognized fields (checkpoints, memory, neural, github, optimization)
- **Hook Names**: Corrected invalid hook names to match Claude Code 1.0.51+ format
  - `user-prompt-submit` â†’ `UserPromptSubmit`
  - Removed invalid `checkpoint` and `error` hooks

### ğŸ”§ Infrastructure
- **Settings Validation**: Now passes `/doctor` command validation
- **Claude Code Compatibility**: Full compatibility with Claude Code 1.0.51+ settings format
- **Version Update**: Bumped to alpha.67 across all version references

### ğŸ“š Documentation
- Updated version references in help text and CLI commands
- Enhanced hive-mind documentation with corrected hook configurations

## [2.0.0-alpha.66] - 2025-01-20

### ğŸ”§ Bug Fixes
- **Hooks Command**: Fixed "command.toLowerCase is not a function" error in hooks pre-command
- **ARM64 Support**: Improved ARM64 compatibility for better-sqlite3 on macOS (#378)
- Added type checking for command parameter in hooks to handle empty/missing values
- Enhanced postinstall script with ARM64 detection and automatic rebuild

### ğŸš€ New Features
- Automatic SQLite binding verification and rebuild for Apple Silicon Macs
- Graceful fallback to in-memory storage if SQLite bindings fail
- Better error handling and user feedback during installation

### ğŸ—ï¸ Infrastructure
- Added `node20-macos-arm64` target to pkg configuration
- Improved boolean parameter parsing in hooks commands
- Enhanced platform detection for ARM64 architecture

### ğŸ“š Documentation
- Added ARM64 troubleshooting guide
- Updated hooks command usage examples

## [2.0.0-alpha.65] - 2025-01-20

### ğŸ”§ Bug Fixes
- **CRITICAL**: Fixed "table agents has no column named role" error in hive-mind wizard (#403)
- Added missing `role` column to agents table schema in init/index.js
- Fixed TypeScript build errors preventing compilation
- Resolved ILogger interface issues and async/await problems
- Fixed missing type definitions in multiple modules

### ğŸ—ï¸ Infrastructure
- **Database Schema**: Synchronized agents table schema across all modules
- **Build System**: Fixed critical TypeScript compilation errors
- **Type Safety**: Added proper type annotations throughout codebase

### ğŸ“š Documentation
- Added migration instructions for existing databases
- Updated test suite with schema validation tests

## [2.0.0-alpha.64] - 2025-01-18

### ğŸ”§ Bug Fixes
- Fixed wrapper script hardcoded to use outdated alpha-27 version
- Updated wrapper to use `@alpha` tag for always getting latest alpha version
- Ensures `./claude-flow` wrapper always uses the most recent alpha release

### ğŸ“¦ Dependencies
- No dependency changes, only template fix

## [2.0.0-alpha.63] - 2025-01-18

### ğŸš€ Major Features
- **MCP/NPX Fallback Pattern**: All 60+ command files now include both MCP tools (preferred) and NPX CLI (fallback)
- **SPARC Included by Default**: No more `--sparc` flag needed, SPARC commands automatically initialized
- **Complete Environment Init**: Creates 112+ files including both databases properly initialized

### ğŸ—ï¸ Infrastructure
- **Template System**: Updated template generation to include MCP/NPX fallback patterns
- **Init Command**: Fixed missing imports for createAgentsReadme and createSessionsReadme
- **Database Init**: Added .hive-mind directory creation and hive.db initialization with schema
- **SPARC Integration**: Made SPARC included by default in v2.0.0 flow

### ğŸ› ï¸ Improvements
- Updated all 18 SPARC command files in .claude/commands/sparc/ with MCP/NPX fallback
- Updated 5 swarm strategy files with MCP/NPX patterns
- Enhanced init command to create complete environment with 113 files
- Fixed copyRevisedTemplates to include SPARC files

### ğŸ“š Documentation
- Updated CLAUDE.md template with comprehensive MCP/NPX usage examples
- Added fallback guidance to all command documentation
- Enhanced GitHub integration documentation with gh CLI usage

## [2.0.0-alpha.62] - 2025-01-18

### ğŸ”’ Security Fixes
- **CRITICAL**: Removed vulnerable `pkg` dependency (GHSA-22r3-9w55-cj54) - Local privilege escalation vulnerability
- Replaced `pkg` with secure `@vercel/ncc` alternative for binary building
- Security score improved from 55/100 to 75/100
- All npm audit vulnerabilities resolved (0 vulnerabilities)

### ğŸš€ Infrastructure Improvements
- **CI/CD Pipeline**: Re-enabled ALL security gates with strict enforcement
  - Removed all `|| true` and `|| echo` fallbacks
  - Added production dependency audit (moderate level)
  - Added license compliance checks
  - Test coverage reporting re-enabled
- **Test Infrastructure**: Major fixes and improvements
  - Fixed Jest configuration (removed deprecated globals)
  - Created comprehensive `test.utils.ts` with mock utilities
  - Fixed 18 TypeScript test files with incorrect import paths
  - Fixed ESM module issues (assert â†’ with syntax)
  - Created test fixtures and generators
  - Core tests now passing

### ğŸ› ï¸ Code Quality Improvements
- **ESLint**: Fixed 145 errors (16% reduction from 900 to 755)
  - Removed 104 unused `getErrorMessage` imports
  - Fixed non-null assertions with proper null checks
  - Added underscore prefix for intentionally unused parameters
- **TypeScript**: Fixed 15 critical errors in CLI commands
  - Fixed cli-table3 import issues
  - Corrected date arithmetic operations
  - Added proper type assertions for error handling
  - Resolved Commander/Cliffy compatibility issues
- **Configuration**: Added development tooling
  - Created `babel.config.cjs` with modern import syntax support
  - Created `.eslintrc.json` with TypeScript rules
  - Created `.prettierrc.json` for consistent formatting

### ğŸ“š Documentation
- Created `SECURITY_AUDIT_REPORT.md` with detailed security findings
- Created `FIX_SUMMARY.md` documenting all code quality fixes
- Created `FUNCTIONALITY_REVIEW.md` verifying all features work
- Updated GitHub issue #362 with comprehensive progress reports

### âœ… Verified Working Features
- All core CLI commands operational
- SPARC development system functional
- Hive Mind system ready
- Swarm coordination active
- Memory persistence working
- MCP server integration verified
- Help system comprehensive

### ğŸ› Known Issues
- ESLint: 755 warnings remaining (mostly `any` types)
- TypeScript: 413 errors remaining (complex type issues)
- Some integration tests need implementation
- Build process has declaration file conflicts (workaround available)

## [2.0.0-alpha.61] - 2025-01-17

### Added
- **Neural Training Enhancements**: 
  - Enhanced neural training with real WASM acceleration achieving 92.9% accuracy
  - Added task-predictor model for improved agent coordination
  - Implemented SIMD support for faster neural computations
  - Added comprehensive neural training command help documentation

- **Help System Improvements**:
  - Updated help command implementation with proper TypeScript support
  - Enhanced help text with neural training command documentation
  - Added comprehensive examples for training, pattern learning, and model updates
  - Improved command-specific help display formatting

- **Version Management**:
  - Updated all version references to alpha.61 across codebase
  - Updated help text to reflect alpha.61 improvements
  - Enhanced version display in CLI output

### Fixed
- **Issue #351**: Fixed `swarm_status` MCP tool returning mock response instead of real data
  - Removed dependency on uninitialized `databaseManager`
  - Updated to use memory store (SQLite) for swarm data retrieval
  - Fixed agent and task storage keys to enable proper filtering by swarm ID
  - Added support for verbose mode to return detailed swarm information
  - Ensured accurate agent counts, task counts, and status calculations

- **Issue #347**: Fixed MemoryManager initialization error "Unknown memory backend: undefined"
  - Added required configuration parameters to MemoryManager constructor
  - Created default memory configuration with SQLite backend
  - Set sensible defaults: 50MB cache, 30s sync interval, 30-day retention
  - Added proper error handling and logging for memory initialization
  - Resolved critical bug that blocked system integration startup

### Changed
- **MCP Server Memory Integration**: 
  - `swarm_status` now retrieves data from persistent memory store
  - `agent_spawn` stores agents with swarm-scoped keys (`agent:{swarmId}:{agentId}`)
  - `task_orchestrate` now stores tasks in memory (previously only attempted database storage)
  - `getActiveSwarmId()` method updated to use memory store
  
- **System Integration Memory Setup**:
  - MemoryManager now receives EventBus and Logger instances from SystemIntegration
  - Memory configuration is created with sensible defaults during initialization
  - Improved status reporting includes backend type and configuration details

- **CLI Help System**:
  - Maintained emoji-rich help as default based on user preference
  - Added `--plain` flag option for standardized Unix/Linux-style help
  - Updated command registry to use `HelpFormatter` when --plain is used
  - Modified `help-text.js` to support dual help modes
  - Enhanced error messages with helpful usage hints and valid options
  - Commands retain their vibrant, engaging help by default

## [2.0.0-alpha.56] - 2025-07-15

### ğŸš€ Major Hook System Overhaul (Issue #280)

#### **Complete Resolution of Hook Inconsistencies**
- **Hook name compatibility**: Both `pre-command` and `pre-bash` work identically
- **Parameter mapping**: All settings.json template parameters implemented
- **Dual format support**: Both dash-case (`--validate-safety`) and camelCase (`validateSafety`) work
- **100% settings.json compatibility**: All template commands work without modification

#### **Enhanced Safety Features**
- **Dangerous command blocking**: Prevents `rm -rf`, `format`, `del /f`, etc.
- **Safety validation**: Real-time command analysis and blocking
- **Resource preparation**: Automatic working directory setup
- **Command logging**: Full audit trail in SQLite memory store

#### **Intelligent Agent Assignment**
- **File-type based recommendations**: `.js` â†’ `javascript-developer`, `.py` â†’ `python-developer`
- **Context-aware assignment**: Automatic agent matching based on file extensions
- **Load context functionality**: Pre-operation context loading for better decisions

#### **Neural Pattern Training**
- **Confidence scoring**: 70-100% confidence levels for pattern recognition
- **Learning simulation**: Adaptive pattern training for syntax, structure, performance, security
- **Memory persistence**: Cross-session learning data storage

#### **Comprehensive Session Management**
- **State persistence**: Full session state saved to SQLite database
- **Metrics export**: Detailed session statistics and performance data
- **Summary generation**: Automatic session summaries with key metrics
- **Cross-session memory**: Persistent memory across development sessions

#### **Technical Improvements**
- **SQLite integration**: Robust memory store with error handling
- **Performance tracking**: Real-time metrics collection and analysis
- **Enhanced TypeScript types**: Complete interface coverage for all hook parameters
- **Comprehensive testing**: Integration tests for all hook functionality

### Fixed
- **Issue #280**: Complete resolution of hook parameter inconsistencies
- **Parameter validation**: All settings.json template parameters now work correctly
- **Hook name aliases**: Pre-command/pre-bash and post-command/post-bash compatibility
- **Memory storage**: Reliable SQLite-based persistence system

### Dependencies
- **Added**: `diskusage@1.1.3` for system resource monitoring
- **Updated**: Package version to 2.0.0-alpha.56

### Testing
- **Integration tests**: Comprehensive test suite for hook consistency
- **Template validation**: Settings.json command validation tests
- **Manual testing**: All hook variations tested and verified
- **NPM package**: Published and validated on npm registry

## [2.0.0-alpha.51] - 2025-01-14

### Changed
- Version bump with updated CLI version strings
- All features from alpha.50 included

## [2.0.0-alpha.50] - 2025-01-14

### Added

#### **Hive Mind Resume Functionality**
- **Session persistence** across swarm operations with automatic tracking
- **Auto-save system** with 30-second intervals and critical event saves
- **Resume capabilities** with full context restoration and progress tracking
- **Claude Code integration** for seamless continuation of paused sessions
- **Session management commands**: `sessions`, `resume <session-id>`
- **Comprehensive testing** with end-to-end test coverage
- **Complete documentation** in `docs/hive-mind-resume.md`

#### **Technical Infrastructure**
- **HiveMindSessionManager** class for session lifecycle management
- **AutoSaveMiddleware** for automatic state persistence
- **Database schema** with sessions, checkpoints, and logs tables
- **Graceful shutdown handling** with Ctrl+C interrupt support
- **Progress tracking** with completion percentage calculations

### Fixed
- **Session ID tracking** in spawn command output
- **Auto-save timing** for consistent 30-second intervals
- **Error recovery** for corrupted session data
- **Claude Code prompt** generation for resumed sessions

### Performance
- **Minimal overhead**: < 1% CPU usage for auto-save
- **Fast resume**: < 2 seconds session restoration
- **Efficient storage**: Compressed checkpoint data
- **Optimized queries**: Improved database performance

## [2.0.0] - 2025-07-03

### Added

#### **Complete ruv-swarm Integration**
- **27 MCP tools** for comprehensive workflow automation
- **Multi-agent task coordination** with swarm intelligence and hierarchical topology
- **Neural network capabilities** with cognitive diversity patterns (convergent, divergent, lateral, systems, critical, adaptive)
- **Cross-session memory persistence** with swarm coordination
- **Real-time performance monitoring** with sub-10ms response times
- **WASM-powered neural processing** with SIMD optimization support

#### **GitHub Workflow Automation**
- **6 specialized command modes** in `.claude/commands/github/`:
  - `pr-manager`: Automated pull request management with swarm coordination
  - `issue-tracker`: Intelligent issue management and progress tracking
  - `sync-coordinator`: Cross-package synchronization and version alignment
  - `release-manager`: Coordinated release management with multi-stage validation
  - `repo-architect`: Repository structure optimization and template management
  - `gh-coordinator`: Overall GitHub workflow orchestration
- **Automated pull request management** with multi-reviewer coordination
- **Intelligent issue tracking** with swarm-coordinated progress monitoring
- **Cross-repository synchronization** capabilities for monorepo management
- **Release coordination** with comprehensive validation pipelines

#### **Production-Ready Infrastructure**
- **Multi-stage Docker builds** with 60% performance improvement over previous builds
- **Comprehensive testing suite** with 67 CLI tests achieving 100% pass rate
- **Docker Compose orchestration** for development, testing, and production environments
- **CI/CD automation** with automated test execution and validation
- **Real-time monitoring** and performance tracking with detailed metrics
- **Security hardening** with non-root containers and best practices implementation

#### **Enhanced CLI Capabilities**
- **Advanced swarm coordination commands** with `npx claude-flow swarm`
- **GitHub integration commands** accessible through enhanced CLI interface
- **Improved error handling** and validation with detailed error messages
- **Enhanced UI** with `--ui` flag support for interactive management
- **SPARC mode initialization** with `--sparc` flag for development workflows
- **Performance benchmarking** tools integrated into CLI

#### **Enterprise Features**
- **Enterprise-grade documentation** with comprehensive integration guides
- **Production deployment** configurations and best practices
- **Performance metrics** and monitoring capabilities
- **Security audit** tools and vulnerability scanning
- **Cross-platform compatibility** validation (Windows, macOS, Linux)

### Changed

#### **Node.js Requirements**
- **Upgraded minimum version** from `>=18.0.0` to `>=20.0.0` for optimal ruv-swarm compatibility
- **Added npm requirement** of `>=9.0.0` for enhanced package management features

#### **Package Dependencies**
- **Updated better-sqlite3** from `^11.10.0` to `^12.2.0` for improved compatibility
- **Added ruv-swarm dependency** for complete swarm coordination capabilities
- **Enhanced package keywords** for better discoverability on npm registry
- **Optimized file inclusion** for npm publishing with focus on essential files

#### **CLI Command Structure**
- **Enhanced all commands** with swarm coordination capabilities
- **Improved command organization** with specialized GitHub workflow commands
- **Better error handling** throughout the CLI interface
- **Enhanced help documentation** with comprehensive examples

#### **Documentation**
- **Complete overhaul** focusing on enterprise features and v2.0.0 capabilities
- **Added comprehensive integration guides** for ruv-swarm and GitHub workflows
- **Enhanced README.md** with enterprise-focused content and clear value propositions
- **Improved code examples** and usage documentation

#### **Configuration**
- **New `.claude/commands/github/` directory** structure for GitHub workflow commands
- **Enhanced npm publishing** configuration with automated workflows
- **Improved package metadata** for better npm registry presentation
- **Updated build targets** for Node.js 20+ compatibility

### Fixed

#### **Dependency Resolution**
- **Resolved file path dependency issues** for ruv-swarm integration
- **Fixed version compatibility** conflicts between packages
- **Improved dependency alignment** across the entire ecosystem
- **Enhanced package installation** reliability

#### **Version Compatibility**
- **Aligned Node.js requirements** across claude-code-flow and ruv-swarm
- **Fixed better-sqlite3 version** conflicts for cross-platform compatibility
- **Resolved npm installation** issues in Docker environments
- **Enhanced cross-platform** compatibility validation

#### **Memory Coordination**
- **Improved cross-package state management** with enhanced memory persistence
- **Fixed memory leaks** in long-running swarm operations
- **Enhanced memory efficiency** for large-scale operations
- **Optimized memory coordination** between agents

#### **Error Handling**
- **Enhanced error messages** with actionable guidance and context
- **Improved error recovery** mechanisms for robust operation
- **Better error logging** for debugging and troubleshooting
- **Graceful failure handling** in swarm coordination scenarios

### Security

#### **Docker Security**
- **Implemented security hardening** in container configurations
- **Added non-root user** execution for enhanced security
- **Enhanced container isolation** and network security
- **Implemented security scanning** in CI/CD pipelines

#### **Dependency Security**
- **Updated dependencies** to resolve security vulnerabilities
- **Implemented automated security** scanning with npm audit
- **Enhanced access control** for GitHub integrations
- **Added vulnerability monitoring** for continuous security

#### **Access Control**
- **Enhanced permission management** for GitHub integrations
- **Improved API security** for MCP tool interactions
- **Added authentication** validation for sensitive operations
- **Implemented secure communication** protocols

### Performance

#### **Build Performance**
- **60% faster Docker builds** through multi-stage optimization
- **Improved package installation** speed with optimized dependencies
- **Enhanced build caching** for development workflows
- **Optimized binary compilation** for faster CLI startup

#### **Runtime Performance**
- **Sub-10ms MCP response times** for optimal user experience
- **Improved memory efficiency** with optimized coordination algorithms
- **Enhanced CPU utilization** for better resource management
- **Faster CLI startup** times with optimized initialization

#### **Testing Performance**
- **100% CLI test success rate** with comprehensive validation
- **Faster test execution** with parallel testing capabilities
- **Improved test coverage** across all major features
- **Enhanced performance regression** detection

---

## Migration Guide: v1.x to v2.0.0

### Prerequisites

1. **Update Node.js** to version 20 or higher:
   ```bash
   # Check current version
   node --version
   
   # Update to Node.js 20+ (using nvm)
   nvm install 20
   nvm use 20
   ```

2. **Update npm** to version 9 or higher:
   ```bash
   npm install -g npm@latest
   ```

### Installation

1. **Uninstall previous version** (if installed globally):
   ```bash
   npm uninstall -g claude-flow
   ```

2. **Install v2.0.0**:
   ```bash
   npm install -g claude-flow@2.0.0
   ```

3. **Verify installation**:
   ```bash
   claude-flow --version  # Should show 2.0.0
   claude-flow --help     # Verify all commands available
   ```

### Configuration Updates

1. **Initialize new features**:
   ```bash
   npx claude-flow init --sparc
   ```

2. **Test swarm capabilities**:
   ```bash
   npx claude-flow swarm init
   ```

3. **Explore GitHub integration**:
   ```bash
   npx claude-flow github --help
   ```

### Breaking Changes

#### Command Structure
- **All commands** now support swarm coordination
- **New GitHub commands** available in `.claude/commands/github/`
- **Enhanced error handling** may change error message formats
- **Existing commands** remain backward compatible

#### Dependencies
- **ruv-swarm** is now a required dependency
- **better-sqlite3** updated to v12.2.0
- **Node.js 20+** is required for optimal performance

#### Configuration
- **New configuration files** in `.claude/commands/github/`
- **Enhanced MCP integration** requires ruv-swarm setup
- **Updated package metadata** for npm publishing

### New Features

#### Swarm Coordination
```bash
# Initialize swarm
npx claude-flow swarm init

# Spawn agents
npx claude-flow agent spawn researcher
npx claude-flow agent spawn coder

# Orchestrate tasks
npx claude-flow task orchestrate "complex development task"
```

#### GitHub Integration
```bash
# Automated PR management
npx claude-flow github pr-manager "review and merge feature branch"

# Issue tracking
npx claude-flow github issue-tracker "manage project issues"

# Release coordination
npx claude-flow github release-manager "prepare v2.0.0 release"
```

#### Docker Development
```bash
# Build Docker environment
docker-compose -f infrastructure/docker/docker-compose.yml up

# Run tests in Docker
docker-compose -f infrastructure/docker/testing/docker-compose.test.yml up
```

### Verification

After migration, verify functionality:

```bash
# Basic functionality
claude-flow --version
claude-flow --help
claude-flow status

# Swarm features
claude-flow swarm init
claude-flow agent list

# GitHub integration
claude-flow github --help

# Docker testing
cd infrastructure/docker && docker-compose up
```

---

## [1.0.71] - 2025-07-01

### Fixed
- Enhanced stability and performance improvements
- Improved error handling in core orchestration
- Updated dependencies for security

### Added
- Improved CLI interface
- Enhanced configuration management
- Better error reporting

---

## [1.0.0] - 2025-01-01

### Added
- Initial release of claude-flow
- Basic AI agent orchestration
- CLI interface for agent management
- Core workflow automation
- Integration with Claude Code

---

*For older versions, see the [releases page](https://github.com/ruvnet/claude-code-flow/releases).*</doc></docs><examples><doc title="Usage Example" desc="worked example.">/**
 * SPARC Memory Bank - Usage Examples
 * Demonstrates the complete functionality of the memory system
 */

import {
  MemoryManager,
  MemoryItem,
  MemoryQuery,
  ImportExportManager,
  NamespaceManager
} from '../src';

async function main() {
  console.log('ğŸ§  SPARC Memory Bank - Usage Examples\n');

  // 1. Initialize Memory Manager with SQLite backend
  console.log('1. Initializing Memory Manager...');
  const memoryManager = new MemoryManager({
    backend: 'sqlite',
    backendConfig: {
      path: './claude-flow-memory.db',
      wal: true
    },
    cacheConfig: {
      maxSize: 1000,
      ttl: 3600000, // 1 hour
      strategy: 'lru'
    },
    enableIndexing: true,
    enableNamespaces: true,
    replicationConfig: {
      mode: 'peer-to-peer',
      nodes: [
        { id: 'node1', url: 'http://localhost:3001' },
        { id: 'node2', url: 'http://localhost:3002' }
      ],
      syncInterval: 60000 // 1 minute
    }
  });

  await memoryManager.initialize();
  console.log('âœ… Memory Manager initialized\n');

  // 2. Store different types of memory items
  console.log('2. Storing memory items...');
  
  // Agent calibration values
  await memoryManager.store({
    category: 'calibration',
    key: 'react-performance',
    value: {
      bundleSize: { max: 200000, optimal: 150000 },
      renderTime: { max: 16, optimal: 8 },
      memoryUsage: { max: 50000000, optimal: 30000000 }
    },
    metadata: {
      tags: ['react', 'performance', 'frontend'],
      confidence: 0.95,
      source: 'performance-testing'
    }
  });

  // TDD patterns
  await memoryManager.store({
    category: 'test-pattern',
    key: 'london-school-mocking',
    value: {
      pattern: 'Mock all collaborators',
      example: `
        describe('UserService', () => {
          let userService;
          let mockRepository;
          
          beforeEach(() => {
            mockRepository = jest.fn();
            userService = new UserService(mockRepository);
          });
          
          it('should save user', async () => {
            mockRepository.save = jest.fn().mockResolvedValue({ id: 1 });
            await userService.createUser({ name: 'Alice' });
            expect(mockRepository.save).toHaveBeenCalled();
          });
        });
      `,
      benefits: ['Fast tests', 'Isolated units', 'Clear boundaries'],
      drawbacks: ['More setup', 'Brittle to refactoring']
    },
    metadata: {
      tags: ['tdd', 'london-school', 'testing'],
      language: 'javascript'
    }
  });

  // Architectural decisions
  await memoryManager.store({
    category: 'architecture',
    key: 'adr-001-event-sourcing',
    value: {
      title: 'Use Event Sourcing for Audit Trail',
      status: 'accepted',
      context: 'Need complete audit trail of all system changes',
      decision: 'Implement event sourcing pattern',
      consequences: {
        positive: ['Complete audit trail', 'Time travel debugging', 'Event replay'],
        negative: ['Increased complexity', 'Storage requirements']
      }
    },
    metadata: {
      tags: ['architecture', 'event-sourcing', 'audit'],
      date: '2025-01-06',
      author: 'claude-architect'
    }
  });

  console.log('âœ… Memory items stored\n');

  // 3. Query memory items
  console.log('3. Querying memory items...');
  
  // Query by category
  const calibrationItems = await memoryManager.query({
    categories: ['calibration']
  });
  console.log(`Found ${calibrationItems.length} calibration items`);

  // Query by tags
  const testingPatterns = await memoryManager.query({
    tags: ['testing']
  });
  console.log(`Found ${testingPatterns.length} testing patterns`);

  // Query with custom filter
  const recentDecisions = await memoryManager.query({
    categories: ['architecture'],
    filter: (item) => {
      const date = new Date(item.metadata?.date || 0);
      const thirtyDaysAgo = new Date();
      thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
      return date > thirtyDaysAgo;
    }
  });
  console.log(`Found ${recentDecisions.length} recent architectural decisions\n`);

  // 4. Namespace management
  console.log('4. Managing namespaces...');
  
  // Create project-specific namespace
  const projectNamespace = await memoryManager.store({
    category: 'project',
    key: 'ultrasonic-steganography',
    value: {
      name: 'Ultrasonic Steganography',
      description: 'Audio steganography using ultrasonic frequencies',
      status: 'in-progress',
      team: ['alice', 'bob', 'charlie']
    }
  }, 'ultrasonic-project');

  console.log('âœ… Project namespace created\n');

  // 5. Vector search for semantic queries
  console.log('5. Vector search example...');
  
  // Store items with vector embeddings
  const indexer = (memoryManager as any).indexer;
  
  const doc1 = 'React performance optimization techniques for large applications';
  const embedding1 = await indexer.generateEmbedding(doc1);
  
  await memoryManager.store({
    category: 'knowledge',
    key: 'react-perf-guide',
    value: doc1,
    vectorEmbedding: embedding1,
    metadata: {
      type: 'guide',
      topic: 'performance'
    }
  });

  const doc2 = 'Testing strategies for microservices architecture';
  const embedding2 = await indexer.generateEmbedding(doc2);
  
  await memoryManager.store({
    category: 'knowledge',
    key: 'microservices-testing',
    value: doc2,
    vectorEmbedding: embedding2,
    metadata: {
      type: 'guide',
      topic: 'testing'
    }
  });

  // Search for similar documents
  const searchQuery = 'How to optimize React application performance';
  const searchEmbedding = await indexer.generateEmbedding(searchQuery);
  
  const similarDocs = await memoryManager.query({
    vectorSearch: {
      embedding: searchEmbedding,
      topK: 5,
      threshold: 0.7
    }
  });

  console.log(`Found ${similarDocs.length} similar documents\n`);

  // 6. Import/Export functionality
  console.log('6. Import/Export example...');
  
  const exportManager = new ImportExportManager();
  
  // Export to JSON
  const snapshot = await memoryManager.export({
    categories: ['calibration', 'test-pattern'],
    format: 'json'
  });
  
  console.log('âœ… Exported snapshot to JSON');

  // Export to Markdown
  const markdownExport = await memoryManager.export({
    categories: ['architecture'],
    format: 'markdown'
  });
  
  console.log('âœ… Exported architectural decisions to Markdown\n');

  // 7. Time-travel queries
  console.log('7. Time-travel query example...');
  
  const oneHourAgo = Date.now() - 3600000;
  
  const historicalItems = await memoryManager.query({
    asOf: oneHourAgo
  });
  
  console.log(`Found ${historicalItems.length} items from 1 hour ago\n`);

  // 8. Memory statistics
  console.log('8. Memory statistics...');
  
  const stats = await memoryManager.getStats();
  console.log('Memory Stats:', {
    totalItems: stats.backend.totalItems,
    categories: stats.backend.categories,
    cacheHitRate: stats.cache.hitRate,
    cacheSize: stats.cache.itemCount
  });
  console.log('');

  // 9. Conflict resolution example
  console.log('9. CRDT conflict resolution...');
  
  // Simulate concurrent updates
  const item1 = {
    id: 'shared-config',
    category: 'config',
    key: 'app-settings',
    value: { theme: 'light', language: 'en' },
    metadata: { timestamp: Date.now() - 1000 }
  };

  const item2 = {
    id: 'shared-config',
    category: 'config',
    key: 'app-settings',
    value: { theme: 'dark', notifications: true },
    metadata: { timestamp: Date.now() }
  };

  await memoryManager.store(item1);
  const resolved = await memoryManager.store(item2);
  
  console.log('Resolved conflict:', resolved.value);
  console.log('âœ… Conflicts resolved using CRDT\n');

  // 10. Cleanup
  console.log('10. Cleaning up...');
  await memoryManager.close();
  console.log('âœ… Memory Manager closed\n');

  console.log('ğŸ‰ All examples completed successfully!');
}

// Run examples
main().catch(console.error);

/**
 * Advanced Usage Examples
 */

// Example: Creating a custom memory backend
class CustomMemoryBackend {
  // Implement MemoryBackend interface
  async initialize() { /* ... */ }
  async store(item: MemoryItem) { /* ... */ }
  async get(category: string, key: string) { /* ... */ }
  async query(query: MemoryQuery) { /* ... */ }
  async delete(category: string, key: string) { /* ... */ }
  async update(category: string, key: string, updates: any) { /* ... */ }
  async getStats() { /* ... */ }
  async close() { /* ... */ }
}

// Example: Custom conflict resolution
class CustomConflictResolution {
  async resolve(existing: MemoryItem, incoming: MemoryItem): Promise<MemoryItem> {
    // Custom merge logic
    // For example, merge arrays, combine objects, etc.
    return {
      ...existing,
      ...incoming,
      value: this.deepMerge(existing.value, incoming.value)
    };
  }

  private deepMerge(obj1: any, obj2: any): any {
    // Implementation of deep merge
    return { ...obj1, ...obj2 };
  }
}

// Example: Memory-backed agent coordination
class MemoryCoordinator {
  constructor(private memory: MemoryManager) {}

  async registerAgent(agentId: string, capabilities: string[]) {
    await this.memory.store({
      category: 'coordination',
      key: `agent-${agentId}`,
      value: {
        id: agentId,
        capabilities,
        status: 'active',
        lastHeartbeat: Date.now()
      },
      ttl: 300000 // 5 minutes
    }, 'agent-coordination');
  }

  async getActiveAgents(): Promise<any[]> {
    const agents = await this.memory.query({
      categories: ['coordination'],
      namespace: 'agent-coordination'
    });

    return agents
      .filter(a => a.value.status === 'active')
      .map(a => a.value);
  }

  async assignTask(agentId: string, task: any) {
    await this.memory.store({
      category: 'tasks',
      key: `task-${task.id}`,
      value: {
        ...task,
        assignedTo: agentId,
        status: 'assigned',
        assignedAt: Date.now()
      }
    }, 'agent-coordination');
  }
}</doc><doc title="Summary Session 20250806 025626" desc="worked example."># Session Summary - 2025-08-06 02:56:26

## Checkpoints Created
1754447043.json
1754447045.json
1754448240.json
1754448242.json
1754448294.json
1754448295.json
1754448380.json
1754448382.json
1754448488.json
1754448490.json
1754448531.json
1754448533.json
1754448586.json
1754448587.json
1754448738.json
1754448741.json
1754448794.json
1754448796.json
1754448968.json
1754448971.json

## Files Modified
.claude-flow/metrics/performance.json
.claude-flow/metrics/system-metrics.json
.claude-flow/metrics/task-metrics.json
.claude/checkpoints/task-1754446387.json
benchmark/.claude-flow/metrics/performance.json
benchmark/.claude-flow/metrics/system-metrics.json
benchmark/.claude-flow/metrics/task-metrics.json
benchmark/.claude/checkpoints/1754445349.json
benchmark/.claude/checkpoints/1754445369.json
benchmark/.claude/checkpoints/1754446676.json
benchmark/.claude/checkpoints/1754446678.json
benchmark/.claude/checkpoints/1754446680.json
benchmark/.claude/checkpoints/1754446681.json
benchmark/.claude/checkpoints/1754446746.json
benchmark/.claude/checkpoints/1754446747.json
benchmark/.claude/checkpoints/1754446758.json
benchmark/.claude/checkpoints/1754446760.json
benchmark/.claude/checkpoints/1754446762.json
benchmark/.claude/checkpoints/1754446763.json
benchmark/.claude/checkpoints/1754446765.json
benchmark/.claude/checkpoints/1754446767.json
benchmark/.claude/checkpoints/1754446804.json
benchmark/.claude/checkpoints/1754446806.json
benchmark/.claude/checkpoints/1754446825.json
benchmark/.claude/checkpoints/1754446827.json
benchmark/.claude/checkpoints/1754446838.json
benchmark/.claude/checkpoints/1754446840.json
benchmark/.claude/checkpoints/1754446850.json
benchmark/.claude/checkpoints/1754446852.json
benchmark/.claude/checkpoints/1754446853.json
benchmark/.claude/checkpoints/1754446855.json
benchmark/.claude/checkpoints/1754446876.json
benchmark/.claude/checkpoints/1754446878.json
benchmark/.claude/checkpoints/1754446913.json
benchmark/.claude/checkpoints/1754446914.json
benchmark/.claude/checkpoints/1754446929.json
benchmark/.claude/checkpoints/1754446930.json
benchmark/.claude/checkpoints/1754447000.json
benchmark/.claude/checkpoints/1754447002.json
benchmark/.claude/checkpoints/1754447010.json
benchmark/.claude/checkpoints/1754447012.json
benchmark/.claude/checkpoints/1754447073.json
benchmark/.claude/checkpoints/1754447075.json
benchmark/.claude/checkpoints/1754447109.json
benchmark/.claude/checkpoints/1754447111.json
benchmark/.claude/checkpoints/1754447217.json
benchmark/.claude/checkpoints/1754447219.json
benchmark/.claude/checkpoints/1754447291.json
benchmark/.claude/checkpoints/1754447292.json
benchmark/.claude/checkpoints/1754447479.json
benchmark/.claude/checkpoints/1754447481.json
benchmark/.claude/checkpoints/1754447514.json
benchmark/.claude/checkpoints/1754447516.json
benchmark/.claude/checkpoints/1754447819.json
benchmark/.claude/checkpoints/1754447821.json
benchmark/.claude/checkpoints/1754447851.json
benchmark/.claude/checkpoints/1754447854.json
benchmark/.claude/checkpoints/1754447864.json
benchmark/.claude/checkpoints/1754447866.json
benchmark/.claude/checkpoints/1754447873.json
benchmark/.claude/checkpoints/1754447875.json
benchmark/.claude/checkpoints/1754447876.json
benchmark/.claude/checkpoints/1754447878.json
benchmark/.claude/checkpoints/1754447887.json
benchmark/.claude/checkpoints/1754447889.json
benchmark/.claude/checkpoints/1754447894.json
benchmark/.claude/checkpoints/1754447896.json
benchmark/.claude/checkpoints/1754447899.json
benchmark/.claude/checkpoints/1754447901.json
benchmark/.claude/checkpoints/1754447908.json
benchmark/.claude/checkpoints/1754447910.json
benchmark/.claude/checkpoints/1754447918.json
benchmark/.claude/checkpoints/1754447920.json
benchmark/.claude/checkpoints/1754447933.json
benchmark/.claude/checkpoints/1754447935.json
benchmark/.claude/checkpoints/1754447953.json
benchmark/.claude/checkpoints/1754447955.json
benchmark/.claude/checkpoints/1754447970.json
benchmark/.claude/checkpoints/1754447972.json
benchmark/.claude/checkpoints/1754447973.json
benchmark/.claude/checkpoints/1754447975.json
benchmark/.claude/checkpoints/1754447977.json
benchmark/.claude/checkpoints/1754447978.json
benchmark/.claude/checkpoints/1754447986.json
benchmark/.claude/checkpoints/1754447988.json
benchmark/.claude/checkpoints/1754448003.json
benchmark/.claude/checkpoints/1754448005.json
benchmark/.claude/checkpoints/1754448023.json
benchmark/.claude/checkpoints/1754448025.json
benchmark/.claude/checkpoints/summary-session-20250806-020959.md
benchmark/.claude/checkpoints/task-1754446496.json
benchmark/.claude/checkpoints/task-1754447669.json
benchmark/CLI_USAGE.md
benchmark/OPTIMIZATION_WARNING_FIX_REPORT.md
benchmark/PROJECT_SUMMARY.md
benchmark/README.md
benchmark/__pycache__/hello_world.cpython-312.pyc
benchmark/archive/old-files/hello_world.js
benchmark/archive/old-files/hello_world.test.js
benchmark/archive/old-files/optimization_demo_results.json
benchmark/archive/old-files/quick_real_test.py
benchmark/archive/old-files/real_benchmark_results.json
benchmark/archive/old-files/simple_load_test_results.json
benchmark/archive/old-files/simple_test_results.json
benchmark/archive/old-files/test_hello_world.js
benchmark/archive/old-files/test_real_integration.py
benchmark/archive/old-reports/AGENT2_IMPORT_FIXES_REPORT.md
benchmark/archive/old-reports/CLEANUP_REPORT.md
benchmark/archive/old-reports/GITHUB_ISSUE_599_COMPLETION.md
benchmark/archive/old-reports/GITHUB_ISSUE_599_UPDATE.md
benchmark/archive/old-reports/README.md
benchmark/archive/old-reports/README_HELLO_WORLD.md
benchmark/archive/old-reports/REAL_BENCHMARKS_README.md
benchmark/archive/old-reports/REAL_BENCHMARK_COMPLETION_REPORT.md
benchmark/archive/old-reports/REAL_CLAUDE_FLOW_INTEGRATION_REPORT.md
benchmark/archive/old-reports/REORGANIZATION_REPORT.md
benchmark/archive/old-reports/VALIDATION_REPORT.md
benchmark/archive/old-reports/api_development_accuracy_claude.md
benchmark/archive/old-reports/api_development_speed_claude.md
benchmark/archive/old-reports/api_development_tokens_claude.md
benchmark/archive/old-reports/github_issue_599_comment.md
benchmark/archive/old-reports/ml_pipeline_claude.md
benchmark/archive/old-reports/performance_optimization_claude.md
benchmark/archive/old-reports/testing_automation_claude.md
benchmark/ci_performance_integration.py
benchmark/compare_optimizations.py
benchmark/examples/.claude-flow/metrics/agent-metrics.json
benchmark/examples/.claude-flow/metrics/performance.json
benchmark/examples/.claude-flow/metrics/task-metrics.json
benchmark/examples/.claude/checkpoints/1754447043.json
benchmark/examples/.claude/checkpoints/1754447045.json
benchmark/examples/.claude/checkpoints/1754448240.json
benchmark/examples/.claude/checkpoints/1754448242.json
benchmark/examples/.claude/checkpoints/1754448294.json
benchmark/examples/.claude/checkpoints/1754448295.json
benchmark/examples/.claude/checkpoints/1754448380.json
benchmark/examples/.claude/checkpoints/1754448382.json
benchmark/examples/.claude/checkpoints/1754448488.json
benchmark/examples/.claude/checkpoints/1754448490.json
benchmark/examples/.claude/checkpoints/1754448531.json
benchmark/examples/.claude/checkpoints/1754448533.json
benchmark/examples/.claude/checkpoints/1754448586.json
benchmark/examples/.claude/checkpoints/1754448587.json
benchmark/examples/.claude/checkpoints/1754448738.json
benchmark/examples/.claude/checkpoints/1754448741.json
benchmark/examples/.claude/checkpoints/1754448794.json
benchmark/examples/.claude/checkpoints/1754448796.json
benchmark/examples/ORGANIZATION_REPORT.md
benchmark/examples/README.md
benchmark/examples/__pycache__/demo_real_benchmark.cpython-312.pyc
benchmark/examples/advanced/comparative_analysis.py
benchmark/examples/advanced/demo_comprehensive.py
benchmark/examples/advanced/demo_mle_star.py
benchmark/examples/advanced/mle_star_benchmark_example.py
benchmark/examples/advanced/optimization_demo.py
benchmark/examples/advanced/optimization_suite.py
benchmark/examples/advanced/parallel_benchmark_demo.py
benchmark/examples/advanced/parallel_benchmarks.py
benchmark/examples/basic/claude_optimizer_example.py
benchmark/examples/basic/example_usage.py
benchmark/examples/basic/simple_hive_mind.py
benchmark/examples/basic/simple_sparc.py
benchmark/examples/basic/simple_swarm.py
benchmark/examples/cli/batch_benchmarks.sh
benchmark/examples/cli/cli_examples.sh
benchmark/examples/demo_comprehensive.py
benchmark/examples/demo_mle_star.py
benchmark/examples/demo_real_benchmark.py
benchmark/examples/example_usage.py
benchmark/examples/quick_test.py
benchmark/examples/real/demo_real_benchmark.py
benchmark/examples/real/real_benchmark_examples.py
benchmark/examples/real/real_hive_mind_benchmark.py
benchmark/examples/real/real_metrics_demo.py
benchmark/examples/real/real_performance.py
benchmark/examples/real/real_sparc_benchmark.py
benchmark/examples/real/real_swarm_benchmark.py
benchmark/examples/real/real_token_tracking.py
benchmark/examples/real/verify_real_integration.py
benchmark/examples/reports/metrics_edcb3fff-6fe4-432c-ab07-f01483a4cb46.json
benchmark/examples/reports/process_report_edcb3fff-6fe4-432c-ab07-f01483a4cb46.json
benchmark/examples/reports/real-benchmark-auto-centralized_edcb3fff-6fe4-432c-ab07-f01483a4cb46.json
benchmark/mle_star_benchmark_example.py
benchmark/performance_dashboard.py
benchmark/quick_test_integration.py
benchmark/run_real_benchmarks.py
benchmark/src/swarm_benchmark/cli/__pycache__/main.cpython-312.pyc
benchmark/src/swarm_benchmark/cli/main.py
benchmark/src/swarm_benchmark/core/__pycache__/benchmark_engine.cpython-312.pyc
benchmark/src/swarm_benchmark/core/__pycache__/claude_flow_real_executor.cpython-312.pyc
benchmark/src/swarm_benchmark/core/__pycache__/optimized_benchmark_engine.cpython-312.pyc
benchmark/src/swarm_benchmark/core/__pycache__/real_benchmark_engine_v2.cpython-312.pyc
benchmark/src/swarm_benchmark/core/benchmark_engine.py
benchmark/src/swarm_benchmark/core/claude_flow_real_executor.py
benchmark/src/swarm_benchmark/core/optimized_benchmark_engine.py
benchmark/src/swarm_benchmark/core/real_benchmark_engine_v2.py
benchmark/src/swarm_benchmark/optimization/__init__.py
benchmark/src/swarm_benchmark/optimization/__pycache__/__init__.cpython-312.pyc
benchmark/src/swarm_benchmark/optimization/__pycache__/engine.cpython-312.pyc
benchmark/src/swarm_benchmark/optimization/engine.py
benchmark/src/swarm_benchmark/scenarios/__init__.py
benchmark/src/swarm_benchmark/scenarios/__pycache__/__init__.cpython-312.pyc
benchmark/src/swarm_benchmark/scenarios/__pycache__/real_benchmarks.cpython-312.pyc
benchmark/src/swarm_benchmark/scenarios/real_benchmarks.py
benchmark/test_claude_optimizer.py
benchmark/test_integration.py
benchmark/test_mle_star_integration.py
benchmark/test_real_benchmark_engine.py
benchmark/test_real_benchmarks.py
benchmark/test_real_claude_flow.py
benchmark/test_real_execution.py
benchmark/test_real_metrics.py
benchmark/test_real_simple.py
benchmark/test_simple_run.py
benchmark/tests/.claude-flow/metrics/performance.json
benchmark/tests/.claude-flow/metrics/task-metrics.json
benchmark/tests/.claude/checkpoints/1754448082.json
benchmark/tests/.claude/checkpoints/1754448084.json
benchmark/tests/.claude/checkpoints/1754448093.json
benchmark/tests/.claude/checkpoints/1754448094.json
benchmark/tests/.claude/checkpoints/1754448133.json
benchmark/tests/.claude/checkpoints/1754448135.json
benchmark/tests/.claude/checkpoints/1754448139.json
benchmark/tests/.claude/checkpoints/1754448141.json
benchmark/tests/.claude/checkpoints/1754448169.json
benchmark/tests/.claude/checkpoints/1754448171.json
benchmark/tests/__pycache__/conftest.cpython-312-pytest-8.4.0.pyc
benchmark/tests/__pycache__/test_cli.cpython-312-pytest-8.4.0.pyc
benchmark/tests/fixtures/__pycache__/test_data.cpython-312.pyc
benchmark/tests/integration/__pycache__/__init__.cpython-312.pyc
benchmark/tests/integration/__pycache__/test_real_claude_flow_integration.cpython-312-pytest-8.4.0.pyc
benchmark/tests/integration/hello_world.py
benchmark/tests/integration/quick_test_integration.py
benchmark/tests/integration/test_claude_optimizer.py
benchmark/tests/integration/test_hello_world.py
benchmark/tests/integration/test_integration.py
benchmark/tests/integration/test_mle_star_integration.py
benchmark/tests/integration/test_real_benchmark_engine.py
benchmark/tests/integration/test_real_claude_flow.py
benchmark/tests/integration/test_real_claude_flow_integration.py
benchmark/tests/integration/test_real_metrics.py
benchmark/tests/integration/test_simple_run.py
benchmark/tests/test_cli.py
benchmark/tools/continuous_performance_monitor.py
benchmark/tools/scripts/hive-mind-load-test.py
benchmark/tools/scripts/hive-mind-stress-test.py
benchmark/tools/scripts/run-load-tests.py
benchmark/tools/scripts/run_performance_tests.py
benchmark/tools/scripts/simple-load-test.py
benchmark/tools/scripts/swarm_performance_suite.py
benchmark/validate_cli.py
claude-flow-wiki
reports/benchmark-development-distributed_cb162c55-4775-41e0-933c-233bf4ece53c.json

## Recent Commits
93562696 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/PROJECT_SUMMARY.md
9ede9962 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/CLI_USAGE.md
b22d0a73 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/quick_test.py
9bdba820 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/ORGANIZATION_REPORT.md
9e590ec0 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/README.md
cd28ae69 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/real/real_performance.py
c9fc55fc ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/real/real_token_tracking.py
ff44b4b8 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/cli/batch_benchmarks.sh
592188c9 ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/cli/cli_examples.sh
30e9008b ğŸ”– Checkpoint: Edit /workspaces/claude-code-flow/benchmark/examples/real/real_swarm_benchmark.py

## GitHub Releases Created
No GitHub releases

## Rollback Instructions
To rollback to a specific checkpoint:
```bash
# List all checkpoints
git tag -l checkpoint-* | sort -r

# List GitHub releases
gh release list

# Rollback to a checkpoint
git checkout checkpoint-YYYYMMDD-HHMMSS
```</doc><doc title="Organization Report" desc="worked example."># Examples Organization Report

## âœ… Organization Complete

The benchmark examples have been successfully organized into a clear, logical structure with proper categorization and comprehensive documentation.

## ğŸ“ Final Structure

```
benchmark/examples/
â”œâ”€â”€ README.md                          # Main documentation
â”œâ”€â”€ ORGANIZATION_REPORT.md             # This report
â”œâ”€â”€ basic/                             # ğŸŸ¢ 5 files - Simple examples
â”‚   â”œâ”€â”€ simple_swarm.py               # Basic swarm benchmark
â”‚   â”œâ”€â”€ simple_hive_mind.py           # Basic hive-mind benchmark  
â”‚   â”œâ”€â”€ simple_sparc.py               # Basic SPARC benchmark
â”‚   â”œâ”€â”€ claude_optimizer_example.py   # Optimizer usage
â”‚   â””â”€â”€ example_usage.py              # General patterns
â”œâ”€â”€ advanced/                          # ğŸŸ¡ 8 files - Complex examples
â”‚   â”œâ”€â”€ parallel_benchmarks.py        # Concurrent execution
â”‚   â”œâ”€â”€ optimization_suite.py         # Performance tuning
â”‚   â”œâ”€â”€ comparative_analysis.py       # Multi-strategy comparison
â”‚   â”œâ”€â”€ demo_comprehensive.py         # Feature demonstration
â”‚   â”œâ”€â”€ demo_mle_star.py             # MLE-STAR implementation
â”‚   â”œâ”€â”€ mle_star_benchmark_example.py # MLE-STAR benchmarking
â”‚   â”œâ”€â”€ parallel_benchmark_demo.py    # Parallel patterns
â”‚   â””â”€â”€ optimization_demo.py          # Optimization patterns
â”œâ”€â”€ real/                              # ğŸ”´ 9 files - Production examples
â”‚   â”œâ”€â”€ real_swarm_benchmark.py       # Real swarm execution
â”‚   â”œâ”€â”€ real_token_tracking.py        # Token/cost analysis
â”‚   â”œâ”€â”€ real_performance.py           # Performance monitoring
â”‚   â”œâ”€â”€ real_hive_mind_benchmark.py   # Real hive-mind execution
â”‚   â”œâ”€â”€ real_sparc_benchmark.py       # Real SPARC execution
â”‚   â”œâ”€â”€ real_benchmark_examples.py    # Various scenarios
â”‚   â”œâ”€â”€ real_metrics_demo.py          # Metrics collection
â”‚   â”œâ”€â”€ demo_real_benchmark.py        # Real benchmark demo
â”‚   â””â”€â”€ verify_real_integration.py    # Integration verification
â”œâ”€â”€ cli/                               # âš« 2 files - CLI examples
â”‚   â”œâ”€â”€ cli_examples.sh               # CLI usage examples
â”‚   â””â”€â”€ batch_benchmarks.sh           # Batch execution
â””â”€â”€ output/                            # ğŸ“Š 4 files - Results storage
    â”œâ”€â”€ aggregated_metrics.json
    â”œâ”€â”€ performance_metrics.json
    â”œâ”€â”€ process_report.json
    â””â”€â”€ real_integration_results.json
```

## ğŸ“Š Statistics

- **Total Files**: 28 example files
- **Basic Examples**: 5 files (learning and simple usage)
- **Advanced Examples**: 8 files (complex features and analysis)
- **Real Examples**: 9 files (production-ready benchmarks)
- **CLI Examples**: 2 executable scripts
- **Output Files**: 4 pre-existing result files
- **Documentation**: 2 comprehensive documentation files

## ğŸ¯ Content by Category

### Basic Examples (Learning & Testing)
- **simple_swarm.py**: Demonstrates basic swarm coordination with CLI and Python API
- **simple_hive_mind.py**: Shows collective intelligence and neural coordination patterns
- **simple_sparc.py**: Implements SPARC methodology with TDD integration
- **claude_optimizer_example.py**: Claude optimizer usage patterns
- **example_usage.py**: General benchmark usage examples

### Advanced Examples (Complex Features)
- **parallel_benchmarks.py**: Concurrent execution with ThreadPoolExecutor and asyncio
- **optimization_suite.py**: Performance tuning with resource monitoring and scoring
- **comparative_analysis.py**: Statistical comparison across methodologies and strategies
- **demo_comprehensive.py**: Comprehensive feature demonstration
- **optimization_demo.py**: Optimization pattern examples
- **parallel_benchmark_demo.py**: Advanced parallel execution patterns
- **MLE-STAR examples**: Machine learning ensemble implementations

### Real Examples (Production-Ready)
- **real_swarm_benchmark.py**: Full production swarm execution with comprehensive metrics
- **real_token_tracking.py**: Token consumption analysis with cost optimization
- **real_performance.py**: System performance monitoring with bottleneck identification
- **real_hive_mind_benchmark.py**: Production hive-mind collective intelligence
- **real_sparc_benchmark.py**: Production SPARC methodology execution
- **Integration examples**: Real claude-flow integration and verification

### CLI Examples (Command-Line)
- **cli_examples.sh**: 50+ CLI command examples across all methodologies
- **batch_benchmarks.sh**: Automated batch execution with analysis and reporting

## ğŸ”§ Key Features Implemented

### Comprehensive Example Coverage
- âœ… Basic usage patterns for all three methodologies (Swarm, Hive-Mind, SPARC)
- âœ… Advanced parallel and concurrent execution strategies
- âœ… Real production-ready benchmarks with actual claude-flow execution
- âœ… CLI interface demonstrations and batch processing
- âœ… Token tracking and cost optimization analysis
- âœ… Performance monitoring and system resource analysis

### Code Quality Standards
- âœ… Comprehensive docstrings and inline comments
- âœ… Type hints and dataclasses for structured data
- âœ… Error handling and timeout management
- âœ… Resource monitoring and cleanup
- âœ… JSON/CSV output for analysis integration
- âœ… Modular, reusable code patterns

### Documentation Excellence
- âœ… Main README with quick start guide and best practices
- âœ… Clear directory structure explanation
- âœ… Usage examples for each category
- âœ… Troubleshooting and configuration guidance
- âœ… CI/CD integration examples
- âœ… Contributing guidelines

## ğŸš€ Usage Patterns

### For New Users (Start Here)
```bash
cd basic/
python3 simple_swarm.py          # Learn swarm basics
python3 simple_hive_mind.py      # Understand collective intelligence
python3 simple_sparc.py          # Explore SPARC methodology
```

### For Production Assessment
```bash
cd real/
python3 real_swarm_benchmark.py  # Full production benchmark
python3 real_token_tracking.py   # Cost analysis
python3 real_performance.py      # Performance monitoring
```

### For Advanced Analysis
```bash
cd advanced/
python3 comparative_analysis.py  # Compare strategies
python3 optimization_suite.py    # Performance tuning
python3 parallel_benchmarks.py   # Concurrent execution
```

### For Automation
```bash
cd cli/
./cli_examples.sh                # Learn CLI patterns
./batch_benchmarks.sh           # Automated testing
```

## ğŸ“ˆ Benefits Achieved

### Organization Benefits
- **Clear Learning Path**: Progressive complexity from basic â†’ advanced â†’ real â†’ CLI
- **Use Case Focused**: Examples grouped by practical application scenarios
- **Self-Contained**: Each example is complete and runnable independently
- **Comprehensive Coverage**: All methodologies, strategies, and coordination modes

### Technical Benefits  
- **Real Integration**: Examples use actual claude-flow commands and APIs
- **Comprehensive Metrics**: Token tracking, performance monitoring, resource analysis
- **Production Ready**: Error handling, timeouts, resource cleanup
- **Analysis Friendly**: JSON/CSV outputs for further analysis

### User Experience Benefits
- **Quick Start**: README provides immediate usage guidance
- **Best Practices**: Examples demonstrate optimal usage patterns  
- **Troubleshooting**: Common issues and solutions documented
- **Extensible**: Clear patterns for adding new examples

## ğŸ‰ Mission Accomplished

The examples directory now provides:

1. **ğŸ¯ Clear Learning Path**: From simple concepts to production deployment
2. **ğŸ“Š Comprehensive Coverage**: All methodologies, strategies, and use cases
3. **ğŸ”§ Production Ready**: Real claude-flow integration with proper error handling
4. **ğŸ“– Excellent Documentation**: Clear usage guidance and best practices
5. **ğŸš€ Easy Automation**: CLI scripts for batch processing and CI/CD integration

**Result**: A professional, well-organized examples suite that serves both learning and production needs, with clear progression paths and comprehensive real-world applicability.

---

*Organization completed successfully. All examples are now properly categorized, documented, and ready for use.*</doc><doc title="README" desc="worked example."># Claude Flow Benchmark Examples

This directory contains organized examples for using the Claude Flow benchmark suite with different strategies, coordination modes, and real-world scenarios.

## Directory Structure

```
examples/
â”œâ”€â”€ basic/                  # Simple examples for getting started
â”œâ”€â”€ advanced/               # Complex examples with advanced features
â”œâ”€â”€ real/                   # Real claude-flow execution examples
â”œâ”€â”€ cli/                    # Command-line interface examples
â””â”€â”€ output/                 # Generated results and metrics
```

## Basic Examples (`basic/`)

**Getting started with simple benchmarks:**

- `simple_swarm.py` - Basic swarm coordination benchmark
- `simple_hive_mind.py` - Basic hive-mind collective intelligence
- `simple_sparc.py` - Basic SPARC methodology (TDD approach)
- `claude_optimizer_example.py` - Claude optimizer usage
- `example_usage.py` - General usage patterns

**Run a basic example:**
```bash
cd basic/
python3 simple_swarm.py
```

## Advanced Examples (`advanced/`)

**Complex benchmarks with advanced features:**

- `parallel_benchmarks.py` - Concurrent execution strategies
- `optimization_suite.py` - Performance tuning and efficiency analysis
- `comparative_analysis.py` - Multi-strategy comparison
- `demo_comprehensive.py` - Comprehensive feature demonstration
- `parallel_benchmark_demo.py` - Parallel execution patterns

**Run an advanced example:**
```bash
cd advanced/
python3 parallel_benchmarks.py
```

## Real Examples (`real/`)

**Production-ready benchmarks with actual claude-flow execution:**

- `real_swarm_benchmark.py` - Real swarm execution with comprehensive metrics
- `real_token_tracking.py` - Token consumption analysis and cost optimization
- `real_performance.py` - System performance monitoring and analysis
- `real_hive_mind_benchmark.py` - Real hive-mind collective intelligence
- `real_sparc_benchmark.py` - Real SPARC methodology execution
- `real_benchmark_examples.py` - Various real benchmark scenarios

**Run a real example:**
```bash
cd real/
python3 real_swarm_benchmark.py
```

## CLI Examples (`cli/`)

**Command-line interface demonstrations:**

- `cli_examples.sh` - Comprehensive CLI usage examples
- `batch_benchmarks.sh` - Batch execution scripts

**Run CLI examples:**
```bash
cd cli/
./cli_examples.sh
```

**Run batch benchmarks:**
```bash
cd cli/
./batch_benchmarks.sh
```

## Quick Start

### 1. Simple Swarm Benchmark
```bash
python3 basic/simple_swarm.py
```

### 2. Real Performance Analysis
```bash
python3 real/real_performance.py
```

### 3. Token Tracking and Cost Analysis
```bash
python3 real/real_token_tracking.py
```

### 4. Comprehensive CLI Demo
```bash
./cli/cli_examples.sh
```

## Example Types by Use Case

### Learning and Testing
- `basic/simple_*.py` - Start here for learning
- `cli/cli_examples.sh` - Command-line reference

### Development and Optimization
- `advanced/optimization_suite.py` - Performance tuning
- `real/real_performance.py` - System monitoring
- `real/real_token_tracking.py` - Cost optimization

### Production Assessment
- `real/real_swarm_benchmark.py` - Production readiness
- `advanced/comparative_analysis.py` - Strategy comparison
- `cli/batch_benchmarks.sh` - Automated testing

### Research and Analysis
- `advanced/parallel_benchmarks.py` - Concurrent execution
- `real/real_hive_mind_benchmark.py` - Collective intelligence
- `advanced/comparative_analysis.py` - Multi-methodology comparison

## Output and Results

All examples save results to the `output/` directory with timestamps:

```
output/
â”œâ”€â”€ simple_swarm_metrics.json
â”œâ”€â”€ parallel_benchmark_results.json
â”œâ”€â”€ token_tracking_metrics_*.json
â”œâ”€â”€ performance_analysis_*.json
â””â”€â”€ batch_results_*/
```

## Requirements

**Python Dependencies:**
```bash
pip install psutil  # For system monitoring
```

**Claude Flow:**
```bash
npm install -g claude-flow@alpha
```

**Benchmark Suite:**
```bash
pip install -e .  # From benchmark root directory
```

## Configuration

Most examples can be configured by modifying parameters at the top of each script:

```python
# Example configuration
config = {
    "agents": 5,
    "coordination": "hierarchical",
    "strategy": "development",
    "timeout": 180
}
```

## Best Practices

1. **Start Simple**: Begin with `basic/` examples
2. **Monitor Resources**: Use `real/real_performance.py` for system analysis
3. **Track Costs**: Use `real/real_token_tracking.py` for cost optimization
4. **Compare Strategies**: Use `advanced/comparative_analysis.py`
5. **Automate Testing**: Use `cli/batch_benchmarks.sh`

## Integration with CI/CD

Use batch scripts for automated testing:

```yaml
# GitHub Actions example
- name: Run Benchmark Suite
  run: |
    cd benchmark/examples/cli/
    ./batch_benchmarks.sh
    
- name: Upload Results
  uses: actions/upload-artifact@v3
  with:
    name: benchmark-results
    path: benchmark/examples/output/
```

## Troubleshooting

**Common Issues:**

1. **Command not found**: Ensure `claude-flow@alpha` is installed globally
2. **Permission denied**: Run `chmod +x cli/*.sh`
3. **Import errors**: Install with `pip install -e .` from benchmark root
4. **Timeout errors**: Increase timeout values in configurations

**Debug Mode:**

Add `--debug` flag to commands for verbose output:
```bash
python3 real/real_swarm_benchmark.py --debug
```

## Contributing

To add new examples:

1. Choose appropriate directory (`basic/`, `advanced/`, `real/`, `cli/`)
2. Follow naming convention: `{purpose}_{type}_{description}.py`
3. Include comprehensive docstrings and comments
4. Save outputs to `output/` directory with timestamps
5. Update this README with usage instructions

## Support

- **Documentation**: `/workspaces/claude-code-flow/benchmark/docs/`
- **Issues**: Create GitHub issues with example logs
- **Community**: Join discussions in GitHub Discussions

---

**Next Steps:**
1. Try basic examples to understand concepts
2. Run real examples for production insights
3. Use CLI examples for automation
4. Customize advanced examples for specific needs</doc><doc title="Comparative Analysis" desc="worked example.">#!/usr/bin/env python3
"""
Advanced comparative analysis between different coordination strategies and methodologies.

This example demonstrates:
- Multi-strategy comparison
- Statistical analysis of performance
- Coordination pattern effectiveness
- Methodology benchmarking (Swarm vs Hive-Mind vs SPARC)
"""

import subprocess
import sys
import json
import time
import statistics
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict
import itertools

@dataclass
class ComparisonConfig:
    """Configuration for comparative analysis."""
    methodology: str  # 'swarm', 'hive-mind', 'sparc'
    strategy: str
    coordination: str
    agents: int
    task_complexity: str  # 'simple', 'medium', 'complex'

@dataclass
class ComparisonResult:
    """Result from a comparative benchmark."""
    config: ComparisonConfig
    execution_time: float
    success: bool
    quality_score: float
    token_consumption: int
    resource_utilization: Dict[str, float]
    metrics: Dict[str, Any]
    error: Optional[str] = None

class ComparativeAnalysisEngine:
    """Engine for running comparative analysis across methodologies."""
    
    def __init__(self):
        self.results: List[ComparisonResult] = []
        self.task_definitions = {
            "simple": "Create a hello world function with basic error handling",
            "medium": "Build a REST API with authentication and basic CRUD operations", 
            "complex": "Design and implement a distributed microservices architecture with monitoring"
        }
    
    def generate_comparison_matrix(self) -> List[ComparisonConfig]:
        """Generate comprehensive comparison matrix."""
        methodologies = ["swarm", "hive-mind", "sparc"]
        
        # Strategy mappings for each methodology
        strategy_mappings = {
            "swarm": ["development", "optimization", "research", "analysis"],
            "hive-mind": ["collective", "consensus", "distributed", "adaptive"],
            "sparc": ["tdd", "specification", "architecture", "refinement"]
        }
        
        coordination_mappings = {
            "swarm": ["hierarchical", "mesh", "ring", "star"],
            "hive-mind": ["collective", "mesh", "distributed", "consensus"],
            "sparc": ["hierarchical", "sequential", "parallel", "adaptive"]
        }
        
        agent_counts = [3, 5, 7]
        task_complexities = ["simple", "medium", "complex"]
        
        configs = []
        
        for methodology in methodologies:
            strategies = strategy_mappings[methodology]
            coordinations = coordination_mappings[methodology]
            
            # Create balanced combinations
            for strategy, coordination, agents, complexity in itertools.product(
                strategies[:2],  # Limit to 2 strategies per methodology
                coordinations[:2],  # Limit to 2 coordination modes
                agent_counts[:2],  # Limit to 2 agent counts  
                task_complexities
            ):
                configs.append(ComparisonConfig(
                    methodology=methodology,
                    strategy=strategy,
                    coordination=coordination,
                    agents=agents,
                    task_complexity=complexity
                ))
        
        return configs
    
    def execute_comparison_benchmark(self, config: ComparisonConfig) -> ComparisonResult:
        """Execute a single comparison benchmark."""
        print(f"ğŸ“Š Running: {config.methodology}-{config.strategy}-{config.coordination} ({config.agents} agents, {config.task_complexity})")
        
        start_time = time.time()
        task = self.task_definitions[config.task_complexity]
        
        try:
            # Build command based on methodology
            cmd = self._build_methodology_command(config, task)
            
            # Execute benchmark
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=180,  # 3 minute timeout for complex tasks
                cwd="/workspaces/claude-code-flow/benchmark"
            )
            
            execution_time = time.time() - start_time
            
            if result.returncode == 0:
                # Parse and analyze output
                metrics = self._parse_comparison_output(result.stdout)
                quality_score = self._calculate_quality_score(result.stdout, config)
                token_consumption = self._estimate_token_consumption(result.stdout)
                resource_util = self._estimate_resource_utilization(execution_time, config)
                
                return ComparisonResult(
                    config=config,
                    execution_time=execution_time,
                    success=True,
                    quality_score=quality_score,
                    token_consumption=token_consumption,
                    resource_utilization=resource_util,
                    metrics=metrics
                )
            else:
                return ComparisonResult(
                    config=config,
                    execution_time=execution_time,
                    success=False,
                    quality_score=0.0,
                    token_consumption=0,
                    resource_utilization={},
                    metrics={},
                    error=result.stderr
                )
                
        except subprocess.TimeoutExpired:
            return ComparisonResult(
                config=config,
                execution_time=180.0,
                success=False,
                quality_score=0.0,
                token_consumption=0,
                resource_utilization={},
                metrics={},
                error="Timeout exceeded"
            )
        except Exception as e:
            return ComparisonResult(
                config=config,
                execution_time=time.time() - start_time,
                success=False,
                quality_score=0.0,
                token_consumption=0,
                resource_utilization={},
                metrics={},
                error=str(e)
            )
    
    def _build_methodology_command(self, config: ComparisonConfig, task: str) -> List[str]:
        """Build command specific to methodology."""
        base_cmd = ["swarm-benchmark", "real"]
        
        if config.methodology == "swarm":
            cmd = base_cmd + [
                "swarm", task,
                "--strategy", config.strategy,
                "--coordination", config.coordination,
                "--max-agents", str(config.agents)
            ]
        elif config.methodology == "hive-mind":
            cmd = base_cmd + [
                "hive-mind", task,
                "--thinking-pattern", config.strategy,
                "--coordination", config.coordination,
                "--agents", str(config.agents)
            ]
        elif config.methodology == "sparc":
            cmd = base_cmd + [
                "sparc", task,
                "--mode", config.strategy,
                "--coordination", config.coordination,
                "--agents", str(config.agents)
            ]
        else:
            # Fallback to swarm
            cmd = base_cmd + [
                "swarm", task,
                "--strategy", "auto",
                "--max-agents", str(config.agents)
            ]
        
        return cmd
    
    def _parse_comparison_output(self, output: str) -> Dict[str, Any]:
        """Parse output for comparison metrics."""
        # Try JSON parsing first
        try:
            lines = output.strip().split('\n')
            for line in lines:
                if line.strip().startswith('{'):
                    return json.loads(line.strip())
        except:
            pass
        
        # Fallback analysis
        return {
            "output_length": len(output),
            "line_count": len(output.split('\n')),
            "success_markers": output.count("âœ…"),
            "warning_markers": output.count("âš ï¸"),
            "error_markers": output.count("âŒ"),
            "completion_indicators": output.count("Complete") + output.count("Finished"),
            "code_blocks": output.count("```"),
            "bullet_points": output.count("â€¢") + output.count("-"),
        }
    
    def _calculate_quality_score(self, output: str, config: ComparisonConfig) -> float:
        """Calculate quality score based on output analysis."""
        base_score = 50.0  # Baseline
        
        # Success indicators
        success_count = output.count("âœ…")
        completion_count = output.count("Complete") + output.count("Finished")
        base_score += (success_count * 5) + (completion_count * 3)
        
        # Error penalties
        error_count = output.count("âŒ")
        warning_count = output.count("âš ï¸")
        base_score -= (error_count * 10) + (warning_count * 3)
        
        # Complexity bonuses
        complexity_multiplier = {"simple": 1.0, "medium": 1.2, "complex": 1.5}
        base_score *= complexity_multiplier.get(config.task_complexity, 1.0)
        
        # Methodology-specific adjustments
        if config.methodology == "sparc":
            # SPARC typically produces more structured output
            structure_indicators = output.count("Specification") + output.count("Architecture")
            base_score += structure_indicators * 2
        elif config.methodology == "hive-mind":
            # Hive-mind should show consensus
            consensus_indicators = output.count("consensus") + output.count("collective")
            base_score += consensus_indicators * 3
        
        return max(0.0, min(100.0, base_score))
    
    def _estimate_token_consumption(self, output: str) -> int:
        """Estimate token consumption from output."""
        # Rough estimation: 1 token â‰ˆ 0.75 words
        word_count = len(output.split())
        return int(word_count * 1.33)  # Conservative estimate
    
    def _estimate_resource_utilization(self, execution_time: float, config: ComparisonConfig) -> Dict[str, float]:
        """Estimate resource utilization patterns."""
        # Model-based estimation
        base_cpu = 30.0  # Base CPU %
        base_memory = 100.0  # Base memory MB
        
        # Agent scaling
        agent_multiplier = 1.0 + (config.agents - 1) * 0.15
        
        # Methodology scaling
        methodology_multipliers = {
            "swarm": {"cpu": 1.0, "memory": 1.0},
            "hive-mind": {"cpu": 1.3, "memory": 1.2},  # More intensive
            "sparc": {"cpu": 0.9, "memory": 1.1}  # More structured
        }
        
        multipliers = methodology_multipliers.get(config.methodology, {"cpu": 1.0, "memory": 1.0})
        
        # Complexity scaling
        complexity_multipliers = {"simple": 1.0, "medium": 1.5, "complex": 2.2}
        complexity_mult = complexity_multipliers.get(config.task_complexity, 1.0)
        
        estimated_cpu = base_cpu * agent_multiplier * multipliers["cpu"] * complexity_mult
        estimated_memory = base_memory * agent_multiplier * multipliers["memory"] * complexity_mult
        
        return {
            "cpu_percent": min(100.0, estimated_cpu),
            "memory_mb": estimated_memory,
            "efficiency_score": max(0.0, 100.0 - (execution_time / 120.0) * 50)  # Efficiency based on time
        }
    
    def run_comparative_analysis(self) -> Dict[str, Any]:
        """Run complete comparative analysis."""
        print("ğŸ“Š Starting Comparative Analysis")
        print("=" * 45)
        
        configs = self.generate_comparison_matrix()
        print(f"ğŸ” Generated {len(configs)} comparison configurations")
        
        results = []
        successful_results = []
        
        for i, config in enumerate(configs[:12], 1):  # Limit to 12 for demo
            print(f"\n[{i}/12] ", end="")
            result = self.execute_comparison_benchmark(config)
            results.append(result)
            
            if result.success:
                successful_results.append(result)
                status = "âœ…"
            else:
                status = "âŒ"
            
            print(f"{status} {result.execution_time:.1f}s (Quality: {result.quality_score:.1f})")
        
        self.results = results
        
        # Perform statistical analysis
        statistical_analysis = self._perform_statistical_analysis(successful_results)
        
        # Generate comparative insights
        comparative_insights = self._generate_comparative_insights(successful_results)
        
        # Performance rankings
        performance_rankings = self._calculate_performance_rankings(successful_results)
        
        return {
            "total_comparisons": len(results),
            "successful_comparisons": len(successful_results),
            "success_rate": len(successful_results) / len(results) if results else 0,
            "statistical_analysis": statistical_analysis,
            "comparative_insights": comparative_insights,
            "performance_rankings": performance_rankings,
            "raw_results": [self._serialize_result(r) for r in results]
        }
    
    def _perform_statistical_analysis(self, results: List[ComparisonResult]) -> Dict[str, Any]:
        """Perform statistical analysis on results."""
        if not results:
            return {}
        
        # Group by methodology
        by_methodology = defaultdict(list)
        for result in results:
            by_methodology[result.config.methodology].append(result)
        
        methodology_stats = {}
        for methodology, method_results in by_methodology.items():
            execution_times = [r.execution_time for r in method_results]
            quality_scores = [r.quality_score for r in method_results]
            token_consumptions = [r.token_consumption for r in method_results]
            
            methodology_stats[methodology] = {
                "count": len(method_results),
                "execution_time": {
                    "mean": statistics.mean(execution_times),
                    "median": statistics.median(execution_times),
                    "stdev": statistics.stdev(execution_times) if len(execution_times) > 1 else 0,
                    "min": min(execution_times),
                    "max": max(execution_times)
                },
                "quality_score": {
                    "mean": statistics.mean(quality_scores),
                    "median": statistics.median(quality_scores),
                    "stdev": statistics.stdev(quality_scores) if len(quality_scores) > 1 else 0,
                    "min": min(quality_scores),
                    "max": max(quality_scores)
                },
                "token_consumption": {
                    "mean": statistics.mean(token_consumptions),
                    "median": statistics.median(token_consumptions),
                    "total": sum(token_consumptions)
                }
            }
        
        return methodology_stats
    
    def _generate_comparative_insights(self, results: List[ComparisonResult]) -> List[str]:
        """Generate insights from comparative analysis."""
        insights = []
        
        if not results:
            return ["No successful results to analyze"]
        
        # Methodology comparison
        by_methodology = defaultdict(list)
        for result in results:
            by_methodology[result.config.methodology].append(result)
        
        if len(by_methodology) > 1:
            avg_times = {}
            avg_quality = {}
            
            for methodology, method_results in by_methodology.items():
                avg_times[methodology] = statistics.mean([r.execution_time for r in method_results])
                avg_quality[methodology] = statistics.mean([r.quality_score for r in method_results])
            
            fastest_method = min(avg_times.items(), key=lambda x: x[1])
            highest_quality = max(avg_quality.items(), key=lambda x: x[1])
            
            insights.append(f"Fastest methodology: {fastest_method[0]} ({fastest_method[1]:.1f}s avg)")
            insights.append(f"Highest quality: {highest_quality[0]} ({highest_quality[1]:.1f} avg score)")
        
        # Coordination analysis
        by_coordination = defaultdict(list)
        for result in results:
            by_coordination[result.config.coordination].append(result)
        
        if len(by_coordination) > 1:
            coord_performance = {}
            for coordination, coord_results in by_coordination.items():
                avg_time = statistics.mean([r.execution_time for r in coord_results])
                avg_quality = statistics.mean([r.quality_score for r in coord_results])
                coord_performance[coordination] = (avg_time + (100 - avg_quality)) / 2  # Combined score
            
            best_coordination = min(coord_performance.items(), key=lambda x: x[1])
            insights.append(f"Most effective coordination: {best_coordination[0]}")
        
        # Complexity scaling
        by_complexity = defaultdict(list)
        for result in results:
            by_complexity[result.config.task_complexity].append(result)
        
        if len(by_complexity) > 1:
            complexity_scaling = {}
            for complexity, comp_results in by_complexity.items():
                avg_time = statistics.mean([r.execution_time for r in comp_results])
                complexity_scaling[complexity] = avg_time
            
            if "simple" in complexity_scaling and "complex" in complexity_scaling:
                scaling_factor = complexity_scaling["complex"] / complexity_scaling["simple"]
                insights.append(f"Complexity scaling factor: {scaling_factor:.1f}x (simple to complex)")
        
        # Agent scaling insights
        agent_groups = defaultdict(list)
        for result in results:
            agent_groups[result.config.agents].append(result)
        
        if len(agent_groups) > 1:
            agent_efficiency = {}
            for agent_count, agent_results in agent_groups.items():
                avg_time = statistics.mean([r.execution_time for r in agent_results])
                agent_efficiency[agent_count] = avg_time / agent_count  # Time per agent
            
            most_efficient = min(agent_efficiency.items(), key=lambda x: x[1])
            insights.append(f"Most efficient agent count: {most_efficient[0]} agents")
        
        return insights
    
    def _calculate_performance_rankings(self, results: List[ComparisonResult]) -> Dict[str, List[Dict[str, Any]]]:
        """Calculate performance rankings across different metrics."""
        if not results:
            return {}
        
        rankings = {
            "fastest_execution": sorted(results, key=lambda r: r.execution_time)[:5],
            "highest_quality": sorted(results, key=lambda r: r.quality_score, reverse=True)[:5],
            "most_efficient_tokens": sorted(results, key=lambda r: r.token_consumption)[:5],
            "best_overall": sorted(results, key=lambda r: (r.quality_score / max(r.execution_time, 1)), reverse=True)[:5]
        }
        
        serialized_rankings = {}
        for category, ranked_results in rankings.items():
            serialized_rankings[category] = [
                {
                    "methodology": r.config.methodology,
                    "strategy": r.config.strategy,
                    "coordination": r.config.coordination,
                    "agents": r.config.agents,
                    "complexity": r.config.task_complexity,
                    "execution_time": r.execution_time,
                    "quality_score": r.quality_score,
                    "token_consumption": r.token_consumption
                }
                for r in ranked_results
            ]
        
        return serialized_rankings
    
    def _serialize_result(self, result: ComparisonResult) -> Dict[str, Any]:
        """Serialize result for JSON storage."""
        return {
            "config": {
                "methodology": result.config.methodology,
                "strategy": result.config.strategy,
                "coordination": result.config.coordination,
                "agents": result.config.agents,
                "task_complexity": result.config.task_complexity
            },
            "execution_time": result.execution_time,
            "success": result.success,
            "quality_score": result.quality_score,
            "token_consumption": result.token_consumption,
            "resource_utilization": result.resource_utilization,
            "metrics": result.metrics,
            "error": result.error
        }

def save_comparative_analysis(analysis_results: Dict[str, Any]):
    """Save comparative analysis results."""
    output_dir = Path("/workspaces/claude-code-flow/benchmark/examples/output")
    output_dir.mkdir(exist_ok=True)
    
    # Save complete analysis
    with open(output_dir / "comparative_analysis_results.json", "w") as f:
        json.dump(analysis_results, f, indent=2)
    
    # Save statistical summary
    stats = analysis_results.get("statistical_analysis", {})
    with open(output_dir / "comparative_statistics.json", "w") as f:
        json.dump(stats, f, indent=2)
    
    # Save performance rankings
    rankings = analysis_results.get("performance_rankings", {})
    with open(output_dir / "performance_rankings.json", "w") as f:
        json.dump(rankings, f, indent=2)
    
    print(f"ğŸ“ Comparative analysis saved to: {output_dir}")

if __name__ == "__main__":
    print("ğŸ“Š Advanced Comparative Analysis")
    print("=" * 50)
    
    # Run comparative analysis
    engine = ComparativeAnalysisEngine()
    results = engine.run_comparative_analysis()
    
    # Display key findings
    print(f"\nğŸ“ˆ Analysis Results")
    print("=" * 25)
    print(f"Total comparisons: {results['total_comparisons']}")
    print(f"Success rate: {results['success_rate']:.1%}")
    
    # Show insights
    insights = results.get("comparative_insights", [])
    if insights:
        print(f"\nğŸ’¡ Key Insights:")
        for insight in insights[:5]:
            print(f"  â€¢ {insight}")
    
    # Show top performers
    rankings = results.get("performance_rankings", {})
    if "best_overall" in rankings and rankings["best_overall"]:
        best = rankings["best_overall"][0]
        print(f"\nğŸ† Best Overall Performer:")
        print(f"   {best['methodology']} with {best['strategy']} strategy")
        print(f"   Quality: {best['quality_score']:.1f}, Time: {best['execution_time']:.1f}s")
        print(f"   Coordination: {best['coordination']}, Agents: {best['agents']}")
    
    # Statistical summary
    stats = results.get("statistical_analysis", {})
    if stats:
        print(f"\nğŸ“Š Methodology Performance Summary:")
        for methodology, method_stats in stats.items():
            avg_time = method_stats.get("execution_time", {}).get("mean", 0)
            avg_quality = method_stats.get("quality_score", {}).get("mean", 0)
            print(f"   {methodology}: {avg_time:.1f}s avg, {avg_quality:.1f} quality")
    
    # Save results
    save_comparative_analysis(results)
    
    print(f"\nğŸ‰ Comparative Analysis Complete!")
    print("Analysis provides insights on:")
    print("- Methodology effectiveness comparison")
    print("- Coordination pattern performance")
    print("- Agent scaling characteristics")
    print("- Task complexity impact")
    print("- Optimization recommendations")</doc><doc title="Demo Comprehensive" desc="worked example.">#!/usr/bin/env python3
"""Comprehensive demonstration of the swarm benchmarking tool."""

import asyncio
import json
import sys
from pathlib import Path

# Add the src directory to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))
from swarm_benchmark.core.benchmark_engine import BenchmarkEngine
from swarm_benchmark.core.models import BenchmarkConfig, StrategyType, CoordinationMode


async def run_comprehensive_demo():
    """Run a comprehensive demonstration of all features."""
    print("ğŸš€ Starting Comprehensive Swarm Benchmark Demonstration")
    print("=" * 60)
    
    # Test scenarios with different strategy/mode combinations
    test_scenarios = [
        {
            "name": "Auto Strategy - Centralized",
            "objective": "Build a user authentication system",
            "strategy": StrategyType.AUTO,
            "mode": CoordinationMode.CENTRALIZED,
            "max_agents": 3
        },
        {
            "name": "Research Strategy - Distributed", 
            "objective": "Research cloud architecture patterns and best practices",
            "strategy": StrategyType.RESEARCH,
            "mode": CoordinationMode.DISTRIBUTED,
            "max_agents": 5
        },
        {
            "name": "Development Strategy - Hierarchical",
            "objective": "Develop a microservices REST API with authentication",
            "strategy": StrategyType.DEVELOPMENT,
            "mode": CoordinationMode.HIERARCHICAL,
            "max_agents": 6
        },
        {
            "name": "Analysis Strategy - Mesh",
            "objective": "Analyze user behavior patterns and generate insights",
            "strategy": StrategyType.ANALYSIS,
            "mode": CoordinationMode.MESH,
            "max_agents": 4
        },
        {
            "name": "Optimization Strategy - Hybrid",
            "objective": "Optimize database queries and improve application performance", 
            "strategy": StrategyType.OPTIMIZATION,
            "mode": CoordinationMode.HYBRID,
            "max_agents": 7
        },
        {
            "name": "Testing Strategy - Distributed",
            "objective": "Create comprehensive test suite with unit and integration tests",
            "strategy": StrategyType.TESTING,
            "mode": CoordinationMode.DISTRIBUTED,
            "max_agents": 4
        },
        {
            "name": "Maintenance Strategy - Centralized",
            "objective": "Update documentation and refactor legacy code components",
            "strategy": StrategyType.MAINTENANCE,
            "mode": CoordinationMode.CENTRALIZED,
            "max_agents": 2
        }
    ]
    
    results_summary = []
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ“‹ Test {i}/{len(test_scenarios)}: {scenario['name']}")
        print(f"   Objective: {scenario['objective']}")
        print(f"   Strategy: {scenario['strategy'].value}")
        print(f"   Mode: {scenario['mode'].value}")
        print(f"   Agents: {scenario['max_agents']}")
        
        # Create configuration
        config = BenchmarkConfig(
            name=f"demo-{scenario['strategy'].value}-{scenario['mode'].value}",
            description=f"Demo: {scenario['name']}",
            strategy=scenario['strategy'],
            mode=scenario['mode'],
            max_agents=scenario['max_agents'],
            output_formats=["json"],
            output_directory="./demo_reports",
            verbose=True
        )
        
        # Run benchmark
        engine = BenchmarkEngine(config)
        
        try:
            result = await engine.run_benchmark(scenario['objective'])
            
            if result['status'] == 'success':
                print(f"   âœ… Success - Duration: {result['duration']:.2f}s")
                
                # Extract key metrics
                if result['results']:
                    first_result = result['results'][0]
                    execution_time = first_result.get('execution_time', 0)
                    cpu_usage = first_result.get('resource_usage', {}).get('cpu_percent', 0)
                    memory_usage = first_result.get('resource_usage', {}).get('memory_mb', 0)
                    
                    summary = {
                        'scenario': scenario['name'],
                        'strategy': scenario['strategy'].value,
                        'mode': scenario['mode'].value,
                        'agents': scenario['max_agents'],
                        'duration': result['duration'],
                        'execution_time': execution_time,
                        'cpu_usage': cpu_usage,
                        'memory_usage': memory_usage,
                        'status': 'success'
                    }
                else:
                    summary = {
                        'scenario': scenario['name'],
                        'strategy': scenario['strategy'].value,
                        'mode': scenario['mode'].value,
                        'agents': scenario['max_agents'],
                        'duration': result['duration'],
                        'status': 'success'
                    }
            else:
                print(f"   âŒ Failed - Error: {result.get('error', 'Unknown error')}")
                summary = {
                    'scenario': scenario['name'],
                    'strategy': scenario['strategy'].value,
                    'mode': scenario['mode'].value,
                    'agents': scenario['max_agents'],
                    'status': 'failed',
                    'error': result.get('error', 'Unknown error')
                }
            
            results_summary.append(summary)
            
        except Exception as e:
            print(f"   âŒ Exception: {e}")
            results_summary.append({
                'scenario': scenario['name'],
                'strategy': scenario['strategy'].value,
                'mode': scenario['mode'].value,
                'agents': scenario['max_agents'],
                'status': 'exception',
                'error': str(e)
            })
        
        # Small delay between tests
        await asyncio.sleep(0.5)
    
    # Generate summary report
    print("\n" + "=" * 60)
    print("ğŸ“Š BENCHMARK SUMMARY REPORT")
    print("=" * 60)
    
    successful_tests = [r for r in results_summary if r['status'] == 'success']
    failed_tests = [r for r in results_summary if r['status'] != 'success']
    
    print(f"âœ… Successful Tests: {len(successful_tests)}/{len(test_scenarios)}")
    print(f"âŒ Failed Tests: {len(failed_tests)}")
    
    if successful_tests:
        print("\nğŸ† Performance Metrics:")
        avg_duration = sum(r.get('duration', 0) for r in successful_tests) / len(successful_tests)
        avg_execution = sum(r.get('execution_time', 0) for r in successful_tests) / len(successful_tests)
        
        print(f"   Average Benchmark Duration: {avg_duration:.2f}s")
        print(f"   Average Task Execution Time: {avg_execution:.2f}s")
        
        # Strategy performance
        print("\nğŸ“ˆ Strategy Performance:")
        strategy_performance = {}
        for result in successful_tests:
            strategy = result['strategy']
            if strategy not in strategy_performance:
                strategy_performance[strategy] = []
            strategy_performance[strategy].append(result.get('duration', 0))
        
        for strategy, durations in strategy_performance.items():
            avg_duration = sum(durations) / len(durations)
            print(f"   {strategy.capitalize()}: {avg_duration:.2f}s avg ({len(durations)} tests)")
        
        # Coordination mode performance
        print("\nğŸ”— Coordination Mode Performance:")
        mode_performance = {}
        for result in successful_tests:
            mode = result['mode']
            if mode not in mode_performance:
                mode_performance[mode] = []
            mode_performance[mode].append(result.get('duration', 0))
        
        for mode, durations in mode_performance.items():
            avg_duration = sum(durations) / len(durations)
            print(f"   {mode.capitalize()}: {avg_duration:.2f}s avg ({len(durations)} tests)")
    
    if failed_tests:
        print(f"\nâŒ Failed Tests:")
        for test in failed_tests:
            print(f"   {test['scenario']}: {test.get('error', 'Unknown error')}")
    
    # Save detailed summary
    summary_path = Path("./demo_reports/benchmark_summary.json")
    summary_path.parent.mkdir(exist_ok=True)
    
    with open(summary_path, 'w') as f:
        json.dump({
            "demonstration_results": results_summary,
            "summary_statistics": {
                "total_tests": len(test_scenarios),
                "successful_tests": len(successful_tests),
                "failed_tests": len(failed_tests),
                "success_rate": len(successful_tests) / len(test_scenarios) * 100,
                "strategy_coverage": len(set(r['strategy'] for r in results_summary)),
                "mode_coverage": len(set(r['mode'] for r in results_summary))
            }
        }, f, indent=2)
    
    print(f"\nğŸ’¾ Detailed summary saved to: {summary_path}")
    print(f"ğŸ“ Individual benchmark reports saved to: ./demo_reports/")
    
    print("\nğŸ‰ Comprehensive demonstration completed!")
    
    return results_summary


if __name__ == "__main__":
    results = asyncio.run(run_comprehensive_demo())</doc></examples><optional><doc title="Changelog" desc="optional reading."># Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [2.0.0-alpha.91] - 2025-08-21

> **ğŸš€ Claude Code Task Tool Integration Update**: Enhanced integration with Claude Code's Task tool for concurrent agent execution. Clear separation between MCP coordination tools and Claude Code's execution capabilities, with comprehensive documentation and examples for parallel agent spawning.

### âœ¨ New Features

#### ğŸ¯ Claude Code Task Tool Integration
- **Enhanced CLAUDE.md Templates**: Updated initialization templates with clear guidance
  - Explicit instructions that Claude Code's Task tool spawns agents for actual work
  - MCP tools clearly marked as coordination-only, not for execution
  - Step-by-step workflow: Optional MCP setup â†’ Required Task tool execution
  - Comprehensive examples of concurrent agent spawning patterns

- **Improved Swarm Prompts**: Updated swarm command prompts for better clarity
  - Prominent header emphasizing Task tool usage for agent execution
  - Clear visual separation between coordination and execution tools
  - Concrete examples showing ALL agents spawned in ONE message
  - Warning boxes highlighting critical concurrent execution patterns

- **Enhanced Hive Mind Prompts**: Restructured hive-mind spawn prompts
  - Three-step process clearly documented in prompts
  - Step 1: Optional MCP coordination setup
  - Step 2: REQUIRED Claude Code Task tool for agent spawning
  - Step 3: Batch ALL todos in single TodoWrite call (8-10 todos)

#### ğŸ“‹ Batch Operation Emphasis
- **TodoWrite Batching**: Strong emphasis on batching 5-10+ todos in ONE call
  - Clear examples showing proper todo batching patterns
  - Visual warnings against sequential todo updates
  - Concrete todo examples with priorities and statuses

- **Task Tool Concurrency**: Comprehensive examples of parallel agent execution
  - Full-stack development swarm examples (6-8 agents)
  - Research coordination patterns
  - Distributed system agent spawning
  - All with proper coordination hooks

#### ğŸ“š Documentation Improvements
- **Clear Separation of Concerns**:
  - âœ… Claude Code handles: Task tool, file operations, code generation, execution
  - âŒ MCP tools handle: Coordination setup, memory, performance tracking only
  - Visual formatting with emojis and boxes for clarity

- **Concrete Code Examples**:
  ```javascript
  // CORRECT Pattern - Single Message
  Task("Researcher", "Analyze patterns...", "researcher")
  Task("Coder", "Implement features...", "coder")
  Task("Tester", "Create tests...", "tester")
  TodoWrite { todos: [8-10 todos ALL in ONE call] }
  ```

### ğŸ”§ Technical Improvements

#### Prompt Generation Updates
- **generateHiveMindPrompt()**: Restructured to emphasize Task tool usage
  - Added getWorkerTypeInstructions() integration for agent-specific guidance
  - Clear step-by-step execution protocol
  - Visual examples of concurrent patterns

- **Swarm Prompt Updates**: Enhanced swarm initialization guidance
  - Separated MCP coordination from Task execution
  - Added critical execution reminders
  - Updated batch operation examples

### ğŸ“ˆ Version Updates
- Updated version to `2.0.0-alpha.91` across all files
- Updated `package.json`, `version.js`, `version.ts`
- New release notes in `--version` command output

### ğŸ“ Files Modified

#### Core Files Updated
- `src/cli/simple-commands/init/templates/claude-md.js` - CLAUDE.md template generation
- `src/cli/simple-commands/hive-mind.js` - generateHiveMindPrompt() function
- `src/cli/simple-commands/swarm.js` - swarm prompt generation
- `package.json` - Version bump to 2.0.0-alpha.91
- `src/core/version.js` - Fallback version update
- `src/core/version.ts` - TypeScript version update
- `bin/claude-flow.js` - Version display and release notes

### ğŸ› ï¸ Command Documentation Improvements

#### Complete Command File Generation
- **Fixed Init Command**: Now creates ALL 91 command documentation files
  - 10 swarm command files in `.claude/commands/swarm/`
  - 12 hive-mind command files in `.claude/commands/hive-mind/`
  - 5 agents documentation files in `.claude/commands/agents/`
  - All standard command documentation properly organized

- **Enhanced Template Structure**: Updated `enhanced-templates.js`
  - Added complete COMMAND_STRUCTURE with swarm, hive-mind, and agents categories
  - Comprehensive fallback documentation for all missing command files
  - Proper emphasis on Task tool usage in all agent-related docs

### ğŸ“ File Organization Rules
- **Never save to root folder**: All files properly organized in subdirectories
- Clear directory structure guidance in CLAUDE.md
- Proper organization for `/src`, `/tests`, `/docs`, `/config` directories

### ğŸ¯ Key Takeaways for Users

1. **Always use Claude Code's Task tool** to spawn agents that do actual work
2. **MCP tools are ONLY** for coordination setup, not execution
3. **Batch everything**: Spawn ALL agents in ONE message
4. **TodoWrite must batch**: Always include 5-10+ todos in ONE call
5. **Use coordination hooks**: Every agent must use claude-flow hooks
6. **Proper file organization**: Never save files to root directory

This release ensures users understand the critical distinction between:
- **MCP tools**: Coordinate and plan (the "brain")
- **Claude Code Task tool**: Execute and implement (the "hands")

## [2.0.0-alpha.90] - 2025-08-16

> **ğŸš€ Major MCP Implementation & Quality Update**: Delivered >95% functionality with 15+ real MCP tools, critical bug fixes, WASM neural networks, and reduced mock rate from 40% to <5%. This release represents our commitment to community feedback and real, working tools.

### âœ¨ New Features

#### ğŸ¯ Real MCP Tool Implementations
- **DAA Tools (6 tools)**: Complete Decentralized Autonomous Agent suite
  - `daa_agent_create` - Dynamic agent creation with unique ID tracking
  - `daa_capability_match` - Real capability scoring algorithm implementation
  - `daa_resource_alloc` - CPU/memory resource distribution system
  - `daa_lifecycle_manage` - Full state machine (created â†’ active â†’ idle â†’ terminated)
  - `daa_communication` - Inter-agent messaging with delivery confirmation
  - `daa_consensus` - Voting mechanism with configurable thresholds

- **Workflow Automation (6 tools)**: Complete workflow engine
  - `workflow_create` - Workflow storage with step dependencies
  - `workflow_execute` - Real execution tracking with status updates
  - `parallel_execute` - Concurrent task management using Promise.all
  - `batch_process` - Batch operation processing with configurable sizes
  - `workflow_export` - JSON/YAML export format support
  - `workflow_template` - Template management and retrieval system

- **Performance Monitoring (3 tools)**: Real system metrics
  - `performance_report` - Actual CPU, memory, uptime metrics from OS
  - `bottleneck_analyze` - Real bottleneck detection algorithms
  - `memory_analytics` - Process memory usage from process.memoryUsage()

#### ğŸ§  WASM Neural Networks
- **Real WebAssembly Integration**: Discovered and integrated actual WASM modules
  - `ruv-fann.wasm` - Fast Artificial Neural Network engine
  - `ruv_swarm_simd.wasm` - SIMD-optimized operations
  - `neuro-divergent.wasm` - Cognitive pattern processing
  - Not simulations - actual neural network processing capabilities

#### ğŸ“Š Agent Tracking System
- **Centralized Agent Registry**: New `agent-tracker.js` implementation
  - Real agent storage and retrieval
  - Persistent tracking across operations
  - Fixed `agent_list` to return actual tracked agents
  - Fixed `agent_metrics` to show real performance data

### ğŸ› Bug Fixes

#### Critical Runtime Errors Fixed
- **agent_metrics**: Fixed `neuralNetworks.map is not a function` error
  - Added type safety wrapper ensuring neuralNetworks is always an array
  - Proper initialization of neural network data structures

- **swarm_monitor**: Fixed `recentEvents.map is not a function` error
  - Initialized recentEvents as empty array with type checking
  - Added proper event queue management

- **neural_train**: Fixed parameter validation errors
  - Corrected parameter naming (pattern_type â†’ patternType)
  - Added comprehensive input validation

#### MCP Routing Fixes
- **Fixed 9 tools falling through**: Workflow and performance tools now route correctly
- **Proper error handling**: When managers not initialized
- **Response consistency**: All tools return consistent format

### ğŸ”§ Technical Improvements

#### Architecture Enhancements
- **Modular Structure**: New organized implementation directory
  ```
  src/mcp/
  â”œâ”€â”€ implementations/
  â”‚   â”œâ”€â”€ agent-tracker.js
  â”‚   â”œâ”€â”€ daa-tools.js
  â”‚   â””â”€â”€ workflow-tools.js
  â”œâ”€â”€ fixes/
  â”‚   â””â”€â”€ mcp-error-fixes.js
  â””â”€â”€ mcp-server.js
  ```

- **Type Safety**: Added validation for all tool inputs
- **Error Boundaries**: Proper error handling for all operations
- **Response Format**: Consistent JSON responses across all tools

### ğŸ“ˆ Performance Improvements
- **Response Time**: Reduced from 50-100ms to <20ms average
- **Memory Usage**: Stable at ~9.8% (6.5GB of 67GB total)
- **CPU Load**: Low utilization (0.02-0.14 average)
- **Success Rate**: Increased from ~60% to >95%

### ğŸ“Š Quality Metrics

| Category | Working | Mock/Stub | Success Rate |
|----------|---------|-----------|--------------|
| Memory | 10 | 0 | **100%** |
| DAA | 6 | 0 | **100%** |
| Workflow | 6 | 0 | **100%** |
| Performance | 3 | 0 | **100%** |
| Agent/Swarm | 10 | 0 | **100%** |
| Neural | 8 | 0 | **100%** |
| **TOTAL** | **43** | **2** | **>95%** |

### ğŸ™ Acknowledgments
- Community feedback from issues #653, #645, #640
- Contributors: @alexx-ftw, @lanemc
- All alpha testers who provided valuable feedback
- Discord community for continuous support

### ğŸ“¦ Installation
```bash
npm install -g claude-flow@alpha
```

### ğŸ”— Links
- [npm Package](https://www.npmjs.com/package/claude-flow/v/2.0.0-alpha.90)
- [Pull Request #661](https://github.com/ruvnet/claude-flow/pull/661)
- [Issue #660](https://github.com/ruvnet/claude-flow/issues/660)

---

## [2.0.0-alpha.89] - 2025-08-13

> **Highlights**: Working auto-fix implementation for pair programming with real command execution, complete command documentation system, real Claude Code stream chaining with background execution, enhanced help system with emojis, comprehensive pair programming features with guidance modes, and complete removal of simulation mode in training.

### âœ¨ New Features

#### ğŸ”— Stream Chain Command - Real Claude Code Execution
- **Complete Implementation**: Fixed missing `stream-chain` command (Issue #642)
  - Added full command handler in `/src/cli/simple-commands/stream-chain.js`
  - Registered in command registry with all subcommands
  - Implemented `run`, `demo`, `pipeline`, and `test` subcommands
  - Four pipeline types: `analysis`, `refactor`, `test`, `optimize`
  - Full integration with Claude Code's stream-json output format

- **Real Claude Code Integration**: Stream-chain now uses actual Claude Code execution
  - Fixed stream-json format compatibility with Claude Code
  - Proper context preservation between chained steps
  - Extracts assistant responses from stream-json output
  - Transforms output into context for next step
  - Handles system message filtering automatically
  - ~10-30s per step with full context preservation

- **Enhanced Help System**: Comprehensive documentation with emoji formatting
  - Brief help via `--help` with expanded details section
  - Full documentation via `stream-chain help` subcommand
  - Emoji section headers for better readability (ğŸ“š SUBCOMMANDS, âš™ï¸ OPTIONS, etc.)
  - Added pipeline subcommand with 4 predefined workflows:
    - `analysis` - Code analysis and improvement pipeline
    - `refactor` - Automated refactoring workflow
    - `test` - Comprehensive test generation
    - `optimize` - Performance optimization pipeline

- **Working Implementation Details**:
  - Uses `claude -p --output-format stream-json --verbose` for proper execution
  - Context injection via prompts (workaround for `--input-format` limitations)
  - Timeout handling with configurable `--timeout` flag (default 30s)
  - Verbose mode shows command execution and content preview
  - Test suite validates context preservation between steps

#### ğŸ§  Real Training Pipeline
- **Removed Simulation Mode**: Training now exclusively uses real code execution
  - Creates actual JavaScript files with real code
  - Runs real `npm install` and `npm test` commands  
  - Executes actual Jest tests for validation
  - Learns from genuine test results with 0.4 learning rate
  - Shows real improvements in agent performance (~50% success rate achieved)
  - Proper regex escaping in code templates
  - Code restoration after each strategy test

#### âœ… Truth Verification System
- **Production-Ready Implementation**: Based on GitHub Issue #640
  - Truth scoring with 95% accuracy threshold
  - Real-time verification during task execution
  - Git-based rollback mechanism for failed verifications
  - Integration with training pipeline for continuous improvement
  - Verification hooks for agent task validation
  - Dashboard export functionality for metrics
  - Pair programming mode with real-time verification

#### ğŸ‘¥ Pair Programming Features
- **Interactive Pair Programming**: New `pair` command with full documentation
  - Real-time code review and verification
  - Automated truth enforcement
  - Integration testing capabilities
  - Quality gates and thresholds
  - Collaborative development workflow
  - Three collaboration modes: driver, navigator, and switch
  - Session persistence and recovery
  - Background session support
  - Comprehensive metrics tracking

- **Full Interactive Implementation** (Fixed compilation issues):
  - Created standalone `pair.js` replacing verification.js integration
  - Interactive readline interface with 10+ session commands
  - Real verification system running `npm run typecheck`, `lint`, and `build`
  - Actual test execution with `npm test` and result parsing
  - Session commands: `/verify`, `/test`, `/status`, `/metrics`, `/commit`, `/switch`
  - Automatic role switching every 10 minutes in switch mode
  - Verification scoring with configurable thresholds (default 0.95)
  - Test result tracking and coverage monitoring
  - Pre-commit verification gates
  - Session data persistence in `.claude-flow/sessions/pair/`

- **Working Auto-Fix Implementation** (2025-08-13):
  - **Real Fix Application**: Actually applies fixes instead of simulating
    - ESLint auto-fix with `npm run lint -- --fix`
    - Prettier formatting as fallback for style issues
    - Missing TypeScript type definitions installation
    - Security vulnerability fixes with `npm audit fix`
    - Dependency updates with `npm update`
    - Build cache clearing and rebuild on errors
  - **Graduated Scoring**: Based on actual error/warning counts
    - Errors reduce score by 0.1 per error (min 0.2)
    - Warnings reduce score by 0.05 per warning (min 0.7)
    - Accurate reflection of code quality state
  - **Fix History Tracking**: Complete audit trail
    - Records all applied fixes per iteration
    - Shows score improvement over time
    - Tracks which fix types were most effective

- **Enhanced Guidance Modes** (2025-08-13):
  - **Five Expertise Levels**: 
    - `beginner`: Detailed explanations, frequent tips, educational focus
    - `intermediate`: Balanced guidance with key explanations
    - `expert`: Minimal guidance, maximum efficiency
    - `mentor`: Teaching mode with learning opportunities
    - `strict`: Enforces highest quality standards (0.99 threshold)
  - **Interactive Q&A System**: Ask questions with `?` prefix
  - **Contextual Suggestions**: Based on current code state
  - **Best Practices Library**: Per-language recommendations
  - **Pattern Suggestions**: Design pattern recommendations

#### ğŸ“š Command Documentation System
- **Complete Documentation Structure**: Created comprehensive docs in `.claude/commands/`
  - **Stream Chain Documentation** (`/stream-chain/`):
    - `README.md` - Overview with background execution integration
    - `pipeline.md` - Predefined pipeline documentation
    - `run.md` - Custom chain execution guide
    - Background commands approach from wiki integrated
  - **Pair Programming Documentation** (`/pair/`):
    - `README.md` - Complete overview and quick start
    - `start.md` - Starting sessions with all options
    - `modes.md` - Driver, navigator, switch, and specialized modes
    - `session.md` - Session lifecycle and management
    - `config.md` - Full configuration reference
    - `commands.md` - Complete command reference (100+ commands)
    - `examples.md` - 10 real-world scenarios with workflows
  - **Verification Documentation** (`/verify/`):
    - Complete verification system documentation
  - **Truth Metrics Documentation** (`/truth/`):
    - Truth scoring and reliability metrics

### ğŸ› ï¸ Technical Improvements

#### Command System
- **Stream Chain Infrastructure**:
  - Subcommands: `run`, `demo`, `pipeline`, `test`
  - Pipeline types: `analysis`, `refactor`, `test`, `optimize`
  - Stream-JSON format support for context preservation
  - 100% context preservation between agents
  - Sequential execution with configurable timeouts
  - O(1) memory usage via streaming

#### Pair Programming System
- **Performance Optimizations** (2025-08-13):
  - **Resource Usage**: Reduced from 10-17% CPU to <1% idle
    - Removed 30-second verification interval loop
    - Added 60-second cooldown for auto-verify
    - Manual verification control with `/verify` command
  - **Intelligent Fix Chains**: Targeted fix application
    - Only runs fixes for failing checks
    - Parallel fix application where possible
    - Caches verification results between iterations
  - **Guidance Mode Performance**:
    - Expert mode: Minimal overhead, fastest execution
    - Beginner mode: Educational value with reasonable performance
    - Strict mode: Highest quality with 0.99 threshold

#### Training System
- **Real Execution Metrics**:
  - Conservative strategy: 49.9% success, 1909ms avg time
  - Balanced strategy: 50.0% success, 1887ms avg time
  - Aggressive strategy: 50.0% success, 1670ms avg time (fastest)
  - All strategies using 14+ real executions
  - Exponential Moving Average (EMA) learning with 0.4 rate

#### Verification System
- **Comprehensive Verification**:
  - `verify` command with subcommands: `check`, `rollback`, `report`, `dashboard`
  - Truth threshold configuration (default 0.95)
  - Integration with swarm commands via `--verify` flag
  - Automatic rollback on verification failure
  - Performance tracking and reporting

### ğŸ› Bug Fixes

#### Stream Chain Command
- **Issue #642 Resolved**: Stream-chain command was documented but missing
  - Command now fully implemented and registered
  - All subcommands working with proper error handling
  - Background execution properly tracked
  - Monitor and kill commands functional

- **Claude Code Integration Fixed**: Resolved multiple issues with real execution
  - Fixed "Expected message type 'user' got 'system'" error
  - Implemented proper stream-json message filtering
  - Fixed timeout issues with Claude Code execution
  - Resolved `--input-format` and `--output-format` compatibility
  - Working context preservation between chained steps

#### Pair Programming Command
- **Fixed Compilation Errors**: Resolved verification system issues
  - Separated pair command from verification.js to standalone pair.js
  - Fixed infinite compile score 0.50 loop from typecheck failures
  - Removed simulated verification with Math.random()
  - Implemented real npm command execution for verification
  - Added proper error handling for test and build failures

- **Fixed Auto-Fix Issues** (2025-08-13):
  - **Shell Command Execution**: Fixed npm commands with proper escaping
    - Resolved issue where "2" was appended to all commands
    - Fixed stderr redirection with parentheses wrapping
    - Commands now execute correctly: `(npm run lint) 2>&1 || true`
  - **Actual Fix Application**: Auto-fix now performs real fixes
    - Previously just ran verification repeatedly without fixing
    - Now executes `npm run lint -- --fix` for real ESLint fixes
    - Applies Prettier formatting when ESLint can't auto-fix
    - Installs missing @types packages automatically
    - Runs `npm audit fix` for security vulnerabilities
  - **Verification Accuracy**: Scores based on actual output
    - Counts real errors and warnings from command output
    - Graduated scoring: errors -0.1, warnings -0.05
    - Reflects true code quality state

#### Training Pipeline
- **Fixed Simulation Issues**:
  - Removed `Math.random()` simulation that showed 0% improvement
  - Fixed regex escaping issues in generated code
  - Fixed conservative strategy breaking JavaScript syntax
  - Proper error handling for npm test failures
  - Real test results now driving learning

#### Non-Interactive Mode
- **Fixed Argument Injection**: 
  - Corrected command-line argument ordering for non-interactive mode
  - Flags must precede prompt arguments
  - Hive-mind spawn commands now work in CI/CD environments

### ğŸ“š Documentation

#### New Documentation
- **Command Documentation System**: Complete docs in `.claude/commands/`
  - Stream chain with background execution integration
  - Pair programming with 7 comprehensive guides
  - Verification system documentation
  - Truth metrics documentation
  - All commands now have structured documentation

- **Stream Chain Command Wiki**: Created `/claude-flow-wiki/Stream-Chain-Command.md`
  - Complete command reference with all subcommands
  - Background execution guide
  - Performance characteristics
  - Integration with other Claude Flow features
  - Troubleshooting section

- **Training Pipeline Documentation**: `/docs/training-pipeline-real-only.md`
  - Explains shift from simulation to real execution
  - Performance metrics and improvements
  - Task complexity levels
  - Learning mechanisms

- **Performance Validation**: `/workspaces/claude-code-flow/performance-validation.md`
  - Validation of training improvements
  - Agent profile analysis
  - Stream chaining integration

### ğŸ¯ Performance Improvements

#### Stream Chaining
- Latency: <100ms per handoff between agents
- Context preservation: 100% maintained
- Memory usage: O(1) constant via streaming
- Speed: 40-60% faster than file-based approaches

#### Training Pipeline
- Real execution provides genuine performance data
- Strategies converging to ~50% success rate
- Aggressive strategy 12.5% faster than conservative
- Learning effectiveness validated through real tests

### ğŸ”§ Command Updates

#### New Commands
- `stream-chain run` - Execute custom stream chains
- `stream-chain demo` - Run demonstration chain
- `stream-chain pipeline <type>` - Execute predefined pipelines
- `stream-chain test` - Test stream connection
- `stream-chain monitor` - Monitor background chains
- `stream-chain kill <id>` - Terminate background chains
- `verify check` - Run verification checks
- `verify rollback` - Rollback on failure
- `verify report` - Generate verification report
- `pair` - Start pair programming mode

#### Updated Commands
- Training pipeline now real-only (no `--real` flag needed)
- Swarm commands support `--verify` flag
- Non-interactive mode properly handles argument ordering

### ğŸ“¦ Files Changed

#### New Files
- `/src/cli/simple-commands/stream-chain.js` - Stream chain command implementation
- `/src/cli/simple-commands/train-and-stream.js` - Integrated training/streaming
- `/src/cli/simple-commands/pair.js` - Interactive pair programming implementation
- `/claude-flow-wiki/Stream-Chain-Command.md` - Wiki documentation
- `/docs/training-pipeline-real-only.md` - Real training documentation
- `/performance-validation.md` - Performance validation report
- `.claude/commands/stream-chain/README.md` - Stream chain main documentation
- `.claude/commands/stream-chain/pipeline.md` - Pipeline documentation
- `.claude/commands/stream-chain/run.md` - Run command documentation
- `.claude/commands/pair/README.md` - Pair programming overview
- `.claude/commands/pair/start.md` - Starting sessions guide
- `.claude/commands/pair/modes.md` - Collaboration modes guide
- `.claude/commands/pair/session.md` - Session management guide
- `.claude/commands/pair/config.md` - Configuration reference
- `.claude/commands/pair/commands.md` - Command reference
- `.claude/commands/pair/examples.md` - Real-world examples
- `.claude/commands/verify/README.md` - Verification documentation
- `.claude/commands/truth/README.md` - Truth metrics documentation

#### Modified Files
- `/src/cli/command-registry.js` - Updated pair command to use new pair.js
- `/src/cli/simple-commands/training-pipeline.js` - Removed simulation mode
- `/src/cli/simple-commands/verification.js` - Enhanced verification features
- `/.claude-flow/agents/profiles.json` - Updated with real execution metrics
- `/CLAUDE.md` - Updated with stream chain examples
- `/CHANGELOG.md` - Updated with alpha-89 release notes

### ğŸš€ Migration Notes

#### For Existing Users
1. Stream-chain command now available - run `stream-chain help`
2. Training pipeline uses real execution - expect initial slower performance
3. Verification system active - configure thresholds as needed
4. Background chains persist across sessions

#### Breaking Changes
- Training pipeline no longer supports simulation mode
- `--real` flag removed from training commands (always real now)
- Verification may block deployments if threshold not met

### ğŸ“Š Metrics

#### Issue Resolution
- Resolved: #642 (Missing stream-chain command)
- Resolved: #640 (Truth Verification System implementation)
- Fixed: Non-interactive mode argument injection
- Fixed: Training pipeline simulation issues

#### Test Coverage
- Stream chain: All subcommands tested and working
- Training pipeline: 14+ real executions per strategy
- Verification: 95% accuracy threshold validated

## [2.0.0-alpha.88] - 2025-08-11

### âœ¨ New Features
- **Session Persistence Enhancements**: Improved cross-session memory and state management
- **Background Command Improvements**: Enhanced background task management system
- **Wiki Documentation Updates**: Comprehensive documentation for all new features

## [2.0.0-alpha.87] - 2025-08-05

### âœ¨ New Features
- **Centralized Version Management**: Version now reads dynamically from package.json
  - Single source of truth for version numbers
  - Automatic version updates across all CLI commands
  - No more manual version string updates needed
  - Fallback support if package.json can't be read

### ğŸ› Bug Fixes
- **Async/Await Fixes**: Fixed missing await keywords in hive-mind commands
  - Fixed `getActiveSessionsWithProcessInfo()` missing await in stop.ts (lines 24, 90)
  - Fixed `getSession()` missing await in stop.ts (line 57) 
  - Fixed `getSession()` missing await in pause.ts (line 23)
  - Resolves "sessions.forEach is not a function" errors

### ğŸ”§ Improvements
- **Code Organization**: Created centralized version module
  - Added `src/core/version.ts` and `src/core/version.js`
  - Updated all CLI entry points to use centralized version
  - Improved maintainability and consistency

### ğŸ”„ Synced with Main
- Merged all latest changes from main branch
- Includes PR #584 (session resume fix)
- Includes all recent bug fixes and improvements

## [2.0.0-alpha.86] - 2025-08-05

### ğŸ› Bug Fixes
- **Import Alias Fix**: Removed unnecessary `execSyncOriginal` alias in init/index.js (PR #558)
  - Fixed unused import alias that was causing confusion
  - Simplified import statement for better code clarity

### ğŸ”„ Version Updates
- Updated version strings across the codebase to alpha-86
- Updated package.json version
- Updated CLI help text version references
- Updated --version command output

### ğŸ“š Documentation
- Updated CHANGELOG.md with latest release notes

## [2.0.0-alpha.85] - 2025-08-05

### âœ¨ New Features

#### ğŸ” Stream-JSON Chaining
- **Multi-Agent Pipeline Support**: Connect multiple Claude instances using real-time JSON streams
  - Use `--output-format stream-json` and `--input-format stream-json` flags
  - Build modular, recursive, multi-agent pipelines
  - Automatic dependency detection and stream chaining
  - Enables complex workflows: planner â†’ executor â†’ reviewer
  - Support for recursive pipelines and iterative refinement
  - Live feedback systems and task decomposition
  - New `stream-chain` command for easy pipeline creation

#### ğŸ¤– Advanced Automation Capabilities
- **Enhanced Workflow Automation**: Improved automation features for complex tasks
  - Automatic task dependency resolution
  - Intelligent agent spawning based on task requirements
  - Smart parallel execution with resource optimization
  - Enhanced error recovery and retry mechanisms
  - Automated progress tracking and reporting
  - Better integration with CI/CD pipelines

#### ğŸ¯ Improved Swarm Intelligence
- **Smarter Agent Coordination**: Enhanced multi-agent collaboration
  - Automatic topology optimization based on task type
  - Dynamic agent scaling based on workload
  - Improved knowledge sharing between agents
  - Better conflict resolution in parallel tasks
  - Enhanced performance monitoring and bottleneck detection

### ğŸ› ï¸ Technical Improvements
- **Stream Processing**: New stream-json module for efficient data piping
- **Automation Engine**: Enhanced task orchestration with dependency graphs
- **Performance**: Optimized agent communication reducing overhead by 15%
- **Reliability**: Improved error handling in multi-agent scenarios

### ğŸ“š Documentation
- Added comprehensive stream-chaining guide in `/docs/stream-chaining.md`
- Updated automation examples in `/examples/automation-examples.md`
- Enhanced workflow documentation with pipeline patterns

## [2.0.0-alpha.84] - 2025-02-03

### ğŸ”§ Bug Fixes
- **Fixed Hive Mind Wizard Memory Retrieval**: 
  - Fixed memory listing to read from correct database (`hive.db` instead of `memory.db`)
  - Updated collective memory search to query the `collective_memory` table
  - Memory wizard now correctly displays all 264 stored memories
  - Search functionality now properly queries collective memory store

### ğŸ“¦ Package Optimization
- **Reduced NPM Package Size by 31%**:
  - Excluded unnecessary `bin/claude-flow-node-pkg` binary (45MB) from npm package
  - Package size reduced from 58MB to 40MB
  - Binary is only needed for standalone distribution, not for npm/npx users
  - Updated package.json files field to exclude the precompiled binary

### ğŸ› ï¸ Technical Improvements
- **Database Consistency**: Aligned memory retrieval across hive mind commands
- **Memory Search**: Direct SQLite queries for better performance and accuracy

## [2.0.0-alpha.83] - 2025-02-01

### ğŸ”§ Bug Fixes
- **Fixed CLAUDE.md Template Generation**: 
  - Updated init command template to use correct agent names
  - Replaced legacy agent names (analyst, coordinator, etc.) with proper mappings
  - Ensures all generated CLAUDE.md files use valid agent types
  - Fixes issue #557: "Agent type 'analyst' not found" error

### ğŸ› ï¸ Technical Improvements
- **Agent Name Mapping**: Enhanced backward compatibility with legacy agent names
- **Template Updates**: Updated 18 instances of agent names in CLAUDE.md template
- **Agent Loader**: Maintains support for legacy names while using correct internal types

### ğŸ“¦ Package Notes
- Package successfully published to npm with alpha tag
- All agent definitions included (64 specialized agents)
- TypeScript build warnings present but don't affect functionality

## [2.0.0-alpha.80] - 2025-01-30

### âœ¨ New Features
- **Real Token Usage Tracking**: Track actual Claude API token consumption instead of simulated data
  - Integrates with Claude Code's OpenTelemetry metrics
  - Accurate cost calculations based on Anthropic pricing
  - Agent-level token breakdown showing usage by agent type
  - CSV export for detailed billing and analysis reports
  - Smart optimization recommendations to reduce costs

- **Real Performance Analytics**: ALL analysis commands now use real data
  - `claude-flow analysis performance-report` - Real task execution metrics
  - `claude-flow analysis bottleneck-detect` - Actual system bottleneck detection
  - Automatic performance tracking for all commands
  - System resource monitoring (CPU, memory)
  - Agent performance metrics by type
  - Trend analysis comparing periods

- **Enhanced Analytics Command**: 
  - `claude-flow analysis token-usage --breakdown --cost-analysis`
  - Real-time token consumption metrics
  - Cost projections with current Anthropic pricing
  - Filter by agent type with `--agent <type>`

- **Optional Monitoring During Init**:
  - `claude-flow init --monitoring` sets up token tracking
  - Creates `.claude-flow/` directory with tracking configuration
  - Generates environment setup script for telemetry
  - Adds token tracking hooks to Claude settings

### ğŸ”§ Technical Improvements
- **Performance Metrics System**: Complete real-time metrics collection in `performance-metrics.js`
- **Performance Hooks**: Automatic tracking integration for all commands
- **Token Tracking Implementation**: Real metrics integration in `analysis.js`
- **Init Command Enhancement**: Added `setupMonitoring()` function
- **Help Text Updates**: Added monitoring options to init and analysis commands
- **Documentation**: 
  - Token tracking guide in `/docs/REAL_TOKEN_TRACKING.md`
  - Performance tracking guide in `/docs/REAL_PERFORMANCE_TRACKING.md`

### ğŸ“Š Monitoring Features
- **Token Usage Tracking**:
  - OpenTelemetry metrics (when `CLAUDE_CODE_ENABLE_TELEMETRY=1`)
  - Local Claude Code metrics (`~/.claude/metrics/usage.json`)
  - Project-specific tracking (`.claude-flow/token-usage.json`)
- **Performance Tracking**:
  - Task execution metrics (duration, success rate)
  - Agent performance by type
  - System resource monitoring
  - Bottleneck detection and recommendations
  - HTML/JSON/CSV export formats
- Automatic fallback between data sources
- Monthly rotation for tracking data

## [2.0.0-alpha.79] - 2025-01-30

### ğŸš€ Major Improvements
- **Removed Deno Dependency**: Complete migration to pure Node.js implementation (#521)
  - Eliminated all Deno runtime references
  - Simplified installation and deployment
  - Fixed TypeScript compilation issues
  - Improved cross-platform compatibility

- **TBench Integration**: Added comprehensive Terminal Bench support
  - Created `ClaudeFlowInstalledAgent` implementation
  - Added installation script for TBench containers
  - Integrated with TBench evaluation framework
  - Support for both swarm and hive execution modes

- **Headless Mode Support**: Fixed non-interactive execution (#510)
  - Claude CLI now works in headless/production environments
  - Improved CI/CD pipeline compatibility
  - Better error handling in non-TTY environments

### ğŸ› Bug Fixes
- **Commander Dependency**: Fixed missing commander module error
- **GitHub CLI Timeout**: Resolved timeout issues with special characters (#514, #522)
- **Memory System**: Addressed memory persistence issues (#530)
- **Windows Compatibility**: Continued improvements from alpha 75
- **Hook Execution**: Stable hook system from previous alphas

### ğŸ“š Documentation
- **TBench Guide**: Added comprehensive integration documentation
- **Alpha Test Report**: Created detailed testing documentation
- **README Updates**: Fixed inaccuracies identified in #478
- **Maestro Workflow Guide**: Added comprehensive guide (#512)

### ğŸ”§ Technical Improvements
- **Build System**: Cleaned up TypeScript compilation warnings
- **Package Size**: Optimized to ~46.3MB including binary
- **Test Suite**: Identified configuration issues (non-blocking)
- **MCP Tools**: Verified all 87 tools functioning correctly

### ğŸ¯ Known Issues
- Test suite configuration needs adjustment (development only)
- Some TypeScript warnings remain (don't affect runtime)
- MCP process proliferation in some scenarios (#527)

### ğŸ“¦ Dependencies
- Updated all dependencies to latest stable versions
- Added explicit commander dependency
- Maintained compatibility with Node.js 20+

## [2.0.0-alpha.78] - 2025-01-28

### ğŸš€ Features
- **Agent System Fix**: Dynamic loading from .claude/agents/ (#485)
- **SPARC Experience**: Cleaned up legacy warnings
- **GitHub Safe Utilities**: Added timeout protection (#514)

### ğŸ› Bug Fixes
- **Hooks Pre-task**: Enhanced exit with timeout protection
- **Legacy Warnings**: Removed Deno-related warnings

## [2.0.0-alpha.77] - 2025-01-26

### ğŸ”§ Improvements
- Native Hive Mind Maestro Implementation
- Complete Maestro cleanup and consolidation
- Enhanced agent type system

## [2.0.0-alpha.75] - 2025-01-24

### ğŸš€ Windows Compatibility
- Major Windows compatibility overhaul
- Fixed path handling issues
- Improved cross-platform support

## [2.0.0-alpha.70] - 2025-01-22

### ğŸ”§ Critical Quote Handling Fix
- **Hook Commands**: Fixed "Unterminated quoted string" errors in all hook commands
  - Replaced complex `printf` and nested quotes with simpler `cat | jq | tr | xargs` pipeline
  - Used `jq -r '.field // empty'` instead of problematic `'.field // ""'` syntax
  - All hook commands now use consistent: `cat | jq -r '.tool_input.command // empty' | tr '\\n' '\\0' | xargs -0 -I {}`
  - Fixed both init template and current settings.json files

### ğŸ› ï¸ Command Improvements  
- **Simplified Pipeline**: More reliable command parsing without quote conflicts
- **Better Error Handling**: Clean failures instead of shell syntax errors
- **Consistent Syntax**: All hook commands use identical, tested patterns

## [2.0.0-alpha.69] - 2025-01-22

### ğŸ”§ Critical Fix
- **Init Template**: Fixed `claude-flow init` creating broken settings.json with xargs quote errors
  - Updated template to use `printf '%s\0'` instead of problematic `cat | jq | xargs -I` pipeline
  - Changed to `xargs -0` with single quotes around `{}` placeholders  
  - Removed non-existent `--train-neural` flag from post-edit hooks
  - All new projects initialized with `claude-flow init` now have working hooks

### ğŸ› ï¸ Template Improvements
- **Safer Command Execution**: Printf-based approach prevents quote parsing issues
- **Better Error Handling**: Commands fail gracefully instead of breaking xargs
- **Cleaner Syntax**: Simplified hook commands for better reliability

## [2.0.0-alpha.68] - 2025-01-22

### ğŸ”§ Critical Bug Fixes
- **Hook Execution**: Fixed xargs unmatched quote error in PreToolUse:Bash and PostToolUse:Bash hooks
  - Updated to use `xargs -0` with null-delimited input to properly handle commands with quotes
  - Changed from double quotes to single quotes around command placeholders
  - Added `tr '\n' '\0'` to convert newlines to null characters for safe processing
- **Neural Command**: Identified missing neural command implementation (created issue #444)
  - Affects error prevention, performance optimization, and session training
  - Temporary workaround: hooks fail gracefully with non-blocking errors

### ğŸ› ï¸ Improvements
- **Hook Reliability**: Enhanced quote and special character handling in all hook commands
- **Error Handling**: Improved error reporting for missing commands
- **Settings Format**: Updated .claude/settings.json with fixed hook configurations

### ğŸ“ Known Issues
- Neural commands (`neural predict`, `neural train`, etc.) are not yet implemented in alpha version
- Memory store command requires proper key-value syntax

## [2.0.0-alpha.67] - 2025-01-21

### ğŸ Hive Mind Enhancement
- **Hive Mind Integration**: Fixed settings.json validation errors for Claude Code compatibility
- **Configuration Fix**: Removed unrecognized fields (checkpoints, memory, neural, github, optimization)
- **Hook Names**: Corrected invalid hook names to match Claude Code 1.0.51+ format
  - `user-prompt-submit` â†’ `UserPromptSubmit`
  - Removed invalid `checkpoint` and `error` hooks

### ğŸ”§ Infrastructure
- **Settings Validation**: Now passes `/doctor` command validation
- **Claude Code Compatibility**: Full compatibility with Claude Code 1.0.51+ settings format
- **Version Update**: Bumped to alpha.67 across all version references

### ğŸ“š Documentation
- Updated version references in help text and CLI commands
- Enhanced hive-mind documentation with corrected hook configurations

## [2.0.0-alpha.66] - 2025-01-20

### ğŸ”§ Bug Fixes
- **Hooks Command**: Fixed "command.toLowerCase is not a function" error in hooks pre-command
- **ARM64 Support**: Improved ARM64 compatibility for better-sqlite3 on macOS (#378)
- Added type checking for command parameter in hooks to handle empty/missing values
- Enhanced postinstall script with ARM64 detection and automatic rebuild

### ğŸš€ New Features
- Automatic SQLite binding verification and rebuild for Apple Silicon Macs
- Graceful fallback to in-memory storage if SQLite bindings fail
- Better error handling and user feedback during installation

### ğŸ—ï¸ Infrastructure
- Added `node20-macos-arm64` target to pkg configuration
- Improved boolean parameter parsing in hooks commands
- Enhanced platform detection for ARM64 architecture

### ğŸ“š Documentation
- Added ARM64 troubleshooting guide
- Updated hooks command usage examples

## [2.0.0-alpha.65] - 2025-01-20

### ğŸ”§ Bug Fixes
- **CRITICAL**: Fixed "table agents has no column named role" error in hive-mind wizard (#403)
- Added missing `role` column to agents table schema in init/index.js
- Fixed TypeScript build errors preventing compilation
- Resolved ILogger interface issues and async/await problems
- Fixed missing type definitions in multiple modules

### ğŸ—ï¸ Infrastructure
- **Database Schema**: Synchronized agents table schema across all modules
- **Build System**: Fixed critical TypeScript compilation errors
- **Type Safety**: Added proper type annotations throughout codebase

### ğŸ“š Documentation
- Added migration instructions for existing databases
- Updated test suite with schema validation tests

## [2.0.0-alpha.64] - 2025-01-18

### ğŸ”§ Bug Fixes
- Fixed wrapper script hardcoded to use outdated alpha-27 version
- Updated wrapper to use `@alpha` tag for always getting latest alpha version
- Ensures `./claude-flow` wrapper always uses the most recent alpha release

### ğŸ“¦ Dependencies
- No dependency changes, only template fix

## [2.0.0-alpha.63] - 2025-01-18

### ğŸš€ Major Features
- **MCP/NPX Fallback Pattern**: All 60+ command files now include both MCP tools (preferred) and NPX CLI (fallback)
- **SPARC Included by Default**: No more `--sparc` flag needed, SPARC commands automatically initialized
- **Complete Environment Init**: Creates 112+ files including both databases properly initialized

### ğŸ—ï¸ Infrastructure
- **Template System**: Updated template generation to include MCP/NPX fallback patterns
- **Init Command**: Fixed missing imports for createAgentsReadme and createSessionsReadme
- **Database Init**: Added .hive-mind directory creation and hive.db initialization with schema
- **SPARC Integration**: Made SPARC included by default in v2.0.0 flow

### ğŸ› ï¸ Improvements
- Updated all 18 SPARC command files in .claude/commands/sparc/ with MCP/NPX fallback
- Updated 5 swarm strategy files with MCP/NPX patterns
- Enhanced init command to create complete environment with 113 files
- Fixed copyRevisedTemplates to include SPARC files

### ğŸ“š Documentation
- Updated CLAUDE.md template with comprehensive MCP/NPX usage examples
- Added fallback guidance to all command documentation
- Enhanced GitHub integration documentation with gh CLI usage

## [2.0.0-alpha.62] - 2025-01-18

### ğŸ”’ Security Fixes
- **CRITICAL**: Removed vulnerable `pkg` dependency (GHSA-22r3-9w55-cj54) - Local privilege escalation vulnerability
- Replaced `pkg` with secure `@vercel/ncc` alternative for binary building
- Security score improved from 55/100 to 75/100
- All npm audit vulnerabilities resolved (0 vulnerabilities)

### ğŸš€ Infrastructure Improvements
- **CI/CD Pipeline**: Re-enabled ALL security gates with strict enforcement
  - Removed all `|| true` and `|| echo` fallbacks
  - Added production dependency audit (moderate level)
  - Added license compliance checks
  - Test coverage reporting re-enabled
- **Test Infrastructure**: Major fixes and improvements
  - Fixed Jest configuration (removed deprecated globals)
  - Created comprehensive `test.utils.ts` with mock utilities
  - Fixed 18 TypeScript test files with incorrect import paths
  - Fixed ESM module issues (assert â†’ with syntax)
  - Created test fixtures and generators
  - Core tests now passing

### ğŸ› ï¸ Code Quality Improvements
- **ESLint**: Fixed 145 errors (16% reduction from 900 to 755)
  - Removed 104 unused `getErrorMessage` imports
  - Fixed non-null assertions with proper null checks
  - Added underscore prefix for intentionally unused parameters
- **TypeScript**: Fixed 15 critical errors in CLI commands
  - Fixed cli-table3 import issues
  - Corrected date arithmetic operations
  - Added proper type assertions for error handling
  - Resolved Commander/Cliffy compatibility issues
- **Configuration**: Added development tooling
  - Created `babel.config.cjs` with modern import syntax support
  - Created `.eslintrc.json` with TypeScript rules
  - Created `.prettierrc.json` for consistent formatting

### ğŸ“š Documentation
- Created `SECURITY_AUDIT_REPORT.md` with detailed security findings
- Created `FIX_SUMMARY.md` documenting all code quality fixes
- Created `FUNCTIONALITY_REVIEW.md` verifying all features work
- Updated GitHub issue #362 with comprehensive progress reports

### âœ… Verified Working Features
- All core CLI commands operational
- SPARC development system functional
- Hive Mind system ready
- Swarm coordination active
- Memory persistence working
- MCP server integration verified
- Help system comprehensive

### ğŸ› Known Issues
- ESLint: 755 warnings remaining (mostly `any` types)
- TypeScript: 413 errors remaining (complex type issues)
- Some integration tests need implementation
- Build process has declaration file conflicts (workaround available)

## [2.0.0-alpha.61] - 2025-01-17

### Added
- **Neural Training Enhancements**: 
  - Enhanced neural training with real WASM acceleration achieving 92.9% accuracy
  - Added task-predictor model for improved agent coordination
  - Implemented SIMD support for faster neural computations
  - Added comprehensive neural training command help documentation

- **Help System Improvements**:
  - Updated help command implementation with proper TypeScript support
  - Enhanced help text with neural training command documentation
  - Added comprehensive examples for training, pattern learning, and model updates
  - Improved command-specific help display formatting

- **Version Management**:
  - Updated all version references to alpha.61 across codebase
  - Updated help text to reflect alpha.61 improvements
  - Enhanced version display in CLI output

### Fixed
- **Issue #351**: Fixed `swarm_status` MCP tool returning mock response instead of real data
  - Removed dependency on uninitialized `databaseManager`
  - Updated to use memory store (SQLite) for swarm data retrieval
  - Fixed agent and task storage keys to enable proper filtering by swarm ID
  - Added support for verbose mode to return detailed swarm information
  - Ensured accurate agent counts, task counts, and status calculations

- **Issue #347**: Fixed MemoryManager initialization error "Unknown memory backend: undefined"
  - Added required configuration parameters to MemoryManager constructor
  - Created default memory configuration with SQLite backend
  - Set sensible defaults: 50MB cache, 30s sync interval, 30-day retention
  - Added proper error handling and logging for memory initialization
  - Resolved critical bug that blocked system integration startup

### Changed
- **MCP Server Memory Integration**: 
  - `swarm_status` now retrieves data from persistent memory store
  - `agent_spawn` stores agents with swarm-scoped keys (`agent:{swarmId}:{agentId}`)
  - `task_orchestrate` now stores tasks in memory (previously only attempted database storage)
  - `getActiveSwarmId()` method updated to use memory store
  
- **System Integration Memory Setup**:
  - MemoryManager now receives EventBus and Logger instances from SystemIntegration
  - Memory configuration is created with sensible defaults during initialization
  - Improved status reporting includes backend type and configuration details

- **CLI Help System**:
  - Maintained emoji-rich help as default based on user preference
  - Added `--plain` flag option for standardized Unix/Linux-style help
  - Updated command registry to use `HelpFormatter` when --plain is used
  - Modified `help-text.js` to support dual help modes
  - Enhanced error messages with helpful usage hints and valid options
  - Commands retain their vibrant, engaging help by default

## [2.0.0-alpha.56] - 2025-07-15

### ğŸš€ Major Hook System Overhaul (Issue #280)

#### **Complete Resolution of Hook Inconsistencies**
- **Hook name compatibility**: Both `pre-command` and `pre-bash` work identically
- **Parameter mapping**: All settings.json template parameters implemented
- **Dual format support**: Both dash-case (`--validate-safety`) and camelCase (`validateSafety`) work
- **100% settings.json compatibility**: All template commands work without modification

#### **Enhanced Safety Features**
- **Dangerous command blocking**: Prevents `rm -rf`, `format`, `del /f`, etc.
- **Safety validation**: Real-time command analysis and blocking
- **Resource preparation**: Automatic working directory setup
- **Command logging**: Full audit trail in SQLite memory store

#### **Intelligent Agent Assignment**
- **File-type based recommendations**: `.js` â†’ `javascript-developer`, `.py` â†’ `python-developer`
- **Context-aware assignment**: Automatic agent matching based on file extensions
- **Load context functionality**: Pre-operation context loading for better decisions

#### **Neural Pattern Training**
- **Confidence scoring**: 70-100% confidence levels for pattern recognition
- **Learning simulation**: Adaptive pattern training for syntax, structure, performance, security
- **Memory persistence**: Cross-session learning data storage

#### **Comprehensive Session Management**
- **State persistence**: Full session state saved to SQLite database
- **Metrics export**: Detailed session statistics and performance data
- **Summary generation**: Automatic session summaries with key metrics
- **Cross-session memory**: Persistent memory across development sessions

#### **Technical Improvements**
- **SQLite integration**: Robust memory store with error handling
- **Performance tracking**: Real-time metrics collection and analysis
- **Enhanced TypeScript types**: Complete interface coverage for all hook parameters
- **Comprehensive testing**: Integration tests for all hook functionality

### Fixed
- **Issue #280**: Complete resolution of hook parameter inconsistencies
- **Parameter validation**: All settings.json template parameters now work correctly
- **Hook name aliases**: Pre-command/pre-bash and post-command/post-bash compatibility
- **Memory storage**: Reliable SQLite-based persistence system

### Dependencies
- **Added**: `diskusage@1.1.3` for system resource monitoring
- **Updated**: Package version to 2.0.0-alpha.56

### Testing
- **Integration tests**: Comprehensive test suite for hook consistency
- **Template validation**: Settings.json command validation tests
- **Manual testing**: All hook variations tested and verified
- **NPM package**: Published and validated on npm registry

## [2.0.0-alpha.51] - 2025-01-14

### Changed
- Version bump with updated CLI version strings
- All features from alpha.50 included

## [2.0.0-alpha.50] - 2025-01-14

### Added

#### **Hive Mind Resume Functionality**
- **Session persistence** across swarm operations with automatic tracking
- **Auto-save system** with 30-second intervals and critical event saves
- **Resume capabilities** with full context restoration and progress tracking
- **Claude Code integration** for seamless continuation of paused sessions
- **Session management commands**: `sessions`, `resume <session-id>`
- **Comprehensive testing** with end-to-end test coverage
- **Complete documentation** in `docs/hive-mind-resume.md`

#### **Technical Infrastructure**
- **HiveMindSessionManager** class for session lifecycle management
- **AutoSaveMiddleware** for automatic state persistence
- **Database schema** with sessions, checkpoints, and logs tables
- **Graceful shutdown handling** with Ctrl+C interrupt support
- **Progress tracking** with completion percentage calculations

### Fixed
- **Session ID tracking** in spawn command output
- **Auto-save timing** for consistent 30-second intervals
- **Error recovery** for corrupted session data
- **Claude Code prompt** generation for resumed sessions

### Performance
- **Minimal overhead**: < 1% CPU usage for auto-save
- **Fast resume**: < 2 seconds session restoration
- **Efficient storage**: Compressed checkpoint data
- **Optimized queries**: Improved database performance

## [2.0.0] - 2025-07-03

### Added

#### **Complete ruv-swarm Integration**
- **27 MCP tools** for comprehensive workflow automation
- **Multi-agent task coordination** with swarm intelligence and hierarchical topology
- **Neural network capabilities** with cognitive diversity patterns (convergent, divergent, lateral, systems, critical, adaptive)
- **Cross-session memory persistence** with swarm coordination
- **Real-time performance monitoring** with sub-10ms response times
- **WASM-powered neural processing** with SIMD optimization support

#### **GitHub Workflow Automation**
- **6 specialized command modes** in `.claude/commands/github/`:
  - `pr-manager`: Automated pull request management with swarm coordination
  - `issue-tracker`: Intelligent issue management and progress tracking
  - `sync-coordinator`: Cross-package synchronization and version alignment
  - `release-manager`: Coordinated release management with multi-stage validation
  - `repo-architect`: Repository structure optimization and template management
  - `gh-coordinator`: Overall GitHub workflow orchestration
- **Automated pull request management** with multi-reviewer coordination
- **Intelligent issue tracking** with swarm-coordinated progress monitoring
- **Cross-repository synchronization** capabilities for monorepo management
- **Release coordination** with comprehensive validation pipelines

#### **Production-Ready Infrastructure**
- **Multi-stage Docker builds** with 60% performance improvement over previous builds
- **Comprehensive testing suite** with 67 CLI tests achieving 100% pass rate
- **Docker Compose orchestration** for development, testing, and production environments
- **CI/CD automation** with automated test execution and validation
- **Real-time monitoring** and performance tracking with detailed metrics
- **Security hardening** with non-root containers and best practices implementation

#### **Enhanced CLI Capabilities**
- **Advanced swarm coordination commands** with `npx claude-flow swarm`
- **GitHub integration commands** accessible through enhanced CLI interface
- **Improved error handling** and validation with detailed error messages
- **Enhanced UI** with `--ui` flag support for interactive management
- **SPARC mode initialization** with `--sparc` flag for development workflows
- **Performance benchmarking** tools integrated into CLI

#### **Enterprise Features**
- **Enterprise-grade documentation** with comprehensive integration guides
- **Production deployment** configurations and best practices
- **Performance metrics** and monitoring capabilities
- **Security audit** tools and vulnerability scanning
- **Cross-platform compatibility** validation (Windows, macOS, Linux)

### Changed

#### **Node.js Requirements**
- **Upgraded minimum version** from `>=18.0.0` to `>=20.0.0` for optimal ruv-swarm compatibility
- **Added npm requirement** of `>=9.0.0` for enhanced package management features

#### **Package Dependencies**
- **Updated better-sqlite3** from `^11.10.0` to `^12.2.0` for improved compatibility
- **Added ruv-swarm dependency** for complete swarm coordination capabilities
- **Enhanced package keywords** for better discoverability on npm registry
- **Optimized file inclusion** for npm publishing with focus on essential files

#### **CLI Command Structure**
- **Enhanced all commands** with swarm coordination capabilities
- **Improved command organization** with specialized GitHub workflow commands
- **Better error handling** throughout the CLI interface
- **Enhanced help documentation** with comprehensive examples

#### **Documentation**
- **Complete overhaul** focusing on enterprise features and v2.0.0 capabilities
- **Added comprehensive integration guides** for ruv-swarm and GitHub workflows
- **Enhanced README.md** with enterprise-focused content and clear value propositions
- **Improved code examples** and usage documentation

#### **Configuration**
- **New `.claude/commands/github/` directory** structure for GitHub workflow commands
- **Enhanced npm publishing** configuration with automated workflows
- **Improved package metadata** for better npm registry presentation
- **Updated build targets** for Node.js 20+ compatibility

### Fixed

#### **Dependency Resolution**
- **Resolved file path dependency issues** for ruv-swarm integration
- **Fixed version compatibility** conflicts between packages
- **Improved dependency alignment** across the entire ecosystem
- **Enhanced package installation** reliability

#### **Version Compatibility**
- **Aligned Node.js requirements** across claude-code-flow and ruv-swarm
- **Fixed better-sqlite3 version** conflicts for cross-platform compatibility
- **Resolved npm installation** issues in Docker environments
- **Enhanced cross-platform** compatibility validation

#### **Memory Coordination**
- **Improved cross-package state management** with enhanced memory persistence
- **Fixed memory leaks** in long-running swarm operations
- **Enhanced memory efficiency** for large-scale operations
- **Optimized memory coordination** between agents

#### **Error Handling**
- **Enhanced error messages** with actionable guidance and context
- **Improved error recovery** mechanisms for robust operation
- **Better error logging** for debugging and troubleshooting
- **Graceful failure handling** in swarm coordination scenarios

### Security

#### **Docker Security**
- **Implemented security hardening** in container configurations
- **Added non-root user** execution for enhanced security
- **Enhanced container isolation** and network security
- **Implemented security scanning** in CI/CD pipelines

#### **Dependency Security**
- **Updated dependencies** to resolve security vulnerabilities
- **Implemented automated security** scanning with npm audit
- **Enhanced access control** for GitHub integrations
- **Added vulnerability monitoring** for continuous security

#### **Access Control**
- **Enhanced permission management** for GitHub integrations
- **Improved API security** for MCP tool interactions
- **Added authentication** validation for sensitive operations
- **Implemented secure communication** protocols

### Performance

#### **Build Performance**
- **60% faster Docker builds** through multi-stage optimization
- **Improved package installation** speed with optimized dependencies
- **Enhanced build caching** for development workflows
- **Optimized binary compilation** for faster CLI startup

#### **Runtime Performance**
- **Sub-10ms MCP response times** for optimal user experience
- **Improved memory efficiency** with optimized coordination algorithms
- **Enhanced CPU utilization** for better resource management
- **Faster CLI startup** times with optimized initialization

#### **Testing Performance**
- **100% CLI test success rate** with comprehensive validation
- **Faster test execution** with parallel testing capabilities
- **Improved test coverage** across all major features
- **Enhanced performance regression** detection

---

## Migration Guide: v1.x to v2.0.0

### Prerequisites

1. **Update Node.js** to version 20 or higher:
   ```bash
   # Check current version
   node --version
   
   # Update to Node.js 20+ (using nvm)
   nvm install 20
   nvm use 20
   ```

2. **Update npm** to version 9 or higher:
   ```bash
   npm install -g npm@latest
   ```

### Installation

1. **Uninstall previous version** (if installed globally):
   ```bash
   npm uninstall -g claude-flow
   ```

2. **Install v2.0.0**:
   ```bash
   npm install -g claude-flow@2.0.0
   ```

3. **Verify installation**:
   ```bash
   claude-flow --version  # Should show 2.0.0
   claude-flow --help     # Verify all commands available
   ```

### Configuration Updates

1. **Initialize new features**:
   ```bash
   npx claude-flow init --sparc
   ```

2. **Test swarm capabilities**:
   ```bash
   npx claude-flow swarm init
   ```

3. **Explore GitHub integration**:
   ```bash
   npx claude-flow github --help
   ```

### Breaking Changes

#### Command Structure
- **All commands** now support swarm coordination
- **New GitHub commands** available in `.claude/commands/github/`
- **Enhanced error handling** may change error message formats
- **Existing commands** remain backward compatible

#### Dependencies
- **ruv-swarm** is now a required dependency
- **better-sqlite3** updated to v12.2.0
- **Node.js 20+** is required for optimal performance

#### Configuration
- **New configuration files** in `.claude/commands/github/`
- **Enhanced MCP integration** requires ruv-swarm setup
- **Updated package metadata** for npm publishing

### New Features

#### Swarm Coordination
```bash
# Initialize swarm
npx claude-flow swarm init

# Spawn agents
npx claude-flow agent spawn researcher
npx claude-flow agent spawn coder

# Orchestrate tasks
npx claude-flow task orchestrate "complex development task"
```

#### GitHub Integration
```bash
# Automated PR management
npx claude-flow github pr-manager "review and merge feature branch"

# Issue tracking
npx claude-flow github issue-tracker "manage project issues"

# Release coordination
npx claude-flow github release-manager "prepare v2.0.0 release"
```

#### Docker Development
```bash
# Build Docker environment
docker-compose -f infrastructure/docker/docker-compose.yml up

# Run tests in Docker
docker-compose -f infrastructure/docker/testing/docker-compose.test.yml up
```

### Verification

After migration, verify functionality:

```bash
# Basic functionality
claude-flow --version
claude-flow --help
claude-flow status

# Swarm features
claude-flow swarm init
claude-flow agent list

# GitHub integration
claude-flow github --help

# Docker testing
cd infrastructure/docker && docker-compose up
```

---

## [1.0.71] - 2025-07-01

### Fixed
- Enhanced stability and performance improvements
- Improved error handling in core orchestration
- Updated dependencies for security

### Added
- Improved CLI interface
- Enhanced configuration management
- Better error reporting

---

## [1.0.0] - 2025-01-01

### Added
- Initial release of claude-flow
- Basic AI agent orchestration
- CLI interface for agent management
- Core workflow automation
- Integration with Claude Code

---

*For older versions, see the [releases page](https://github.com/ruvnet/claude-code-flow/releases).*</doc><doc title="License" desc="optional reading.">MIT License

Copyright (c) 2025 rUv

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</doc><doc title="Security" desc="optional reading."># Security Guide

This guide covers security features, best practices, and configurations for the SPARC Memory Bank system.

## Security Architecture

### Defense in Depth

The SPARC Memory Bank implements multiple layers of security:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Application Layer           â”‚
â”‚  â€¢ Input validation                         â”‚
â”‚  â€¢ Rate limiting                            â”‚
â”‚  â€¢ Authentication & authorization           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Data Layer                  â”‚
â”‚  â€¢ Encryption at rest                       â”‚
â”‚  â€¢ Data integrity checks                    â”‚
â”‚  â€¢ Secure key management                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Storage Layer               â”‚
â”‚  â€¢ File system permissions                  â”‚
â”‚  â€¢ Database access controls                 â”‚
â”‚  â€¢ Audit logging                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Network Layer               â”‚
â”‚  â€¢ TLS encryption                           â”‚
â”‚  â€¢ Certificate validation                   â”‚
â”‚  â€¢ Network segmentation                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Encryption

### Encryption at Rest

The memory bank supports multiple encryption algorithms for data at rest:

```typescript
// AES-256-GCM encryption (recommended)
const secureConfig = {
  backend: 'sqlite',
  storage: { path: './secure.db' },
  security: {
    encryption: {
      enabled: true,
      algorithm: 'aes-256-gcm', // Authenticated encryption
      keyDerivation: 'argon2',   // Strong key derivation
      keyDerivationOptions: {
        memory: 65536,            // 64MB memory cost
        iterations: 3,            // Time cost
        parallelism: 1,           // Parallelism
        saltLength: 32            // 256-bit salt
      },
      rotateKeys: true,
      keyRotationInterval: 30 * 24 * 60 * 60 * 1000 // 30 days
    }
  }
};

// Alternative: ChaCha20-Poly1305 for high-performance environments
const highPerfConfig = {
  security: {
    encryption: {
      enabled: true,
      algorithm: 'chacha20-poly1305', // Fast authenticated encryption
      keyDerivation: 'scrypt',
      keyDerivationOptions: {
        memory: 32768,            // 32MB memory cost
        iterations: 1,            // Lower iteration count
        parallelism: 1,
        saltLength: 32
      }
    }
  }
};
```

### Key Management

```typescript
// Environment-based key management
class EnvironmentKeyManager implements KeyManager {
  async getKey(keyId: string): Promise<Buffer> {
    const key = process.env[`MEMORY_KEY_${keyId.toUpperCase()}`];
    if (!key) {
      throw new Error(`Key not found: ${keyId}`);
    }
    return Buffer.from(key, 'base64');
  }
  
  async rotateKey(keyId: string): Promise<Buffer> {
    const newKey = crypto.randomBytes(32);
    // Store new key securely (implementation depends on your key storage)
    await this.storeKey(keyId, newKey);
    return newKey;
  }
}

// HashiCorp Vault integration
class VaultKeyManager implements KeyManager {
  constructor(private vaultClient: VaultClient) {}
  
  async getKey(keyId: string): Promise<Buffer> {
    const response = await this.vaultClient.read(`secret/memory-keys/${keyId}`);
    return Buffer.from(response.data.key, 'base64');
  }
  
  async rotateKey(keyId: string): Promise<Buffer> {
    const newKey = crypto.randomBytes(32);
    await this.vaultClient.write(`secret/memory-keys/${keyId}`, {
      key: newKey.toString('base64'),
      created: new Date().toISOString()
    });
    return newKey;
  }
}

// AWS KMS integration
class KMSKeyManager implements KeyManager {
  constructor(private kmsClient: KMSClient) {}
  
  async getKey(keyId: string): Promise<Buffer> {
    const command = new DecryptCommand({
      CiphertextBlob: Buffer.from(keyId, 'base64')
    });
    const response = await this.kmsClient.send(command);
    return Buffer.from(response.Plaintext!);
  }
  
  async generateDataKey(): Promise<{ keyId: string; key: Buffer }> {
    const command = new GenerateDataKeyCommand({
      KeyId: 'alias/memory-bank-key',
      KeySpec: 'AES_256'
    });
    const response = await this.kmsClient.send(command);
    
    return {
      keyId: Buffer.from(response.CiphertextBlob!).toString('base64'),
      key: Buffer.from(response.Plaintext!)
    };
  }
}
```

### Field-Level Encryption

```typescript
// Encrypt sensitive fields individually
class FieldEncryption {
  constructor(private keyManager: KeyManager) {}
  
  async encryptSensitiveData(item: MemoryItem): Promise<MemoryItem> {
    const encryptedItem = { ...item };
    
    // Encrypt content if it contains sensitive data
    if (this.isSensitive(item.content)) {
      encryptedItem.content = await this.encrypt(item.content, 'content-key');
      encryptedItem.metadata = {
        ...item.metadata,
        encrypted: ['content']
      };
    }
    
    // Encrypt sensitive metadata fields
    if (item.metadata) {
      const sensitiveFields = ['ssn', 'creditCard', 'password', 'apiKey'];
      const encryptedMetadata = { ...item.metadata };
      const encryptedFields: string[] = [];
      
      for (const field of sensitiveFields) {
        if (encryptedMetadata[field]) {
          encryptedMetadata[field] = await this.encrypt(
            String(encryptedMetadata[field]), 
            `metadata-${field}-key`
          );
          encryptedFields.push(field);
        }
      }
      
      if (encryptedFields.length > 0) {
        encryptedMetadata.encrypted = [
          ...(encryptedMetadata.encrypted || []),
          ...encryptedFields
        ];
      }
      
      encryptedItem.metadata = encryptedMetadata;
    }
    
    return encryptedItem;
  }
  
  private isSensitive(content: string): boolean {
    const sensitivePatterns = [
      /\b\d{3}-\d{2}-\d{4}\b/,      // SSN pattern
      /\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b/, // Credit card pattern
      /(?:password|pwd|passwd)[:=]\s*\S+/i,     // Password patterns
      /(?:api[_-]?key|token)[:=]\s*\S+/i        // API key patterns
    ];
    
    return sensitivePatterns.some(pattern => pattern.test(content));
  }
  
  private async encrypt(data: string, keyId: string): Promise<string> {
    const key = await this.keyManager.getKey(keyId);
    const iv = crypto.randomBytes(12); // 96-bit IV for GCM
    const cipher = crypto.createCipher('aes-256-gcm', key, { iv });
    
    let encrypted = cipher.update(data, 'utf8', 'base64');
    encrypted += cipher.final('base64');
    const authTag = cipher.getAuthTag();
    
    // Combine IV, auth tag, and encrypted data
    const combined = Buffer.concat([iv, authTag, Buffer.from(encrypted, 'base64')]);
    return combined.toString('base64');
  }
}
```

## Access Control

### Authentication

```typescript
// JWT-based authentication
interface AuthConfig {
  enabled: boolean;
  method: 'jwt' | 'certificate' | 'api-key' | 'custom';
  jwt?: {
    secret: string;
    algorithm: 'HS256' | 'RS256' | 'ES256';
    issuer: string;
    audience: string;
    expiresIn: string;
    clockTolerance: number;
  };
  certificate?: {
    ca: string;
    cert: string;
    key: string;
    passphrase?: string;
  };
  apiKey?: {
    headerName: string;
    prefix?: string;
    validation: (key: string) => Promise<boolean>;
  };
}

class JWTAuthenticator implements Authenticator {
  constructor(private config: AuthConfig['jwt']) {}
  
  async authenticate(token: string): Promise<AuthContext> {
    try {
      const payload = jwt.verify(token, this.config!.secret, {
        algorithms: [this.config!.algorithm],
        issuer: this.config!.issuer,
        audience: this.config!.audience,
        clockTolerance: this.config!.clockTolerance
      }) as JWTPayload;
      
      return {
        authenticated: true,
        agentId: payload.sub,
        roles: payload.roles || [],
        permissions: payload.permissions || [],
        namespace: payload.namespace,
        expiresAt: new Date(payload.exp * 1000)
      };
    } catch (error) {
      throw new SecurityError('Invalid token', 'INVALID_TOKEN', { error });
    }
  }
  
  async generateToken(agentId: string, options: TokenOptions): Promise<string> {
    const payload: JWTPayload = {
      sub: agentId,
      iss: this.config!.issuer,
      aud: this.config!.audience,
      iat: Math.floor(Date.now() / 1000),
      exp: Math.floor(Date.now() / 1000) + this.parseExpiration(this.config!.expiresIn),
      roles: options.roles || [],
      permissions: options.permissions || [],
      namespace: options.namespace
    };
    
    return jwt.sign(payload, this.config!.secret, {
      algorithm: this.config!.algorithm
    });
  }
}

// Certificate-based authentication
class CertificateAuthenticator implements Authenticator {
  constructor(private config: AuthConfig['certificate']) {}
  
  async authenticate(certificate: X509Certificate): Promise<AuthContext> {
    // Verify certificate chain
    if (!this.verifyCertificateChain(certificate)) {
      throw new SecurityError('Invalid certificate chain', 'INVALID_CERTIFICATE');
    }
    
    // Extract agent information from certificate
    const subject = certificate.subject;
    const agentId = subject.getField('CN').value;
    const roles = this.extractRoles(certificate);
    
    return {
      authenticated: true,
      agentId,
      roles,
      permissions: this.resolvePermissions(roles),
      expiresAt: certificate.validTo
    };
  }
  
  private verifyCertificateChain(certificate: X509Certificate): boolean {
    // Implementation depends on your PKI setup
    const ca = fs.readFileSync(this.config!.ca);
    return certificate.verify(ca);
  }
  
  private extractRoles(certificate: X509Certificate): string[] {
    // Extract roles from certificate extensions or subject
    const organizationalUnit = certificate.subject.getField('OU')?.value;
    return organizationalUnit ? organizationalUnit.split(',') : [];
  }
}
```

### Role-Based Access Control (RBAC)

```typescript
// Define roles and permissions
interface Role {
  name: string;
  permissions: Permission[];
  description: string;
}

interface Permission {
  resource: string;
  actions: string[];
  conditions?: Condition[];
}

interface Condition {
  field: string;
  operator: 'equals' | 'in' | 'regex';
  value: any;
}

const predefinedRoles: Role[] = [
  {
    name: 'admin',
    description: 'Full system access',
    permissions: [
      {
        resource: '*',
        actions: ['*']
      }
    ]
  },
  {
    name: 'agent',
    description: 'Standard agent access',
    permissions: [
      {
        resource: 'memory',
        actions: ['read', 'write', 'delete'],
        conditions: [
          {
            field: 'namespace',
            operator: 'equals',
            value: '${auth.namespace}'
          }
        ]
      }
    ]
  },
  {
    name: 'reader',
    description: 'Read-only access',
    permissions: [
      {
        resource: 'memory',
        actions: ['read']
      }
    ]
  },
  {
    name: 'researcher',
    description: 'Research data access',
    permissions: [
      {
        resource: 'memory',
        actions: ['read', 'write'],
        conditions: [
          {
            field: 'category',
            operator: 'in',
            value: ['research', 'analysis', 'findings']
          }
        ]
      }
    ]
  }
];

class RBACAuthorizer implements Authorizer {
  constructor(private roles: Map<string, Role>) {}
  
  async authorize(
    auth: AuthContext,
    action: string,
    resource: MemoryItem | MemoryQuery
  ): Promise<boolean> {
    // Check if user has required roles
    for (const roleName of auth.roles) {
      const role = this.roles.get(roleName);
      if (!role) continue;
      
      for (const permission of role.permissions) {
        if (this.matchesPermission(permission, action, resource, auth)) {
          return true;
        }
      }
    }
    
    return false;
  }
  
  private matchesPermission(
    permission: Permission,
    action: string,
    resource: any,
    auth: AuthContext
  ): boolean {
    // Check resource match
    if (permission.resource !== '*' && permission.resource !== 'memory') {
      return false;
    }
    
    // Check action match
    if (!permission.actions.includes('*') && !permission.actions.includes(action)) {
      return false;
    }
    
    // Check conditions
    if (permission.conditions) {
      return permission.conditions.every(condition =>
        this.evaluateCondition(condition, resource, auth)
      );
    }
    
    return true;
  }
  
  private evaluateCondition(
    condition: Condition,
    resource: any,
    auth: AuthContext
  ): boolean {
    let value = this.resolveValue(condition.value, auth);
    let resourceValue = this.getResourceValue(resource, condition.field);
    
    switch (condition.operator) {
      case 'equals':
        return resourceValue === value;
      case 'in':
        return Array.isArray(value) && value.includes(resourceValue);
      case 'regex':
        return new RegExp(value).test(String(resourceValue));
      default:
        return false;
    }
  }
  
  private resolveValue(value: any, auth: AuthContext): any {
    if (typeof value === 'string' && value.startsWith('${')) {
      const path = value.slice(2, -1); // Remove ${ and }
      return this.getNestedValue(auth, path);
    }
    return value;
  }
  
  private getNestedValue(obj: any, path: string): any {
    return path.split('.').reduce((current, key) => current?.[key], obj);
  }
  
  private getResourceValue(resource: any, field: string): any {
    return this.getNestedValue(resource, field);
  }
}
```

### Namespace Isolation

```typescript
// Enforce namespace-based access control
class NamespaceSecurityManager {
  constructor(
    private config: NamespaceConfig,
    private authorizer: Authorizer
  ) {}
  
  async enforceNamespaceAccess(
    auth: AuthContext,
    operation: string,
    target: MemoryItem | MemoryQuery
  ): Promise<void> {
    if (!this.config.enabled) return;
    
    const targetNamespace = this.extractNamespace(target);
    
    // Check if agent has access to the namespace
    if (!await this.hasNamespaceAccess(auth, targetNamespace, operation)) {
      throw new SecurityError(
        `Access denied to namespace: ${targetNamespace}`,
        'NAMESPACE_ACCESS_DENIED',
        { namespace: targetNamespace, operation }
      );
    }
    
    // Apply namespace restrictions to queries
    if (operation === 'query' && target && typeof target === 'object') {
      this.restrictQueryToNamespaces(target as MemoryQuery, auth);
    }
  }
  
  private async hasNamespaceAccess(
    auth: AuthContext,
    namespace: string,
    operation: string
  ): Promise<boolean> {
    const permissions = this.config.permissions?.[namespace];
    if (!permissions) {
      // Use default namespace permissions
      return this.hasNamespaceAccess(auth, this.config.defaultNamespace, operation);
    }
    
    // Check public access
    if (operation === 'read' && permissions.public) {
      return true;
    }
    
    // Check specific permissions
    const requiredList = this.getRequiredPermissionList(permissions, operation);
    return requiredList.includes('*') || requiredList.includes(auth.agentId);
  }
  
  private getRequiredPermissionList(
    permissions: NamespacePermissions[string],
    operation: string
  ): string[] {
    switch (operation) {
      case 'read':
      case 'query':
        return permissions.read;
      case 'write':
      case 'store':
      case 'update':
        return permissions.write;
      case 'delete':
      case 'admin':
        return permissions.admin;
      default:
        return [];
    }
  }
  
  private extractNamespace(target: MemoryItem | MemoryQuery): string {
    if ('namespace' in target && target.namespace) {
      return target.namespace;
    }
    return this.config.defaultNamespace;
  }
  
  private restrictQueryToNamespaces(query: MemoryQuery, auth: AuthContext): void {
    const allowedNamespaces = this.getAllowedNamespaces(auth);
    
    if (query.namespace) {
      // Verify the requested namespace is allowed
      if (!allowedNamespaces.includes(query.namespace)) {
        throw new SecurityError(
          `Access denied to namespace: ${query.namespace}`,
          'NAMESPACE_ACCESS_DENIED'
        );
      }
    } else if (query.namespaces) {
      // Filter to only allowed namespaces
      query.namespaces = query.namespaces.filter(ns => allowedNamespaces.includes(ns));
    } else {
      // Restrict to allowed namespaces
      query.namespaces = allowedNamespaces;
    }
  }
  
  private getAllowedNamespaces(auth: AuthContext): string[] {
    const allowed: string[] = [];
    
    if (this.config.permissions) {
      for (const [namespace, permissions] of Object.entries(this.config.permissions)) {
        if (permissions.public || 
            permissions.read.includes('*') || 
            permissions.read.includes(auth.agentId)) {
          allowed.push(namespace);
        }
      }
    }
    
    return allowed.length > 0 ? allowed : [this.config.defaultNamespace];
  }
}
```

## Data Integrity

### Checksums and Validation

```typescript
// Data integrity verification
class IntegrityManager {
  constructor(private config: SecurityConfig['checksums']) {}
  
  async calculateChecksum(data: string | Buffer): Promise<string> {
    if (!this.config?.enabled) return '';
    
    const hash = crypto.createHash(this.config.algorithm);
    hash.update(data);
    return `${this.config.algorithm}:${hash.digest('hex')}`;
  }
  
  async verifyChecksum(data: string | Buffer, expectedChecksum: string): Promise<boolean> {
    if (!this.config?.enabled || !expectedChecksum) return true;
    
    const actualChecksum = await this.calculateChecksum(data);
    return actualChecksum === expectedChecksum;
  }
  
  async verifyItem(item: MemoryItem): Promise<IntegrityResult> {
    const result: IntegrityResult = {
      valid: true,
      errors: []
    };
    
    // Verify content checksum
    if (item.checksum && this.config?.verifyOnRead) {
      const contentValid = await this.verifyChecksum(item.content, item.checksum);
      if (!contentValid) {
        result.valid = false;
        result.errors.push('Content checksum mismatch');
        
        if (this.config.repairCorruption) {
          await this.attemptRepair(item);
        }
      }
    }
    
    // Verify metadata integrity
    if (item.metadata && item.vectorClock) {
      const metadataValid = this.verifyMetadataIntegrity(item);
      if (!metadataValid) {
        result.valid = false;
        result.errors.push('Metadata integrity check failed');
      }
    }
    
    return result;
  }
  
  private verifyMetadataIntegrity(item: MemoryItem): boolean {
    // Check required fields
    const requiredFields = ['id', 'category', 'content', 'created', 'updated'];
    for (const field of requiredFields) {
      if (!(field in item) || item[field as keyof MemoryItem] === null || item[field as keyof MemoryItem] === undefined) {
        return false;
      }
    }
    
    // Check timestamp consistency
    if (item.updated < item.created) {
      return false;
    }
    
    // Check version consistency
    if (item.version < 1) {
      return false;
    }
    
    return true;
  }
  
  private async attemptRepair(item: MemoryItem): Promise<void> {
    // Log corruption for investigation
    console.warn(`Data corruption detected for item ${item.id}`);
    
    // Attempt to reconstruct from backup or replica
    // Implementation depends on your backup/replication strategy
  }
}

interface IntegrityResult {
  valid: boolean;
  errors: string[];
}
```

### Secure Deletion

```typescript
// Secure deletion implementation
class SecureDeletion {
  constructor(private config: SecurityConfig) {}
  
  async secureDelete(backend: MemoryBackend, itemId: string): Promise<boolean> {
    const item = await backend.retrieve(itemId);
    if (!item) return false;
    
    try {
      // Overwrite sensitive data before deletion
      if (this.config.checksums?.enabled && this.config.secureDelete) {
        await this.overwriteData(backend, item);
      }
      
      // Perform actual deletion
      const deleted = await backend.delete(itemId);
      
      // Log secure deletion
      if (this.config.auditLog?.enabled) {
        await this.logSecureDeletion(itemId, item);
      }
      
      return deleted;
    } catch (error) {
      console.error(`Secure deletion failed for item ${itemId}:`, error);
      return false;
    }
  }
  
  private async overwriteData(backend: MemoryBackend, item: MemoryItem): Promise<void> {
    // Overwrite with random data multiple times
    const overwritePasses = 3;
    
    for (let pass = 0; pass < overwritePasses; pass++) {
      const randomContent = crypto.randomBytes(item.content.length).toString('base64');
      const overwriteItem: MemoryItem = {
        ...item,
        content: randomContent,
        checksum: await this.calculateChecksum(randomContent),
        updated: Date.now()
      };
      
      await backend.update(item.id, overwriteItem);
    }
  }
  
  private async logSecureDeletion(itemId: string, item: MemoryItem): Promise<void> {
    const auditEvent = {
      timestamp: new Date(),
      operation: 'secure_delete',
      itemId,
      category: item.category,
      namespace: item.namespace,
      agent: 'system' // Or extract from current context
    };
    
    // Write to audit log
    console.log('AUDIT:', JSON.stringify(auditEvent));
  }
  
  private async calculateChecksum(data: string): Promise<string> {
    const hash = crypto.createHash('sha256');
    hash.update(data);
    return `sha256:${hash.digest('hex')}`;
  }
}
```

## Audit Logging

### Comprehensive Audit Trail

```typescript
// Audit logging system
class AuditLogger {
  constructor(
    private config: SecurityConfig['auditLog'],
    private storage: AuditStorage
  ) {}
  
  async logOperation(event: AuditEvent): Promise<void> {
    if (!this.config?.enabled) return;
    
    const enrichedEvent: EnrichedAuditEvent = {
      ...event,
      timestamp: new Date(),
      id: crypto.randomUUID(),
      sessionId: this.getCurrentSessionId(),
      level: this.determineLogLevel(event),
      checksum: await this.calculateEventChecksum(event)
    };
    
    // Include data payload if configured
    if (this.config.includeData && event.data) {
      enrichedEvent.data = this.sanitizeData(event.data);
    }
    
    await this.storage.write(enrichedEvent);
    
    // Real-time monitoring alerts
    if (this.isSecurityEvent(event)) {
      await this.sendSecurityAlert(enrichedEvent);
    }
  }
  
  private determineLogLevel(event: AuditEvent): 'info' | 'warning' | 'error' {
    if (event.operation.includes('delete') || event.operation.includes('admin')) {
      return 'warning';
    }
    if (event.success === false) {
      return 'error';
    }
    return 'info';
  }
  
  private sanitizeData(data: any): any {
    // Remove sensitive information from audit logs
    const sanitized = JSON.parse(JSON.stringify(data));
    
    const sensitiveFields = ['password', 'token', 'apiKey', 'secret'];
    const sanitizeObject = (obj: any) => {
      if (typeof obj !== 'object' || obj === null) return;
      
      for (const key of Object.keys(obj)) {
        if (sensitiveFields.some(field => key.toLowerCase().includes(field))) {
          obj[key] = '[REDACTED]';
        } else if (typeof obj[key] === 'object') {
          sanitizeObject(obj[key]);
        }
      }
    };
    
    sanitizeObject(sanitized);
    return sanitized;
  }
  
  private isSecurityEvent(event: AuditEvent): boolean {
    const securityOperations = [
      'authentication_failed',
      'authorization_denied',
      'admin_operation',
      'security_violation',
      'data_corruption_detected'
    ];
    
    return securityOperations.includes(event.operation);
  }
  
  private async sendSecurityAlert(event: EnrichedAuditEvent): Promise<void> {
    // Implementation depends on your alerting system
    console.warn('SECURITY ALERT:', {
      operation: event.operation,
      agent: event.agentId,
      timestamp: event.timestamp,
      details: event.details
    });
  }
  
  private async calculateEventChecksum(event: AuditEvent): Promise<string> {
    const eventString = JSON.stringify(event, Object.keys(event).sort());
    const hash = crypto.createHash('sha256');
    hash.update(eventString);
    return hash.digest('hex');
  }
  
  private getCurrentSessionId(): string {
    // Implementation depends on your session management
    return crypto.randomUUID();
  }
}

interface AuditEvent {
  operation: string;
  agentId?: string;
  namespace?: string;
  itemId?: string;
  success: boolean;
  details?: Record<string, any>;
  data?: any;
}

interface EnrichedAuditEvent extends AuditEvent {
  id: string;
  timestamp: Date;
  sessionId: string;
  level: 'info' | 'warning' | 'error';
  checksum: string;
}

// File-based audit storage
class FileAuditStorage implements AuditStorage {
  constructor(
    private logPath: string,
    private rotateSize: number = 100 * 1024 * 1024 // 100MB
  ) {}
  
  async write(event: EnrichedAuditEvent): Promise<void> {
    const logLine = JSON.stringify(event) + '\n';
    
    // Check if rotation is needed
    await this.checkRotation();
    
    // Append to current log file
    await fs.appendFile(this.logPath, logLine, { encoding: 'utf8' });
  }
  
  private async checkRotation(): Promise<void> {
    try {
      const stats = await fs.stat(this.logPath);
      if (stats.size >= this.rotateSize) {
        await this.rotateLog();
      }
    } catch (error) {
      // File doesn't exist yet, that's fine
    }
  }
  
  private async rotateLog(): Promise<void> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const rotatedPath = `${this.logPath}.${timestamp}`;
    
    await fs.rename(this.logPath, rotatedPath);
    
    // Compress old log file
    const gzip = createGzip();
    const source = createReadStream(rotatedPath);
    const destination = createWriteStream(`${rotatedPath}.gz`);
    
    await pipeline(source, gzip, destination);
    await fs.unlink(rotatedPath);
  }
}
```

## Rate Limiting

### Request Rate Limiting

```typescript
// Rate limiting implementation
class RateLimiter {
  private buckets: Map<string, TokenBucket> = new Map();
  
  constructor(private config: SecurityConfig['rateLimiting']) {}
  
  async checkRateLimit(agentId: string, operation: string): Promise<RateLimitResult> {
    if (!this.config?.enabled) {
      return { allowed: true, remaining: Infinity, resetTime: null };
    }
    
    const bucketKey = `${agentId}:${operation}`;
    let bucket = this.buckets.get(bucketKey);
    
    if (!bucket) {
      bucket = new TokenBucket(
        this.getOperationLimit(operation),
        this.config.windowSize || 60000 // 1 minute default
      );
      this.buckets.set(bucketKey, bucket);
    }
    
    const allowed = bucket.consume();
    
    if (!allowed) {
      // Log rate limit violation
      console.warn(`Rate limit exceeded for agent ${agentId}, operation ${operation}`);
    }
    
    return {
      allowed,
      remaining: bucket.tokens,
      resetTime: bucket.resetTime
    };
  }
  
  private getOperationLimit(operation: string): number {
    // Different limits for different operations
    const operationLimits: Record<string, number> = {
      'store': this.config?.perAgentLimit || 100,
      'query': (this.config?.perAgentLimit || 100) * 2, // Queries can be more frequent
      'retrieve': (this.config?.perAgentLimit || 100) * 5, // Retrievals are lighter
      'delete': Math.floor((this.config?.perAgentLimit || 100) / 10) // Deletions are limited
    };
    
    return operationLimits[operation] || this.config?.perAgentLimit || 100;
  }
}

class TokenBucket {
  public tokens: number;
  public resetTime: Date;
  
  constructor(
    private capacity: number,
    private windowMs: number
  ) {
    this.tokens = capacity;
    this.resetTime = new Date(Date.now() + windowMs);
    
    // Schedule token refill
    this.scheduleRefill();
  }
  
  consume(): boolean {
    if (this.tokens > 0) {
      this.tokens--;
      return true;
    }
    return false;
  }
  
  private scheduleRefill(): void {
    const timeToRefill = this.resetTime.getTime() - Date.now();
    
    setTimeout(() => {
      this.tokens = this.capacity;
      this.resetTime = new Date(Date.now() + this.windowMs);
      this.scheduleRefill();
    }, timeToRefill);
  }
}

interface RateLimitResult {
  allowed: boolean;
  remaining: number;
  resetTime: Date | null;
}
```

## Security Best Practices

### Secure Configuration

```typescript
// Production security configuration template
const productionSecurityConfig: MemoryConfig = {
  backend: 'sqlite',
  storage: {
    path: process.env.MEMORY_DB_PATH || '/var/lib/memory/production.db',
    options: {
      // Security-focused database settings
      foreignKeys: true,
      secureDelete: true,
      journalMode: 'WAL',
      synchronous: 'FULL' // Prioritize data integrity
    }
  },
  security: {
    encryption: {
      enabled: true,
      algorithm: 'aes-256-gcm',
      keyDerivation: 'argon2',
      keyDerivationOptions: {
        memory: 65536,      // 64MB memory cost
        iterations: 3,      // Time cost
        parallelism: 1,     // Parallelism
        saltLength: 32      // 256-bit salt
      },
      rotateKeys: true,
      keyRotationInterval: 30 * 24 * 60 * 60 * 1000 // 30 days
    },
    checksums: {
      enabled: true,
      algorithm: 'blake3', // Fast and secure
      verifyOnRead: true,
      repairCorruption: false // Don't auto-repair in production
    },
    authentication: {
      enabled: true,
      method: 'certificate', // Most secure for production
      certificateConfig: {
        ca: process.env.MEMORY_CA_CERT_PATH!,
        cert: process.env.MEMORY_CLIENT_CERT_PATH!,
        key: process.env.MEMORY_CLIENT_KEY_PATH!
      }
    },
    auditLog: {
      enabled: true,
      level: 'standard',
      destination: 'file',
      logFile: '/var/log/memory/audit.log',
      rotateSize: 100 * 1024 * 1024, // 100MB
      retentionDays: 90,
      includeData: false // Don't include sensitive data
    },
    rateLimiting: {
      enabled: true,
      globalLimit: 10000,   // 10k ops/sec globally
      perAgentLimit: 1000,  // 1k ops/sec per agent
      burstAllowance: 100,  // Allow bursts
      windowSize: 60000     // 1 minute window
    }
  },
  namespaces: {
    enabled: true,
    defaultNamespace: 'default',
    enforcePermissions: true,
    strictIsolation: true,
    allowGlobalSearch: false // Prevent cross-namespace data leaks
  }
};
```

### Security Checklist

#### Deployment Security

- [ ] **Encryption**: Enable encryption at rest with strong algorithms
- [ ] **Key Management**: Use secure key storage (Vault, KMS, etc.)
- [ ] **Authentication**: Implement certificate-based auth for production
- [ ] **Authorization**: Configure role-based access control
- [ ] **Audit Logging**: Enable comprehensive audit trails
- [ ] **Rate Limiting**: Implement request rate limiting
- [ ] **Network Security**: Use TLS for all communications
- [ ] **File Permissions**: Restrict file system permissions

#### Operational Security

- [ ] **Regular Updates**: Keep dependencies updated
- [ ] **Security Scanning**: Regular vulnerability scans
- [ ] **Monitoring**: Real-time security monitoring
- [ ] **Backup Security**: Encrypt and secure backups
- [ ] **Incident Response**: Have incident response procedures
- [ ] **Key Rotation**: Regular key rotation schedules
- [ ] **Access Reviews**: Regular access permission reviews
- [ ] **Security Training**: Team security awareness

#### Development Security

- [ ] **Secure Coding**: Follow secure coding practices
- [ ] **Input Validation**: Validate all inputs
- [ ] **Error Handling**: Don't leak sensitive information
- [ ] **Testing**: Include security in testing procedures
- [ ] **Code Review**: Security-focused code reviews
- [ ] **Dependency Scanning**: Scan for vulnerable dependencies
- [ ] **Secret Management**: Never commit secrets
- [ ] **Least Privilege**: Follow principle of least privilege

### Common Security Vulnerabilities

#### Prevention Strategies

```typescript
// Input validation to prevent injection attacks
class InputValidator {
  static validateMemoryItem(item: Partial<MemoryItem>): ValidationResult {
    const errors: string[] = [];
    
    // Validate required fields
    if (!item.category || typeof item.category !== 'string') {
      errors.push('Category is required and must be a string');
    }
    
    if (!item.content || typeof item.content !== 'string') {
      errors.push('Content is required and must be a string');
    }
    
    // Validate content length to prevent DoS
    if (item.content && item.content.length > 1024 * 1024) { // 1MB limit
      errors.push('Content too large (max 1MB)');
    }
    
    // Validate tags
    if (item.tags) {
      if (!Array.isArray(item.tags)) {
        errors.push('Tags must be an array');
      } else if (item.tags.length > 100) {
        errors.push('Too many tags (max 100)');
      } else if (item.tags.some(tag => typeof tag !== 'string')) {
        errors.push('All tags must be strings');
      }
    }
    
    // Validate namespace
    if (item.namespace && !/^[a-zA-Z0-9_-]+$/.test(item.namespace)) {
      errors.push('Invalid namespace format');
    }
    
    // Validate metadata
    if (item.metadata) {
      if (typeof item.metadata !== 'object') {
        errors.push('Metadata must be an object');
      } else {
        const metadataSize = JSON.stringify(item.metadata).length;
        if (metadataSize > 64 * 1024) { // 64KB limit
          errors.push('Metadata too large (max 64KB)');
        }
      }
    }
    
    return {
      valid: errors.length === 0,
      errors
    };
  }
}

interface ValidationResult {
  valid: boolean;
  errors: string[];
}
```

This comprehensive security guide covers all major aspects of securing the SPARC Memory Bank system, from encryption and access control to audit logging and best practices. The implementation provides multiple layers of security to protect against various threats and vulnerabilities.</doc><doc title="Changelog" desc="optional reading."># Claude Optimized Template Changelog

All notable changes to the Claude optimized template will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [1.0.0] - 2025-06-16

### Added
- Initial release of optimized Claude Code templates
- Complete set of SPARC methodology slash commands
- Batch tools integration for improved performance
- Comprehensive test suite structure
- Documentation files:
  - BATCHTOOLS_GUIDE.md - Complete guide for batch tool usage
  - BATCHTOOLS_BEST_PRACTICES.md - Best practices and examples
  - MIGRATION_GUIDE.md - Migration guide for existing projects
  - PERFORMANCE_BENCHMARKS.md - Performance comparison data
- Claude Flow integration commands:
  - claude-flow-help - Help and documentation access
  - claude-flow-memory - Memory system interaction
  - claude-flow-swarm - Swarm coordination
- SPARC mode commands:
  - architect - System design and architecture
  - code - Clean code implementation
  - debug - Debugging and troubleshooting
  - devops - Deployment and infrastructure
  - docs-writer - Documentation creation
  - integration - System integration
  - mcp - MCP service integration
  - refinement-optimization-mode - Performance optimization
  - security-review - Security analysis
  - spec-pseudocode - Requirements and algorithms
  - supabase-admin - Supabase administration
  - tdd - Test-driven development
  - tutorial - Tutorial creation
  - ask - Interactive queries
  - post-deployment-monitoring-mode - Post-deployment monitoring
- Test suite with categories:
  - Unit tests for core functionality
  - Integration tests for SPARC modes
  - Performance benchmarks
  - Error handling tests
  - End-to-end workflow tests
- Manifest system for easy installation and maintenance
- Version tracking mechanism

### Features
- Optimized prompts for reduced token usage
- Batch operations for improved performance
- Parallel tool execution support
- Comprehensive error handling
- Rollback mechanisms for failed operations
- Resource usage monitoring
- End-to-end workflow support

### Technical Details
- Compatible with Claude Code CLI
- Requires Node.js for test execution
- Supports all major SPARC methodology phases
- Integrated with Claude Flow orchestration
- Designed for maintainability and extensibility

## Version History

- **1.0.0** (2025-06-16): Initial release with full SPARC support and batch tools</doc></optional></project>